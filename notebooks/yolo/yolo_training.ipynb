{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0tyX_84Pj7h8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0tyX_84Pj7h8",
        "outputId": "fb0fc1b9-7307-4b1e-df49-c7eb7b0e210e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6D_pose'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 364 (delta 10), reused 3 (delta 1), pack-reused 334 (from 1)\u001b[K\n",
            "Receiving objects: 100% (364/364), 5.78 MiB | 23.04 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n",
            "Cloned https://github.com/fraco03/6D_pose.git to /content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
        "branch = \"main\"\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17424d2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "17424d2f",
        "outputId": "0a2c014c-b150-4b96-c74a-9c2757f3acc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.240-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.240-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.240 ultralytics-thop-2.0.18\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ultralytics\n",
        "from ultralytics import YOLO\n",
        "from src.detection.yolo_utils import calculate_adapted_map50, visualize_bbox, create_teacher_dataset_final, create_student_dataset_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NuX6Nc1uGPpk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuX6Nc1uGPpk",
        "outputId": "0eba2fba-1e60-4a75-a234-2fc77a4cc00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ› ï¸  Setting up directories...\n",
            "ğŸŒ Downloading background images...\n",
            "â™»ï¸  Loading objects for collages (excluding class 02)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Generating 2000 synthetic collages...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:17<00:00, 111.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¸ Processing real images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [01:50<00:00,  8.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Dataset generated successfully!\n",
            "   [TRAINING]  Synthetic collages (no class 2):  2000\n",
            "   [TRAINING]  Real images (class 2 only):       30\n",
            "   [SKIPPED]   Real training images (others):    374\n",
            "   [VALIDATION] Real images (all classes):       15396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: GENERATE SYNTHETIC TRAINING DATASET WITH COLLAGES\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import yaml\n",
        "import shutil\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "SOURCE_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed/data'\n",
        "DEST_ROOT = '/kaggle/working/datasets'\n",
        "BG_CACHE_DIR = '/kaggle/working/backgrounds_cache'\n",
        "\n",
        "NUM_COLLAGES = 4000      # Number of synthetic collage images to generate\n",
        "MAX_OBJECTS_PER_IMG = 7  # Maximum objects per collage image\n",
        "\n",
        "train_subset, test_subset = create_teacher_dataset_final(SOURCE_ROOT,DEST_ROOT,BG_CACHE_DIR,NUM_COLLAGES,MAX_OBJECTS_PER_IMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcRIw4WjiXgu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "fcRIw4WjiXgu",
        "outputId": "07a1be9f-1b2d-4d57-e00b-79eb0f09551d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GPU: Tesla T4\n",
            "ğŸš€ Starting Training on Colab T4...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/linemod.yaml, degrees=10.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=yolo11_collage_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_Runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_Runs/yolo11_collage_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=13\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    433207  ultralytics.nn.modules.head.Detect           [13, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,592,375 parameters, 2,592,359 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 31.8Â±5.9 MB/s, size: 97.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/labels/train.cache... 2030 images, 0 backgrounds, 8 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2030/2030 2.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1038.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.054688]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1102.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.051562]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1129.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.020313]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1133.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.015625]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1159.png: ignoring corrupt image/label: negative class labels or coordinate [   -0.13594]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1163.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.042969]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1191.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0336]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/images/train/real_02_1205.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0242]\n",
            "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0m3.4GB RAM required to cache images with 50% safety margin but only 3.0/12.7GB available, not caching images\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 73.7Â±16.4 MB/s, size: 455.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/labels/val.cache... 3079 images, 0 backgrounds, 45 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3079/3079 981.5Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0109.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.032]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0120.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0406]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0262.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0109]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0299.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0297]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0301.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.060417]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0363.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.015625]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0373.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.030208]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0382.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0211]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0515.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.021094]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0573.png: ignoring corrupt image/label: negative class labels or coordinate [   -0.01875]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0587.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.05]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0588.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.050781]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0589.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.054688]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0641.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.061458]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0644.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0323]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0658.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0289]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0667.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0664]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0669.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0758]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0695.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.067708]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0718.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.015625]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0721.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.025781]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0767.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0344]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0847.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0823]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0907.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0758]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0908.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0617]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0909.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0797]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0911.png: ignoring corrupt image/label: negative class labels or coordinate [   -0.04375]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0914.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.078125]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0915.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.040625   -0.091406]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0924.png: ignoring corrupt image/label: negative class labels or coordinate [    -0.0625]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0931.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0949.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.034375]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0951.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.038281]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0954.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0148]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0960.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.078125]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0977.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.029167]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0978.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.059375]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_0999.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.076]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1012.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.029687]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1063.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.028906]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1075.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.017188]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1105.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.057813]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1130.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.028125]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1155.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.032]\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/images/val/real_02_1158.png: ignoring corrupt image/label: negative class labels or coordinate [  -0.029687]\n",
            "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0m3.9GB RAM required to cache images with 50% safety margin but only 2.7/12.7GB available, not caching images\n",
            "Plotting labels to /content/drive/MyDrive/YOLO_Runs/yolo11_collage_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000588, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/YOLO_Runs/yolo11_collage_run\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      4.87G      1.637      3.971      1.345         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 1.4it/s 47.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 12/48 1.3it/s 9.2s<27.5s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1616262932.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# --- 3. TRAINING LOOP ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/linemod.yaml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_epoch\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpossible_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# prevent VRAM spike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;31m# NaN recovery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# empty before each val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_val_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# CELL 4: TRAIN YOLO MODEL ON SYNTHETIC DATA\n",
        "import torch\n",
        "\n",
        "# --- 1. HARDWARE CHECK ---\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ WARNING: Using CPU! Go to Runtime > Change runtime type > T4 GPU\")\n",
        "\n",
        "# --- 2. MODEL SELECTION ---\n",
        "# YOLO11 Small is perfect for T4 GPU\n",
        "model = YOLO('yolo11s.pt')\n",
        "\n",
        "print(\"ğŸš€ Starting Training on Colab T4...\")\n",
        "\n",
        "# --- 3. TRAINING LOOP ---\n",
        "results = model.train(\n",
        "    data='/kaggle/working/linemod.yaml',\n",
        "\n",
        "    # --- DURATION ---\n",
        "    epochs=60,           # Increased to 100. Synthetic data requires more time to converge\n",
        "    patience=15,         # Early stopping if no improvement for 15 epochs\n",
        "\n",
        "    # --- HARDWARE ---\n",
        "    imgsz=640,\n",
        "    batch=32,            # Batch size 16 is safer and more stable for generalization on difficult datasets\n",
        "    device=[0, 1],\n",
        "    workers=4,\n",
        "    amp=True,            # Mixed Precision ON (Essential for T4)\n",
        "\n",
        "    # --- AUGMENTATION (Tuned for \"Black-on-Black\" scenarios) ---\n",
        "    mosaic=0.5,          # REDUCED. Data is already collaged, don't overdo it\n",
        "    mixup=0.0,           # DISABLED. Critical! We want solid objects, not transparent ghosts\n",
        "\n",
        "    degrees=10.0,        # Light rotation (already done in generator script)\n",
        "    scale=0.5,           # Zoom in/out\n",
        "    translate=0.1,       # Light translation\n",
        "    fliplr=0.5,          # Horizontal flip OK\n",
        "\n",
        "    # --- LIGHTING (YOLO applies these instead of our script) ---\n",
        "    hsv_h=0.015,         # Light color shift\n",
        "    hsv_s=0.7,           # Saturation\n",
        "    hsv_v=0.4,           # BRIGHTNESS (Value): 0.4 is perfect\n",
        "                         # Teaches the model: \"The phone is the same whether dark (black) or illuminated (gray)\"\n",
        "\n",
        "    close_mosaic=10,     # Last 10 epochs turn off mosaic to refine edges\n",
        "\n",
        "    # --- SAVE RESULTS ---\n",
        "    # WARNING: This saves directly to Google Drive\n",
        "    project='/kaggle/working/YOLO_Runs',\n",
        "    name='yolo11s_collage_run',\n",
        "    verbose=True,\n",
        "    exist_ok=True,\n",
        "    save=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iZOGjy1X5pl7",
      "metadata": {
        "id": "iZOGjy1X5pl7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "MODEL_PATH = '/kaggle/working/YOLO_Runs/yolo11_collage_run/weights/best.pt'\n",
        "TEST_DIR = '/kaggle/working/datasets/images/test'  # Directory containing images\n",
        "CONF_THRESHOLD = 0.3  # Confidence threshold\n",
        "\n",
        "# 1. Load Trained Model\n",
        "print(f\"ğŸ§  Loading model from: {MODEL_PATH}\")\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# 2. Select a Random Image from the Test Directory\n",
        "# Get list of valid image files\n",
        "image_files = [f for f in os.listdir(TEST_DIR) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "if not image_files:\n",
        "    raise FileNotFoundError(f\"âŒ No images found in directory: {TEST_DIR}\")\n",
        "\n",
        "# Pick one random file\n",
        "random_filename = random.choice(image_files)\n",
        "img_path = os.path.join(TEST_DIR, random_filename)\n",
        "print(f\"ğŸ² Selected Image: {random_filename}\")\n",
        "\n",
        "# 3. Define Class Names Mapping\n",
        "# Mapping IDs to readable names\n",
        "class_map = {\n",
        "    0: 'ape', 1: 'benchvise', 2: 'camera', 3: 'can', 4: 'cat',\n",
        "    5: 'driller', 6: 'duck', 7: 'eggbox', 8: 'glue', 9: 'holepuncher',\n",
        "    10: 'iron', 11: 'lamp', 12: 'phone'\n",
        "}\n",
        "\n",
        "# 4. Run Inference on the selected image\n",
        "results = model.predict(img_path, conf=CONF_THRESHOLD)\n",
        "\n",
        "# 5. Visualize Results\n",
        "# Load image for drawing\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Check if detections exist\n",
        "if len(results[0].boxes) == 0:\n",
        "    print(\"âš ï¸ No objects detected in this image.\")\n",
        "else:\n",
        "    # Iterate through detections\n",
        "    for box in results[0].boxes:\n",
        "        cls_id = int(box.cls[0])    # Class ID\n",
        "        conf = float(box.conf[0])   # Confidence score\n",
        "        \n",
        "        # Get coordinates\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "        \n",
        "        # Get name (safely handle missing keys)\n",
        "        label_name = class_map.get(cls_id, f\"Unknown_{cls_id}\")\n",
        "        label_text = f\"{label_name} {conf:.2f}\"\n",
        "        \n",
        "        # Draw Rectangle\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        \n",
        "        # Draw Label Background\n",
        "        (w, h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(img, (x1, y1 - 20), (x1 + w, y1), (0, 255, 0), -1)\n",
        "        \n",
        "        # Draw Text\n",
        "        cv2.putText(img, label_text, (x1, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
        "\n",
        "# Display final result\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f'Detection: {random_filename}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NRkNhJMIairt",
      "metadata": {
        "collapsed": true,
        "id": "NRkNhJMIairt"
      },
      "outputs": [],
      "source": [
        "# CELL 6: AUTO-LABELING - USE TRAINED MODEL TO ADD MISSING LABELS\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "DEST_ROOT = '/kaggle/working/dataset_AUTOLABELED'\n",
        "MODEL_PATH = '/kaggle/working/YOLO_Runs/yolo11s_collage_run/weights/best.pt'\n",
        "\n",
        "create_student_dataset_final(DEST_ROOT, MODEL_PATH, train_subset,'/kaggle/working/datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6MCy88k8cpTp",
      "metadata": {
        "id": "6MCy88k8cpTp"
      },
      "outputs": [],
      "source": [
        "# CELL 9: FINAL TRAINING ON AUTO-LABELED DATASET\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Will automatically download standard weights if not found\n",
        "model = YOLO('yolo11m.pt')\n",
        "\n",
        "results = model.train(\n",
        "    # The clean dataset with automatic labels\n",
        "    data='/kaggle/working/dataset_AUTOLABELED/data.yaml',\n",
        "\n",
        "    # --- DURATION ---\n",
        "    epochs=80,\n",
        "    patience=15,\n",
        "\n",
        "    # --- HARDWARE ---\n",
        "    imgsz=640,\n",
        "    batch=32,            # With the 's' model, use 16 to avoid running out of video memory (OOM)\n",
        "    device=0,\n",
        "    workers=4,\n",
        "    cache=True,\n",
        "    # --- AUGMENTATION ---\n",
        "    mosaic=1.0,          # Now that labels are good, mosaic is useful\n",
        "    mixup=0.1,           # Light mixup\n",
        "\n",
        "    degrees=10.0,\n",
        "    fliplr=0.5,\n",
        "    scale=0.5,\n",
        "\n",
        "    # --- OUTPUT ---\n",
        "    project='/kaggle/working/YOLO_Runs',\n",
        "    name='yolo11s_autolabel_final_with_70_th', # Changed name to remind it's the S model\n",
        "    save=True,\n",
        "    exist_ok=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84c22ce",
      "metadata": {
        "id": "c84c22ce"
      },
      "outputs": [],
      "source": [
        "calculate_adapted_map50('/content/drive/MyDrive/YOLO_Runs/yolo11s_autolabel_final/weights/best.pt',\n",
        "                        '/content/data/Linemod_preprocessed/data')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
