{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dad8daca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad8daca",
        "outputId": "1e1ddb79-4ff6-4bc1-df0f-4482b718216f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/6D_pose\n",
            "Already on 'pose_rgb'\n",
            "Your branch is up to date with 'origin/pose_rgb'.\n",
            "HEAD is now at 53b7b93 Update: Pointnet preload\n",
            "/content\n",
            "Updated https://github.com/fraco03/6D_pose.git\n",
            "/content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/content/6D_pose\"\n",
        "branch = \"pose_rgb\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url}\")\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)\n",
        "\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SQ3b58fTYu_g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SQ3b58fTYu_g",
        "outputId": "b823c960-2b24-4c6d-c92c-86ebe0a4281a"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1qQ8ZjUI6QauzFsiF8EpaaI2nKFWna_kQ/view?usp=sharing -O Linemod_preprocessed.zip\n",
        "!unzip Linemod_preprocessed.zip\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "209858ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209858ea",
        "outputId": "9aa2a4a7-b18c-441f-a740-288747fc9cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Drive mounted at /content/drive\n",
            "\n",
            "‚úÖ Setup complete!\n",
            "üìÅ Dataset path: /content/Linemod_preprocessed\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from utils.load_data import mount_drive\n",
        "\n",
        "mount_drive()\n",
        "\n",
        "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\"\n",
        "dataset_root = \"/content/Linemod_preprocessed\"\n",
        "print(f\"\\n‚úÖ Setup complete!\")\n",
        "print(f\"üìÅ Dataset path: {dataset_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bf7c73b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf7c73b5",
        "outputId": "05d51540-96d4-4173-ecd9-be5232845cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plyfile in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from plyfile) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8eae81c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eae81c8",
        "outputId": "340bd5ee-87f4-4e5d-b38e-b482c7c42ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from src.pose_rgb.pointcloud_dataset import LineModPointCloudDataset\n",
        "from src.pose_rgb.pointnet_model import PointNetPose\n",
        "from src.pose_rgb.loss import AutomaticWeightedLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"üî• Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff242eb0",
      "metadata": {
        "id": "ff242eb0"
      },
      "source": [
        "## Notes on the Loss Function\n",
        "Difference between PointNet and RGB approach:\n",
        "\n",
        "- RGB (ResNet + TranslationNet):\n",
        "\n",
        "  * Predicts [dx, dy, log(z)] ‚Üí then applies pinhole projection ‚Üí [X, Y, Z]\n",
        "\n",
        "  * Uses DisentangledTranslationLoss: separates XY from Z\n",
        "\n",
        "  This makes sense because XY depend on the pinhole geometry, whereas Z is independent\n",
        "\n",
        "- PointNet:\n",
        "\n",
        "  * Predicts [X, Y, Z] directly from the point cloud\n",
        "\n",
        "  * Uses a unified loss for translation: treats X, Y, and Z symmetrically\n",
        "\n",
        "  * Since there is no pinhole projection, separating XY from Z is unnecessary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1ac005",
      "metadata": {
        "id": "0f1ac005"
      },
      "source": [
        "## ‚ö° Performance Optimizations\n",
        "\n",
        "**Optimizations applied to accelerate training:**\n",
        "\n",
        "1. **Point reduction**: 1024 ‚Üí 512 points per point cloud (~2x speed-up).\n",
        "2. **Cached YAML files**: `linemod_config` caches `info.yml` and `gt.yml` instead of opening them for every iteration (~10-20x speed-up!).\n",
        "    - **Critical on Google Drive**: I/O latency is extremely high, making caching essential.\n",
        "3. **Torch sampling**: Used `torch.randperm` instead of `np.random.choice` (~1.5x speed-up).\n",
        "4. **Mixed precision**: Automatic FP16/FP32 training with `torch.cuda.amp` (~1.5x speed-up).\n",
        "\n",
        "**Estimated total speed-up: ~20-30x** compared to the initial version! üöÄ\n",
        "\n",
        "**Note**: The first batch may take longer to load and cache all YAML files; subsequent iterations will be significantly faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9722028",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9722028",
        "outputId": "3711693f-50e9-4cd9-fcee-0583b016204f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LineModConfig initialized: /content/Linemod_preprocessed\n",
            "üîÑ Preloading YAML files...\n",
            "‚úÖ Preloaded YAML data for 13 objects\n",
            "üìä Loaded 2373 samples for train split (preload_images=False)\n",
            "üîÑ Preloading YAML files...\n",
            "‚úÖ Preloaded YAML data for 13 objects\n",
            "üìä Loaded 13407 samples for test split (preload_images=False)\n",
            "Train samples: 2373\n",
            "Test samples: 13407\n"
          ]
        }
      ],
      "source": [
        "# Crea dataset con point clouds\n",
        "# Nota: Prediciamo SOLO rotazione, la traslazione viene ricavata da depth + bbox usando pinhole geometry\n",
        "\n",
        "train_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='train',\n",
        "    num_points=512,\n",
        "    use_rgb=True\n",
        ")\n",
        "\n",
        "test_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='test',\n",
        "    num_points=512,\n",
        "    use_rgb=True\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befa5059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "befa5059",
        "outputId": "65814c45-5b0d-45e7-ff6f-f4fbeeb7398c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample keys: dict_keys(['point_cloud', 'bbox_info', 'rotation', 'translation', 'object_id', 'img_id', 'cam_K', 'bbox'])\n",
            "Point cloud shape: torch.Size([512, 6])\n",
            "Rotation shape: (4,)\n",
            "Translation shape: torch.Size([3])\n",
            "\n",
            "Rotation (quat): [ 0.33261785  0.64730227  0.6364495  -0.2555329 ]\n",
            "Translation (m): tensor([-0.1036, -0.0498,  1.0251])\n"
          ]
        }
      ],
      "source": [
        "# Visualizza un sample\n",
        "sample = train_dataset[0]\n",
        "\n",
        "print(\"Sample keys:\", sample.keys())\n",
        "print(f\"Point cloud shape: {sample['point_cloud'].shape}\")  # (512, 6)\n",
        "print(f\"Rotation shape: {sample['rotation'].shape}\")        # (4,)\n",
        "print(f\"Depth Z: {sample['depth_z']:.4f} m\")\n",
        "print(f\"\\nRotation (quat): {sample['rotation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c441ebe0",
      "metadata": {
        "id": "c441ebe0"
      },
      "outputs": [],
      "source": [
        "# DataLoaders - Ottimizzati per performance\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,  # Aumentato da 32 per migliore GPU utilization\n",
        "    shuffle=True,\n",
        "    num_workers=2,  # Aumentato da 2\n",
        "    pin_memory=True  # Velocizza transfer CPU->GPU\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "54dbb9a9",
      "metadata": {
        "id": "54dbb9a9"
      },
      "outputs": [],
      "source": [
        "# Import visualization utilities\n",
        "from utils.projection_utils import visualize_pose_comparison\n",
        "from utils.linemod_config import get_linemod_config\n",
        "from utils.projection_utils import setup_projection_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Config per caricare modelli 3D\n",
        "config = get_linemod_config(dataset_root)\n",
        "setup_projection_utils(dataset_root)\n",
        "\n",
        "def visualize_training_sample(model, dataset, dataset_root, checkpoint_dir, epoch, device='cuda'):\n",
        "    \"\"\"\n",
        "    Visualizza una predizione casuale e la salva velocemente in /tmp, poi copia su Drive.\n",
        "    \"\"\"\n",
        "    import shutil\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Sample casuale\n",
        "    idx = np.random.randint(0, len(dataset))\n",
        "    sample = dataset[idx]\n",
        "\n",
        "    obj_id = sample['object_id']\n",
        "    img_id = sample['img_id']\n",
        "\n",
        "    # Carica immagine originale\n",
        "    img_path = Path(dataset_root) / \"data\" / f\"{obj_id:02d}\" / \"rgb\" / f\"{img_id:04d}.png\"\n",
        "    image = cv2.imread(str(img_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Prepare input\n",
        "    point_cloud = sample['point_cloud'].unsqueeze(0).to(device)\n",
        "    bbox_info = sample['bbox_info'].unsqueeze(0).to(device)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        pred_rot, pred_trans = model(point_cloud, bbox_info)\n",
        "\n",
        "    # Convert to numpy\n",
        "\n",
        "    pred_rot = pred_rot.squeeze(0).cpu().numpy()\n",
        "    pred_trans = pred_trans.squeeze(0).cpu().numpy()\n",
        "    if hasattr(sample['rotation'], 'numpy'):\n",
        "      gt_rot = sample['rotation'].numpy()\n",
        "    else:\n",
        "      gt_rot = sample['rotation']\n",
        "\n",
        "    if hasattr(sample['translation'], 'numpy'):\n",
        "      gt_trans = sample['translation'].numpy()\n",
        "    else:\n",
        "      gt_trans = sample['translation']\n",
        "    cam_K = sample['cam_K'].numpy()\n",
        "\n",
        "    # Visualizza\n",
        "    img_vis = visualize_pose_comparison(\n",
        "        image, obj_id, cam_K,\n",
        "        gt_rot, gt_trans,\n",
        "        pred_rot, pred_trans\n",
        "    )\n",
        "\n",
        "    # Calcola errori\n",
        "    trans_error = np.linalg.norm(gt_trans - pred_trans)\n",
        "    dot_product = np.abs(np.dot(pred_rot, gt_rot))\n",
        "    dot_product = np.clip(dot_product, -1.0, 1.0)\n",
        "    angle_error = 2 * np.arccos(dot_product) * 180 / np.pi\n",
        "\n",
        "    # SALVA PRIMA IN /tmp (VELOCE - RAM disk)\n",
        "    tmp_path = f\"/tmp/vis_epoch_{epoch:03d}_obj_{obj_id:02d}.png\"\n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(img_vis)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Object {obj_id} | Sample {idx} | Trans Err: {trans_error:.4f}m | Angle Err: {angle_error:.2f}¬∞\")\n",
        "    plt.savefig(tmp_path, bbox_inches='tight', dpi=100)\n",
        "    plt.close()\n",
        "\n",
        "    # POI COPIA SU DRIVE (pi√π lento, ma asincrono dopo)\n",
        "    vis_dir = Path(checkpoint_dir) / \"visualizations\"\n",
        "    vis_dir.mkdir(exist_ok=True)\n",
        "    drive_path = vis_dir / f\"epoch_{epoch:03d}_obj_{obj_id:02d}.png\"\n",
        "    shutil.copy(tmp_path, str(drive_path))\n",
        "\n",
        "    print(f\"‚úÖ Saved: epoch {epoch} | Trans Err: {trans_error:.4f}m | Angle Err: {angle_error:.2f}¬∞\")\n",
        "\n",
        "    model.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dcaf4309",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaf4309",
        "outputId": "3621dc62-0a13-4517-ac8e-0e5e8a4cc5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üî• STARTING POINTNET TRAINING on cuda...\n",
            "üìÅ Checkpoints: /content/drive/MyDrive/runs/pointnet_20251217_222800\n",
            "‚öôÔ∏è  Loss mode: Unified Translation (no XY/Z separation)\n",
            "‚ö° Mixed Precision: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# ==========================================\n",
        "# HYPERPARAMETERS\n",
        "# ==========================================\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50\n",
        "USE_MIXED_PRECISION = True  # Mixed precision for speed-up\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/runs/pointnet_{timestamp}'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize PointNet Model\n",
        "# input_channels=6 because we use [x,y,z,r,g,b]\n",
        "model = PointNetPose(input_channels=6, use_batch_norm=True).to(DEVICE)\n",
        "\n",
        "# Loss for PointNet\n",
        "criterion = AutomaticWeightedLoss(use_disentangled=False).to(DEVICE)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model.parameters()) + list(criterion.parameters()),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# Mixed Precision Scaler\n",
        "scaler = GradScaler('cuda') if USE_MIXED_PRECISION else None\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"\\nüî• STARTING POINTNET TRAINING on {DEVICE}...\")\n",
        "print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"‚öôÔ∏è  Loss mode: Unified Translation (no XY/Z separation)\")\n",
        "print(f\"‚ö° Mixed Precision: {USE_MIXED_PRECISION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c66a224",
      "metadata": {},
      "source": [
        "## üéØ Rotation-Only Model Architecture\n",
        "\n",
        "**Key Insight**: With depth available, we only need to predict **rotation**. Translation is computed directly using pinhole geometry:\n",
        "\n",
        "$$X = \\frac{(c_x - c_x^{intr}) \\cdot Z}{f_x}, \\quad Y = \\frac{(c_y - c_y^{intr}) \\cdot Z}{f_y}, \\quad Z = \\text{depth}[c_x, c_y]$$\n",
        "\n",
        "**Advantages:**\n",
        "- Simpler model (no translation head)\n",
        "- Faster training (only rotation loss)\n",
        "- More stable (depth provides ground truth Z)\n",
        "- Cleaner optimization (one prediction target instead of two)\n",
        "\n",
        "**Dataset returns:**\n",
        "- `point_cloud`: Local point cloud (N√ó3 or N√ó6 with RGB)\n",
        "- `rotation`: Target quaternion\n",
        "- `depth_z`: Z coordinate from depth at bbox center (for inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "lLkxBZJQcTa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkxBZJQcTa3",
        "outputId": "b0ec28f1-f539-4fc5-cbae-9fec997c6c37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'point_cloud': tensor([[-7.6477e-02, -7.7854e-02,  1.1150e+00,  7.4510e-02,  9.4118e-02,\n",
              "           1.6863e-01],\n",
              "         [-9.1665e-02, -8.2356e-02,  1.0040e+00,  5.4118e-01,  2.7059e-01,\n",
              "           1.5686e-01],\n",
              "         [-9.4889e-02, -7.6875e-02,  1.0010e+00,  5.2941e-01,  2.7059e-01,\n",
              "           1.6863e-01],\n",
              "         ...,\n",
              "         [-1.2922e-01,  1.7211e-03,  1.0380e+00,  3.6863e-01,  4.1961e-01,\n",
              "           5.4510e-01],\n",
              "         [-7.3431e-02, -8.9170e-05,  1.0440e+00,  7.2549e-01,  6.7059e-01,\n",
              "           6.3529e-01],\n",
              "         [-1.3987e-01, -8.5092e-02,  1.1080e+00,  4.7059e-01,  4.3529e-01,\n",
              "           3.2157e-01]]),\n",
              " 'bbox_info': tensor([0.4180, 0.4563, 0.0672, 0.1167]),\n",
              " 'rotation': array([ 0.33261785,  0.64730227,  0.6364495 , -0.2555329 ], dtype=float32),\n",
              " 'translation': tensor([-0.1036, -0.0498,  1.0251]),\n",
              " 'object_id': 1,\n",
              " 'img_id': 4,\n",
              " 'cam_K': tensor([[572.4114,   0.0000, 325.2611],\n",
              "         [  0.0000, 573.5704, 242.0490],\n",
              "         [  0.0000,   0.0000,   1.0000]]),\n",
              " 'bbox': tensor([246., 191.,  43.,  56.])}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "659ef393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "659ef393",
        "outputId": "b35276c1-4a0d-43b6-ce6e-a794a34182c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:35<00:00,  1.08it/s, L_Tot=0.26, L_Rot=0.27, L_Trans=0.017]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:46<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 1: Train=0.3383 | Val=0.2694\n",
            "üèÜ New Best Model! (Loss: 0.2694)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:33<00:00,  1.12it/s, L_Tot=0.55, L_Rot=0.55, L_Trans=0.033]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:45<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 2: Train=0.3344 | Val=0.2511\n",
            "üèÜ New Best Model! (Loss: 0.2511)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:36<00:00,  1.05it/s, L_Tot=0.33, L_Rot=0.36, L_Trans=0.012]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:47<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 3: Train=0.3171 | Val=0.2505\n",
            "üèÜ New Best Model! (Loss: 0.2505)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:34<00:00,  1.10it/s, L_Tot=0.35, L_Rot=0.39, L_Trans=0.014]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:47<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 4: Train=0.3071 | Val=0.2296\n",
            "üèÜ New Best Model! (Loss: 0.2296)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:35<00:00,  1.06it/s, L_Tot=0.41, L_Rot=0.45, L_Trans=0.015]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:47<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 5: Train=0.2963 | Val=0.2109\n",
            "üé® Visualizing random validation sample...\n",
            "‚úÖ Saved: epoch 4 | Trans Err: 0.3328m | Angle Err: 112.54¬∞\n",
            "üèÜ New Best Model! (Loss: 0.2109)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:34<00:00,  1.10it/s, L_Tot=0.29, L_Rot=0.33, L_Trans=0.020]\n",
            "Validating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [00:21<00:27,  1.03it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-794608809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mval_pbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_pbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mpoint_clouds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'point_cloud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mbbox_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# TRAINING LOOP (con Mixed Precision)\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- TRAIN PHASE ---\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # Move to device\n",
        "        point_clouds = batch['point_cloud'].to(DEVICE, non_blocking=True)  # (B, N, 6)\n",
        "        bbox_info = batch['bbox_info'].to(DEVICE, non_blocking=True)       # (B, 4)\n",
        "        gt_rot = batch['rotation'].to(DEVICE, non_blocking=True)           # (B, 4)\n",
        "        gt_trans = batch['translation'].to(DEVICE, non_blocking=True)      # (B, 3) in meters\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision Forward + Backward\n",
        "        if USE_MIXED_PRECISION:\n",
        "            with autocast('cuda'):\n",
        "                pred_rot, pred_trans = model(point_clouds, bbox_info)\n",
        "                loss, l_r, l_t, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            pred_rot, pred_trans = model(point_clouds, bbox_info)\n",
        "            loss, l_r, l_t, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'L_Tot': f\"{loss.item():.2f}\",\n",
        "            'L_Rot': f\"{l_r.item():.2f}\",\n",
        "            'L_Trans': f\"{l_t.item():.3f}\"\n",
        "        })\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- VALIDATION PHASE ---\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            point_clouds = batch['point_cloud'].to(DEVICE, non_blocking=True)\n",
        "            bbox_info = batch['bbox_info'].to(DEVICE, non_blocking=True)\n",
        "            gt_rot = batch['rotation'].to(DEVICE, non_blocking=True)\n",
        "            gt_trans = batch['translation'].to(DEVICE, non_blocking=True)\n",
        "\n",
        "            if USE_MIXED_PRECISION:\n",
        "                with autocast('cuda'):\n",
        "                    pred_rot, pred_trans = model(point_clouds, bbox_info)\n",
        "                    loss, _, _, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "            else:\n",
        "                pred_rot, pred_trans = model(point_clouds, bbox_info)\n",
        "                loss, _, _, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0.0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- REPORT & SAVE ---\n",
        "    print(f\"üìä Epoch {epoch+1}: Train={avg_train_loss:.4f} | Val={avg_val_loss:.4f}\")\n",
        "\n",
        "    # --- VISUALIZE RANDOM SAMPLE ---\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      print(f\"üé® Visualizing random validation sample...\")\n",
        "      visualize_training_sample(model, test_dataset, dataset_root, CHECKPOINT_DIR, epoch, DEVICE)\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'criterion_state_dict': criterion.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, \"best_model.pth\"))\n",
        "\n",
        "        print(f\"üèÜ New Best Model! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save last checkpoint\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'criterion_state_dict': criterion.state_dict(),\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_ep{epoch+1}.pth\"))\n",
        "\n",
        "print(\"\\nüéâ TRAINING COMPLETE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbd1b1a",
      "metadata": {
        "id": "cdbd1b1a"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('PointNet Training History')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (log scale)')\n",
        "plt.yscale('log')\n",
        "plt.title('PointNet Training History (Log)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_history.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Training Statistics:\")\n",
        "print(f\"   Best epoch: {best_epoch}\")\n",
        "print(f\"   Best val loss: {best_val_loss:.6f}\")\n",
        "print(f\"   Final train loss: {train_losses[-1]:.6f}\")\n",
        "\n",
        "# Save history\n",
        "history = {\n",
        "    'train_losses': [float(x) for x in train_losses],\n",
        "    'val_losses': [float(x) for x in val_losses],\n",
        "    'best_epoch': int(best_epoch),\n",
        "    'best_val_loss': float(best_val_loss),\n",
        "    'timestamp': timestamp\n",
        "}\n",
        "\n",
        "with open(os.path.join(CHECKPOINT_DIR, 'history.json'), 'w') as f:\n",
        "    json.dump(history, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc8bf1c",
      "metadata": {
        "id": "6cc8bf1c"
      },
      "source": [
        "## Visualize Point Cloud Sample\n",
        "\n",
        "Visualizing point cloud from random point in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e081a4e7",
      "metadata": {
        "id": "e081a4e7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Choose sample\n",
        "sample = train_dataset[100]\n",
        "pc = sample['point_cloud'].numpy()  # (512, 6) [x, y, z, r, g, b]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot 3D points with RGB colors\n",
        "ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2],\n",
        "           c=pc[:, 3:6], s=2, alpha=0.6)\n",
        "\n",
        "ax.set_xlabel('X (m)')\n",
        "ax.set_ylabel('Y (m)')\n",
        "ax.set_zlabel('Z (m)')\n",
        "ax.set_title(f'Point Cloud - Object {sample[\"object_id\"]}')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Object ID: {sample['object_id']}\")\n",
        "print(f\"Rotation (quat): {sample['rotation']}\")\n",
        "print(f\"Translation (m): {sample['translation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xBzdBr4w9w7V",
      "metadata": {
        "id": "xBzdBr4w9w7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
