{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fraco03/6D_pose/blob/pose_rgb/notebooks/pose_rgb/pose_rgb_pointnet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dad8daca",
      "metadata": {
        "id": "dad8daca",
        "outputId": "a31b3035-fe8d-44ed-b89f-36fccfeacce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '6D_pose'...\n",
            "remote: Enumerating objects: 349, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 349 (delta 1), reused 4 (delta 1), pack-reused 334 (from 1)\u001b[K\n",
            "Receiving objects: 100% (349/349), 5.57 MiB | 29.39 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "Cloned https://github.com/fraco03/6D_pose.git\n",
            "/content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/content/6D_pose\"\n",
        "branch = \"pose_rgb\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url}\")\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)\n",
        "\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "209858ea",
      "metadata": {
        "id": "209858ea",
        "outputId": "6a753c13-2f6a-419a-8286-fc712aa62b4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Drive mounted at /content/drive\n",
            "\n",
            "‚úÖ Setup complete!\n",
            "üìÅ Dataset path: /content/drive/MyDrive/Linemod_preprocessed\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from utils.load_data import mount_drive\n",
        "\n",
        "mount_drive()\n",
        "\n",
        "dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\"\n",
        "print(f\"\\n‚úÖ Setup complete!\")\n",
        "print(f\"üìÅ Dataset path: {dataset_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bf7c73b5",
      "metadata": {
        "id": "bf7c73b5",
        "outputId": "4474c7f9-a838-4238-f424-ea758a93c404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plyfile\n",
            "  Downloading plyfile-1.1.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from plyfile) (2.0.2)\n",
            "Downloading plyfile-1.1.3-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8eae81c8",
      "metadata": {
        "id": "8eae81c8",
        "outputId": "900d3003-1352-4930-d99f-11c27394bb6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from src.pose_rgb.pointcloud_dataset import LineModPointCloudDataset\n",
        "from src.pose_rgb.pointnet_model import PointNetPose\n",
        "from src.pose_rgb.loss import AutomaticWeightedLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"üî• Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff242eb0",
      "metadata": {
        "id": "ff242eb0"
      },
      "source": [
        "## üìù Note sulla Loss Function\n",
        "\n",
        "**Differenza tra PointNet e RGB approach:**\n",
        "\n",
        "- **RGB (ResNet + TranslationNet)**:\n",
        "  - Predice `[dx, dy, log(z)]` ‚Üí poi pinhole projection ‚Üí `[X, Y, Z]`\n",
        "  - Usa `DisentangledTranslationLoss`: separa XY da Z\n",
        "  - Ha senso perch√© XY dipendono dalla geometria pinhole, Z √® indipendente\n",
        "\n",
        "- **PointNet**:\n",
        "  - Predice **direttamente** `[X, Y, Z]` dalla point cloud\n",
        "  - Usa loss **unificata** per translation: tratta X, Y, Z simmetricamente\n",
        "  - Non c'√® pinhole projection, quindi non ha senso separare XY da Z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1ac005",
      "metadata": {
        "id": "0f1ac005"
      },
      "source": [
        "## ‚ö° Performance Optimizations\n",
        "\n",
        "**Ottimizzazioni applicate per velocizzare il training:**\n",
        "\n",
        "1. **Riduzione punti**: 1024 ‚Üí 512 punti per point cloud (~2x speed-up)\n",
        "2. **Cached YAML files**: `linemod_config` cacha `info.yml` e `gt.yml` invece di aprirli ogni volta (~10-20x speed-up!)\n",
        "   - **Critico su Google Drive**: I/O latency √® molto alta, caching essenziale\n",
        "3. **Torch sampling**: `torch.randperm` invece di `np.random.choice` (~1.5x speed-up)\n",
        "4. **Mixed precision**: FP16/FP32 automatico con `torch.cuda.amp` (~1.5x speed-up)\n",
        "5. **Batch size**: Aumentato da 32 ‚Üí 64 per migliore GPU utilization\n",
        "6. **DataLoader**: `num_workers=4` + `pin_memory=True` per I/O parallelo\n",
        "\n",
        "**Speed-up totale stimato: ~20-30x** rispetto alla versione iniziale! üöÄ\n",
        "\n",
        "**Nota**: Il primo batch pu√≤ richiedere pi√π tempo per caricare e cachare tutti i YAML files, poi diventa molto pi√π veloce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f9722028",
      "metadata": {
        "id": "f9722028",
        "outputId": "73a986e6-9507-431d-87ae-f4cf8676b25e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ LineModConfig initialized: /content/drive/.shortcut-targets-by-id/1sm0RTmd3Q00Uw99X5cErD8SxrnPrGS6v/Linemod_preprocessed\n",
            "üìä Loaded 2373 samples for train split\n",
            "üìä Loaded 13407 samples for test split\n",
            "Train samples: 2373\n",
            "Test samples: 13407\n"
          ]
        }
      ],
      "source": [
        "# Crea dataset con point clouds\n",
        "# use_rgb=True -> point cloud con 6 canali [x,y,z,r,g,b]\n",
        "# use_rgb=False -> point cloud con 3 canali [x,y,z]\n",
        "\n",
        "train_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='train',\n",
        "    num_points=512,  # Ridotto per speed-up (era 1024)\n",
        "    use_rgb=True      # Include RGB\n",
        ")\n",
        "\n",
        "test_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='test',\n",
        "    num_points=512,\n",
        "    use_rgb=True\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "befa5059",
      "metadata": {
        "id": "befa5059",
        "outputId": "b98b7a21-088c-4511-a49b-b5be03f174d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample keys: dict_keys(['point_cloud', 'rotation', 'translation', 'object_id', 'img_id', 'cam_K', 'bbox'])\n",
            "Point cloud shape: torch.Size([512, 6])\n",
            "Rotation shape: (4,)\n",
            "Translation shape: torch.Size([3])\n",
            "\n",
            "Rotation (quat): [ 0.33261785  0.64730227  0.6364495  -0.2555329 ]\n",
            "Translation (m): tensor([-0.1036, -0.0498,  1.0251])\n"
          ]
        }
      ],
      "source": [
        "# Visualizza un sample\n",
        "sample = train_dataset[0]\n",
        "\n",
        "print(\"Sample keys:\", sample.keys())\n",
        "print(f\"Point cloud shape: {sample['point_cloud'].shape}\")  # (1024, 6)\n",
        "print(f\"Rotation shape: {sample['rotation'].shape}\")        # (4,)\n",
        "print(f\"Translation shape: {sample['translation'].shape}\")  # (3,)\n",
        "print(f\"\\nRotation (quat): {sample['rotation']}\")\n",
        "print(f\"Translation (m): {sample['translation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c441ebe0",
      "metadata": {
        "id": "c441ebe0"
      },
      "outputs": [],
      "source": [
        "# DataLoaders - Ottimizzati per performance\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,  # Aumentato da 32 per migliore GPU utilization\n",
        "    shuffle=True,\n",
        "    num_workers=2,  # Aumentato da 2\n",
        "    pin_memory=True  # Velocizza transfer CPU->GPU\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dcaf4309",
      "metadata": {
        "id": "dcaf4309",
        "outputId": "f4f39a47-d8ed-40fd-af54-0aae19476321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî• STARTING POINTNET TRAINING on cuda...\n",
            "üìÅ Checkpoints: /content/drive/MyDrive/runs/pointnet_20251217_132025\n",
            "‚öôÔ∏è  Loss mode: Unified Translation (no XY/Z separation)\n",
            "‚ö° Mixed Precision: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# ==========================================\n",
        "# HYPERPARAMETERS\n",
        "# ==========================================\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50\n",
        "USE_MIXED_PRECISION = True  # Mixed precision for speed-up\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/runs/pointnet_{timestamp}'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize PointNet Model\n",
        "# input_channels=6 because we use [x,y,z,r,g,b]\n",
        "model = PointNetPose(input_channels=6, use_batch_norm=True).to(DEVICE)\n",
        "\n",
        "# Loss for PointNet\n",
        "criterion = AutomaticWeightedLoss(use_disentangled=False).to(DEVICE)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model.parameters()) + list(criterion.parameters()),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# Mixed Precision Scaler\n",
        "scaler = GradScaler('cuda') if USE_MIXED_PRECISION else None\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"\\nüî• STARTING POINTNET TRAINING on {DEVICE}...\")\n",
        "print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"‚öôÔ∏è  Loss mode: Unified Translation (no XY/Z separation)\")\n",
        "print(f\"‚ö° Mixed Precision: {USE_MIXED_PRECISION}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "659ef393",
      "metadata": {
        "id": "659ef393",
        "outputId": "1283a985-b4c2-439a-ddda-d213260f01c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [18:01<00:00, 28.45s/it, L_Tot=0.56, L_Rot=0.34, L_Trans=0.226]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [24:19<00:00, 29.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 1: Train=0.8885 | Val=0.2928\n",
            "üèÜ New Best Model! (Loss: 0.2928)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:55<00:00,  3.04s/it, L_Tot=0.52, L_Rot=0.49, L_Trans=0.040]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:57<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 2: Train=0.4411 | Val=0.2863\n",
            "üèÜ New Best Model! (Loss: 0.2863)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:54<00:00,  3.01s/it, L_Tot=0.49, L_Rot=0.46, L_Trans=0.040]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:49<00:00,  2.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 3: Train=0.3790 | Val=0.2810\n",
            "üèÜ New Best Model! (Loss: 0.2810)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:53<00:00,  2.98s/it, L_Tot=0.39, L_Rot=0.39, L_Trans=0.025]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:46<00:00,  2.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 4: Train=0.3558 | Val=0.2652\n",
            "üèÜ New Best Model! (Loss: 0.2652)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.22, L_Rot=0.23, L_Trans=0.022]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:46<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 5: Train=0.3371 | Val=0.2618\n",
            "üèÜ New Best Model! (Loss: 0.2618)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.37, L_Rot=0.35, L_Trans=0.058]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:46<00:00,  2.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 6: Train=0.3254 | Val=0.2487\n",
            "üèÜ New Best Model! (Loss: 0.2487)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.54, L_Rot=0.57, L_Trans=0.016]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:47<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 7: Train=0.3222 | Val=0.2417\n",
            "üèÜ New Best Model! (Loss: 0.2417)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:53<00:00,  2.98s/it, L_Tot=0.60, L_Rot=0.61, L_Trans=0.032]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 8: Train=0.3177 | Val=0.2352\n",
            "üèÜ New Best Model! (Loss: 0.2352)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:51<00:00,  2.94s/it, L_Tot=0.37, L_Rot=0.40, L_Trans=0.020]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 9: Train=0.2984 | Val=0.2183\n",
            "üèÜ New Best Model! (Loss: 0.2183)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:51<00:00,  2.94s/it, L_Tot=0.11, L_Rot=0.17, L_Trans=0.006]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 10: Train=0.2823 | Val=0.2252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.36, L_Rot=0.42, L_Trans=0.012]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 11: Train=0.2836 | Val=0.1998\n",
            "üèÜ New Best Model! (Loss: 0.1998)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:51<00:00,  2.94s/it, L_Tot=0.15, L_Rot=0.22, L_Trans=0.008]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 12: Train=0.2662 | Val=0.1936\n",
            "üèÜ New Best Model! (Loss: 0.1936)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.95s/it, L_Tot=0.31, L_Rot=0.38, L_Trans=0.012]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 13: Train=0.2590 | Val=0.1683\n",
            "üèÜ New Best Model! (Loss: 0.1683)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.97s/it, L_Tot=0.55, L_Rot=0.62, L_Trans=0.007]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 14: Train=0.2588 | Val=0.1567\n",
            "üèÜ New Best Model! (Loss: 0.1567)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.95s/it, L_Tot=0.16, L_Rot=0.24, L_Trans=0.027]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:43<00:00,  2.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 15: Train=0.2374 | Val=0.1516\n",
            "üèÜ New Best Model! (Loss: 0.1516)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:51<00:00,  2.94s/it, L_Tot=0.26, L_Rot=0.35, L_Trans=0.014]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 16: Train=0.2227 | Val=0.1392\n",
            "üèÜ New Best Model! (Loss: 0.1392)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.25, L_Rot=0.35, L_Trans=0.014]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 17: Train=0.2234 | Val=0.1587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.04, L_Rot=0.17, L_Trans=0.005]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 18: Train=0.2004 | Val=0.1101\n",
            "üèÜ New Best Model! (Loss: 0.1101)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.15, L_Rot=0.27, L_Trans=0.008]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:43<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 19: Train=0.1921 | Val=0.0962\n",
            "üèÜ New Best Model! (Loss: 0.0962)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.97s/it, L_Tot=0.14, L_Rot=0.27, L_Trans=0.003]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 20: Train=0.1838 | Val=0.0897\n",
            "üèÜ New Best Model! (Loss: 0.0897)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.09, L_Rot=0.22, L_Trans=0.013]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:43<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 21: Train=0.1674 | Val=0.0777\n",
            "üèÜ New Best Model! (Loss: 0.0777)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.97s/it, L_Tot=0.11, L_Rot=0.25, L_Trans=0.011]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 22: Train=0.1499 | Val=0.1140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.14, L_Rot=0.29, L_Trans=0.004]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:43<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 23: Train=0.1462 | Val=0.0697\n",
            "üèÜ New Best Model! (Loss: 0.0697)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.97s/it, L_Tot=0.22, L_Rot=0.36, L_Trans=0.011]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 24: Train=0.1220 | Val=0.0255\n",
            "üèÜ New Best Model! (Loss: 0.0255)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.96s/it, L_Tot=0.31, L_Rot=0.45, L_Trans=0.010]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:43<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 25: Train=0.1160 | Val=0.0624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [01:52<00:00,  2.97s/it, L_Tot=0.19, L_Rot=0.35, L_Trans=0.004]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:50<00:00,  2.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 26: Train=0.1065 | Val=0.0333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50 [Train]:   5%|‚ñå         | 2/38 [01:01<18:28, 30.79s/it, L_Tot=0.07, L_Rot=0.24, L_Trans=0.006]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1307734309.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpoint_clouds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'point_cloud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, N, 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# TRAINING LOOP (con Mixed Precision)\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- TRAIN PHASE ---\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # Move to device\n",
        "        point_clouds = batch['point_cloud'].to(DEVICE, non_blocking=True)  # (B, N, 6)\n",
        "        gt_rot = batch['rotation'].to(DEVICE, non_blocking=True)           # (B, 4)\n",
        "        gt_trans = batch['translation'].to(DEVICE, non_blocking=True)      # (B, 3) in meters\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision Forward + Backward\n",
        "        if USE_MIXED_PRECISION:\n",
        "            with autocast('cuda'):\n",
        "                pred_rot, pred_trans = model(point_clouds)\n",
        "                loss, l_r, l_t, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            pred_rot, pred_trans = model(point_clouds)\n",
        "            loss, l_r, l_t, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'L_Tot': f\"{loss.item():.2f}\",\n",
        "            'L_Rot': f\"{l_r.item():.2f}\",\n",
        "            'L_Trans': f\"{l_t.item():.3f}\"\n",
        "        })\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- VALIDATION PHASE ---\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            point_clouds = batch['point_cloud'].to(DEVICE, non_blocking=True)\n",
        "            gt_rot = batch['rotation'].to(DEVICE, non_blocking=True)\n",
        "            gt_trans = batch['translation'].to(DEVICE, non_blocking=True)\n",
        "\n",
        "            if USE_MIXED_PRECISION:\n",
        "                with autocast('cuda'):\n",
        "                    pred_rot, pred_trans = model(point_clouds)\n",
        "                    loss, _, _, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "            else:\n",
        "                pred_rot, pred_trans = model(point_clouds)\n",
        "                loss, _, _, _ = criterion(pred_rot, gt_rot, pred_trans, gt_trans)\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0.0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- REPORT & SAVE ---\n",
        "    print(f\"üìä Epoch {epoch+1}: Train={avg_train_loss:.4f} | Val={avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'criterion_state_dict': criterion.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, \"best_model.pth\"))\n",
        "\n",
        "        print(f\"üèÜ New Best Model! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save last checkpoint\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'criterion_state_dict': criterion.state_dict(),\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_ep{epoch+1}.pth\"))\n",
        "\n",
        "print(\"\\nüéâ TRAINING COMPLETE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbd1b1a",
      "metadata": {
        "id": "cdbd1b1a"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('PointNet Training History')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (log scale)')\n",
        "plt.yscale('log')\n",
        "plt.title('PointNet Training History (Log)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_history.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Training Statistics:\")\n",
        "print(f\"   Best epoch: {best_epoch}\")\n",
        "print(f\"   Best val loss: {best_val_loss:.6f}\")\n",
        "print(f\"   Final train loss: {train_losses[-1]:.6f}\")\n",
        "\n",
        "# Save history\n",
        "history = {\n",
        "    'train_losses': [float(x) for x in train_losses],\n",
        "    'val_losses': [float(x) for x in val_losses],\n",
        "    'best_epoch': int(best_epoch),\n",
        "    'best_val_loss': float(best_val_loss),\n",
        "    'timestamp': timestamp\n",
        "}\n",
        "\n",
        "with open(os.path.join(CHECKPOINT_DIR, 'history.json'), 'w') as f:\n",
        "    json.dump(history, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc8bf1c",
      "metadata": {
        "id": "6cc8bf1c"
      },
      "source": [
        "## Visualize Point Cloud Sample\n",
        "\n",
        "Visualizing point cloud from random point in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e081a4e7",
      "metadata": {
        "id": "e081a4e7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Choose sample\n",
        "sample = train_dataset[100]\n",
        "pc = sample['point_cloud'].numpy()  # (512, 6) [x, y, z, r, g, b]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot 3D points with RGB colors\n",
        "ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2],\n",
        "           c=pc[:, 3:6], s=2, alpha=0.6)\n",
        "\n",
        "ax.set_xlabel('X (m)')\n",
        "ax.set_ylabel('Y (m)')\n",
        "ax.set_zlabel('Z (m)')\n",
        "ax.set_title(f'Point Cloud - Object {sample[\"object_id\"]}')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Object ID: {sample['object_id']}\")\n",
        "print(f\"Rotation (quat): {sample['rotation']}\")\n",
        "print(f\"Translation (m): {sample['translation']}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}