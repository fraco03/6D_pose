{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oAXrKjNq32c",
        "outputId": "18b06df5-2594-43f9-dade-e6187644f8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6D_pose'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 174 (delta 87), reused 113 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 2.23 MiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Cloned https://github.com/fraco03/6D_pose.git to /content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown -q\n",
        "print(\"Downloading folder from Drive...\")\n",
        "# Downloads the folder structure containing the Linemod dataset\n",
        "!gdown \"https://drive.google.com/file/d/1Zwh-gAk_-CBgpOcNLPLdFNxggi3NTh-S/view?usp=drive_link\" --fuzzy\n",
        "import glob\n",
        "zip_files = glob.glob(\"**/Linemod_preprocessed.zip\", recursive=True)\n",
        "\n",
        "if zip_files:\n",
        "    zip_path = zip_files[0]\n",
        "    print(f\"Unzipping {zip_path}...\")\n",
        "    !unzip -q -o \"{zip_path}\"\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"Error: Linemod_preprocessed.zip not found. Check the download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
        "branch = \"main\"\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancella tutte le cartelle __pycache__ ricorsivamente nella directory di lavoro\n",
        "!find . -name \"__pycache__\" -type d -exec rm -rf {} +\n",
        "print(\"üóëÔ∏è Cache pulita dal disco.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea5j56JR7NjI"
      },
      "outputs": [],
      "source": [
        "!pip install plyfile\n",
        "from src.pose_rgb.dataset import LineModPoseDataset\n",
        "from src.pose_rgb.model import ResNetRotation, TranslationNet\n",
        "from src.pose_rgb.pose_utils import quaternion_to_rotation_matrix, convert_rotation_to_quaternion, inverse_pinhole_projection\n",
        "from src.pose_rgb.test_dataset import *\n",
        "from src.pose_rgb.loss import CombinedPoseLoss, MultiObjectPointMatchingLoss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pathlib\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from utils.projection_utils import *\n",
        "from utils.linemod_config import *\n",
        "from metrics import compute_ADD_metric_quaternion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrOmeFj_sRID",
        "outputId": "d3a4e969-a16f-4f10-ac1a-e0ffe7eb5e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded LineModPoseDataset\n",
            "   Split: train\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 3631\n",
            " Loaded LineModPoseDataset\n",
            "   Split: test\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 20528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/kaggle/input/line-mode/Linemod_preprocessed' #Modify here for kaggle\n",
        "\n",
        "train_dataset = LineModPoseDataset(split='train', root_dir=root_dir)\n",
        "test_dataset = LineModPoseDataset(split='test', root_dir=root_dir)\n",
        "\n",
        "#Dataloder\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import os\n",
        "\n",
        "def load_all_object_points(models_dir, valid_obj_ids, num_points=1000):\n",
        "    \"\"\"\n",
        "    Loads .ply files for ALL objects and stacks them into a single Tensor.\n",
        "    \n",
        "    Args:\n",
        "        models_dir (str): Folder containing .ply files (e.g., 'obj_01.ply').\n",
        "        valid_obj_ids (list): List of integers IDs (e.g., [1, 5, 6...]).\n",
        "        num_points (int): Number of points to sample per object.\n",
        "        \n",
        "    Returns:\n",
        "        torch.Tensor: Shape (Num_Classes, num_points, 3).\n",
        "                      The index in dimension 0 corresponds to the index in valid_obj_ids.\n",
        "    \"\"\"\n",
        "    all_points_list = []\n",
        "    \n",
        "    print(f\"üì¶ Loading {len(valid_obj_ids)} 3D models from {models_dir}...\")\n",
        "    \n",
        "    for i, obj_id in enumerate(valid_obj_ids):\n",
        "        # Construct filename assuming LineMod format (e.g., 'obj_01.ply')\n",
        "        ply_name = f\"obj_{obj_id:02d}.ply\" \n",
        "        ply_path = os.path.join(models_dir, ply_name)\n",
        "        \n",
        "        if not os.path.exists(ply_path):\n",
        "            raise FileNotFoundError(f\"Model not found: {ply_path}\")\n",
        "\n",
        "        # Load mesh\n",
        "        mesh = trimesh.load(ply_path)\n",
        "        vertices = np.array(mesh.vertices)\n",
        "        \n",
        "        # Sample points\n",
        "        if len(vertices) > num_points:\n",
        "            idx = np.random.choice(len(vertices), num_points, replace=False)\n",
        "            selected = vertices[idx]\n",
        "        else:\n",
        "            # Padding via repetition if not enough points (rare in LineMod)\n",
        "            choice = np.random.choice(len(vertices), num_points, replace=True)\n",
        "            selected = vertices[choice]\n",
        "            \n",
        "        # Add to list\n",
        "        all_points_list.append(selected)\n",
        "\n",
        "    # Stack into a single tensor\n",
        "    # Shape: (Num_Classes, Num_Points, 3)\n",
        "    # Example: (13, 1000, 3)\n",
        "    bank_tensor = torch.from_numpy(np.array(all_points_list)).float()\n",
        "    \n",
        "    # Unit conversion (mm to meters) if needed\n",
        "    # bank_tensor = bank_tensor / 1000.0 \n",
        "    \n",
        "    return bank_tensor / 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LINEMOD_NAMES = [\n",
        "            'ape',         # Index 0 (ID 1)\n",
        "            'benchvise',   # Index 1 (ID 2)\n",
        "            'camera',      # Index 2 (ID 4)\n",
        "            'can',         # Index 3 (ID 5)\n",
        "            'cat',         # Index 4 (ID 6)\n",
        "            'driller',     # Index 5 (ID 8)\n",
        "            'duck',        # Index 6 (ID 9)\n",
        "            'eggbox',      # Index 7 (ID 10)\n",
        "            'glue',        # Index 8 (ID 11)\n",
        "            'holepuncher', # Index 9 (ID 12)\n",
        "            'iron',        # Index 10 (ID 13)\n",
        "            'lamp',        # Index 11 (ID 14)\n",
        "            'phone'        # Index 12 (ID 15)\n",
        "        ]\n",
        "name_to_idx = {name: i for i, name in enumerate(LINEMOD_NAMES)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONLY ROTATION TRAINING SCRIPT\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & HYPERPARAMETERS\n",
        "# ==========================================\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# --- PATHS ---\n",
        "# Define where your .ply models are located\n",
        "MODELS_DIR = '/content/data/Linemod_preprocessed/models' \n",
        "# List of valid object IDs in your dataset (must match your dataset logic)\n",
        "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
        "\n",
        "# --- LOGGING SETUP ---\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "# Directory to save checkpoints and logs\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/runs/rotation_only_{timestamp}' \n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "run_dir = CHECKPOINT_DIR\n",
        "\n",
        "print(f\"\\nüî• STARTING ROTATION-ONLY TRAINING on {DEVICE}...\")\n",
        "print(f\"üìÅ Saving outputs to: {run_dir}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. INITIALIZE LOSS & MODELS\n",
        "# ==========================================\n",
        "\n",
        "# A. LOAD 3D POINTS FOR LOSS\n",
        "# We need to load the point clouds for all objects to use PointMatchingLoss.\n",
        "print(\"üì¶ Loading 3D Point Clouds for Loss Function...\")\n",
        "# Use the helper function we defined earlier to load all ply files\n",
        "point_bank = load_all_object_points(MODELS_DIR, VALID_OBJ_IDS, num_points=1000)\n",
        "point_bank = point_bank.to(DEVICE) # Move entire bank to GPU\n",
        "\n",
        "\n",
        "# B. DEFINE LOSS FUNCTION\n",
        "\n",
        "criterion = MultiObjectPointMatchingLoss(point_bank).to(DEVICE)\n",
        "\n",
        "# C. INITIALIZE MODEL\n",
        "# We only use the Rotation Network\n",
        "model_rot = ResNetRotation(freeze_backbone=True).to(DEVICE)\n",
        "\n",
        "# D. OPTIMIZER\n",
        "# We only optimize the rotation model parameters\n",
        "optimizer = optim.Adam(\n",
        "    model_rot.parameters(),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# E. METRICS STORAGE\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- A. TRAIN PHASE ---\n",
        "    model_rot.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    # Progress Bar\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # 1. Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)\n",
        "        gt_rot = batch['rotation'].to(DEVICE)\n",
        "        \n",
        "        # We need class indices for the PointMatchingLoss (Index 0 to 12)\n",
        "        # Ensure your Dataset returns 'class_id' as a mapped index (0..N), NOT the raw Linemod ID (1,5,8..)\n",
        "        class_ids = batch['class_id'].to(DEVICE) \n",
        "\n",
        "        # 2. Forward Pass\n",
        "        pred_rot = model_rot(imgs)\n",
        "\n",
        "        # 3. Calculate Loss\n",
        "        # Pass class_ids so the loss knows which 3D model to use for each image in the batch\n",
        "        if point_bank is not None:\n",
        "            loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "        else:\n",
        "            loss = criterion(pred_rot, gt_rot) # Fallback doesn't use IDs\n",
        "\n",
        "        # 4. Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 5. Logging\n",
        "        running_train_loss += loss.item()\n",
        "        pbar.set_postfix({'ADD Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- B. EVALUATION PHASE ---\n",
        "    model_rot.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50  # Validate on a subset to save time per epoch\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            gt_rot = batch['rotation'].to(DEVICE)\n",
        "            class_ids = batch['class_id'].to(DEVICE)\n",
        "\n",
        "            # Forward\n",
        "            pred_rot = model_rot(imgs)\n",
        "\n",
        "            # Loss\n",
        "            if point_bank is not None:\n",
        "                loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "            else:\n",
        "                loss = criterion(pred_rot, gt_rot)\n",
        "                \n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- C. REPORT & SAVE ---\n",
        "    print(f\"üìä Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save Best Model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        save_path = os.path.join(CHECKPOINT_DIR, \"best_model_rot.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, save_path)\n",
        "        print(f\"üèÜ New Best Rotation Model Saved! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save Last Checkpoint (for resuming if needed)\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'val_loss': avg_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_last.pth\"))\n",
        "\n",
        "# --- D. PLOTTING ---\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss (ADD Metric)')\n",
        "plt.plot(val_losses, label='Val Loss (ADD Metric)')\n",
        "plt.title('Rotation Training Convergence')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Distance (m)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'rotation_training_curve.png'))\n",
        "print(\"üéâ TRAINING COMPLETE! Training curve saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import trimesh\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure compute_ADD_metric_quaternion is imported or defined in your notebook\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD 3D MODELS AND DIAMETERS\n",
        "# ==========================================\n",
        "def load_models_info(models_dir, obj_ids, num_points=1000):\n",
        "    \"\"\"\n",
        "    Loads 3D meshes and calculates the DIAMETER for each object.\n",
        "    Returns:\n",
        "        point_cache: {id: points (N, 3)}\n",
        "        diameters:   {id: diameter (float)}\n",
        "    \"\"\"\n",
        "    point_cache = {}\n",
        "    diameters = {}\n",
        "    \n",
        "    unique_ids = sorted(list(set(obj_ids)))\n",
        "    print(f\"‚è≥ Loading info for {len(unique_ids)} 3D models...\")\n",
        "    \n",
        "    for oid in tqdm(unique_ids, desc=\"Mesh Analysis\"):\n",
        "        filename = f\"obj_{int(oid):02d}.ply\"\n",
        "        path = os.path.join(models_dir, filename)\n",
        "        \n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                mesh = trimesh.load(path)\n",
        "                \n",
        "                # 1. Sample Points (for ADD calculation)\n",
        "                points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
        "                point_cache[oid] = points / 1000.0 # Convert mm -> Meters\n",
        "                \n",
        "                # 2. Calculate Diameter (for Accuracy threshold)\n",
        "                # Standard LineMod method: Diagonal of the Bounding Box\n",
        "                extents = mesh.extents / 1000.0 # Meters\n",
        "                diameter = np.linalg.norm(extents)\n",
        "                diameters[oid] = diameter\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error loading {filename}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Missing model file: {path}\")\n",
        "            \n",
        "    return point_cache, diameters\n",
        "\n",
        "# ==========================================\n",
        "# 2. PANDAS EVALUATION FUNCTION\n",
        "# ==========================================\n",
        "def evaluate_with_pandas(model_rot, dataloader, device, models_dir, model_trans=None):\n",
        "    model_rot.eval()\n",
        "    if model_trans: model_trans.eval()\n",
        "    \n",
        "    # 1. Get unique IDs from the dataset to load specific meshes\n",
        "    try:\n",
        "        # Try to extract IDs from dataset if iterable\n",
        "        all_obj_ids = [s['object_id'] for s in dataloader.dataset]\n",
        "    except:\n",
        "        # Fallback if dataset is complex\n",
        "        all_obj_ids = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "\n",
        "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
        "    \n",
        "    # List to accumulate raw results\n",
        "    raw_results = []\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Benchmark (ADD Error + Accuracy)...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Inference\"):\n",
        "            # Move data to GPU\n",
        "            imgs = batch['image'].to(device)\n",
        "            gt_quats = batch['rotation'].to(device)\n",
        "            gt_trans = batch['translation'].to(device)\n",
        "            obj_ids = batch['object_id'] # CPU tensor\n",
        "            \n",
        "            # Predict Rotation\n",
        "            pred_quats = model_rot(imgs)\n",
        "            \n",
        "            # Predict Translation (or use GT)\n",
        "            if model_trans:\n",
        "                if 'bbox_info' in batch:\n",
        "                    bbox_info = batch['bbox_info'].to(device)\n",
        "                    pred_trans_batch = model_trans(imgs, bbox_info)\n",
        "                else:\n",
        "                    pred_trans_batch = gt_trans\n",
        "            else:\n",
        "                pred_trans_batch = gt_trans # Fallback to GT to test rotation only\n",
        "\n",
        "            # Convert to Numpy for metric calculation\n",
        "            pred_quats_np = pred_quats.cpu().numpy()\n",
        "            pred_trans_np = pred_trans_batch.cpu().numpy()\n",
        "            gt_quats_np = gt_quats.cpu().numpy()\n",
        "            gt_trans_np = gt_trans.cpu().numpy()\n",
        "            \n",
        "            # Loop through batch samples\n",
        "            batch_size = imgs.shape[0]\n",
        "            for i in range(batch_size):\n",
        "                curr_id = int(obj_ids[i])\n",
        "                \n",
        "                # Skip if we don't have 3D info for this object\n",
        "                if curr_id not in points_dict: \n",
        "                    continue\n",
        "                \n",
        "                # --- CALCULATE ADD METRIC (in Meters) ---\n",
        "                add_error = compute_ADD_metric_quaternion(\n",
        "                    model_points=points_dict[curr_id],\n",
        "                    gt_quat=gt_quats_np[i],\n",
        "                    gt_translation=gt_trans_np[i],\n",
        "                    pred_quat=pred_quats_np[i],\n",
        "                    pred_translation=pred_trans_np[i]\n",
        "                )\n",
        "                \n",
        "                # --- CALCULATE THRESHOLD & ACCURACY ---\n",
        "                diam = diameters_dict[curr_id]\n",
        "                threshold = diam * 0.1 # 10% of diameter\n",
        "                is_correct = add_error < threshold\n",
        "                \n",
        "                # Save raw result\n",
        "                raw_results.append({\n",
        "                    'obj_id': curr_id,\n",
        "                    'diameter_cm': diam * 100,\n",
        "                    'add_error_m': add_error,\n",
        "                    'add_error_cm': add_error * 100,\n",
        "                    'threshold_cm': threshold * 100,\n",
        "                    'is_correct': is_correct\n",
        "                })\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. GENERATE PANDAS REPORT\n",
        "    # ==========================================\n",
        "    if not raw_results:\n",
        "        print(\"‚ùå No results collected. Check your dataloader or model paths.\")\n",
        "        return None, None\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(raw_results)\n",
        "    \n",
        "    # Group by Object ID and calculate stats\n",
        "    report = df.groupby('obj_id').agg(\n",
        "        Samples=('obj_id', 'count'),\n",
        "        Diameter_cm=('diameter_cm', 'first'), \n",
        "        Mean_Error_cm=('add_error_cm', 'mean'),\n",
        "        Accuracy_pct=('is_correct', 'mean') # Mean of booleans is percentage\n",
        "    )\n",
        "    \n",
        "    # Format Accuracy column (0.69 -> 69.0)\n",
        "    report['Accuracy_pct'] = report['Accuracy_pct'] * 100\n",
        "    \n",
        "    # --- PRINT TABLE ---\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä DETAILED REPORT BY OBJECT\")\n",
        "    print(\"=\"*60)\n",
        "    # Use pandas to_string for nice formatting\n",
        "    print(report.to_string(float_format=\"{:.2f}\".format))\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # --- CALCULATE GLOBAL METRICS ---\n",
        "    total_correct = df['is_correct'].sum()\n",
        "    total_samples = len(df)\n",
        "    global_acc = (total_correct / total_samples) * 100\n",
        "    global_err = df['add_error_cm'].mean()\n",
        "    \n",
        "    print(f\"\\nüèÜ GLOBAL RESULTS (Entire Dataset)\")\n",
        "    print(f\"   ‚û§ Total Samples:       {total_samples}\")\n",
        "    print(f\"   ‚û§ Mean Error (ADD):    {global_err:.2f} cm\")\n",
        "    print(f\"   ‚û§ Accuracy (ADD-0.1d): {global_acc:.2f} %\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return report, df \n",
        "\n",
        "# --- USAGE EXAMPLE ---\n",
        "MODELS_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed/models'\n",
        "\n",
        "# Make sure 'compute_ADD_metric_quaternion' is defined before running\n",
        "# report_df, raw_df = evaluate_with_pandas(model_rot, test_loader, DEVICE, MODELS_ROOT, model_trans=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ5chic6sfwz",
        "outputId": "3b3b2072-0d84-40f3-9284-2fc7bc04a33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîí ResNet backbone frozen.\n",
            "\n",
            "üî• STARTING TRAINING on cuda...\n",
            "üìÅ Saving outputs to: /content/drive/MyDrive/runs/20251213_004202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1/50 [Train]:   0%|          | 0/114 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:02<00:00,  1.83it/s, Loss=0.3977]\n",
            "Epoch 1/50 [Eval]: 50it [00:30,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 1 Summary: Train Loss: 0.4218 | Val Loss: 0.3150\n",
            "üèÜ New Best Model Saved! (Loss: 0.3150)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:04<00:00,  1.76it/s, Loss=0.2665]\n",
            "Epoch 2/50 [Eval]: 50it [00:29,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 2 Summary: Train Loss: 0.3212 | Val Loss: 0.2930\n",
            "üèÜ New Best Model Saved! (Loss: 0.2930)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:02<00:00,  1.82it/s, Loss=0.1571]\n",
            "Epoch 3/50 [Eval]: 50it [00:28,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 3 Summary: Train Loss: 0.2763 | Val Loss: 0.2508\n",
            "üèÜ New Best Model Saved! (Loss: 0.2508)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:03<00:00,  1.79it/s, Loss=0.1487]\n",
            "Epoch 4/50 [Eval]: 50it [00:29,  1.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 4 Summary: Train Loss: 0.2377 | Val Loss: 0.2504\n",
            "üèÜ New Best Model Saved! (Loss: 0.2504)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:03<00:00,  1.81it/s, Loss=0.1513]\n",
            "Epoch 5/50 [Eval]: 50it [00:30,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 5 Summary: Train Loss: 0.2145 | Val Loss: 0.2231\n",
            "üèÜ New Best Model Saved! (Loss: 0.2231)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:03<00:00,  1.80it/s, Loss=0.1081]\n",
            "Epoch 6/50 [Eval]: 50it [00:28,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 6 Summary: Train Loss: 0.1907 | Val Loss: 0.2144\n",
            "üèÜ New Best Model Saved! (Loss: 0.2144)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [01:03<00:00,  1.79it/s, Loss=0.2181]\n",
            "Epoch 7/50 [Eval]: 50it [00:29,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Epoch 7 Summary: Train Loss: 0.1767 | Val Loss: 0.2007\n",
            "üèÜ New Best Model Saved! (Loss: 0.2007)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50 [Train]:  14%|‚ñà‚ñç        | 16/114 [00:09<00:43,  2.26it/s, Loss=0.1241]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & HYPERPARAMETERS\n",
        "# ==========================================\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# Creiamo una cartella specifica per questo run usando il timestamp\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/runs/{timestamp}' # modify here for kaggle\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Assegno run_dir per compatibilit√† col tuo codice di plot\n",
        "run_dir = CHECKPOINT_DIR\n",
        "\n",
        "# Initialize Models\n",
        "model_rot = ResNetRotation(freeze_backbone=True).to(DEVICE)\n",
        "model_trans = TranslationNet().to(DEVICE)\n",
        "\n",
        "# Initialize Loss & Optimizer\n",
        "criterion = CombinedPoseLoss(w_rot=1.0, w_trans=1.0).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    list(model_rot.parameters()) + list(model_trans.parameters()),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"\\nüî• STARTING TRAINING on {DEVICE}...\")\n",
        "print(f\"üìÅ Saving outputs to: {run_dir}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAINING LOOP\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- A. TRAIN PHASE ---\n",
        "    model_rot.train()\n",
        "    model_trans.train()\n",
        "\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    # Progress Bar for Training\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)\n",
        "        bbox_info = batch['bbox_info'].to(DEVICE)\n",
        "        gt_rot = batch['rotation'].to(DEVICE)\n",
        "        gt_trans_abs = batch['translation'].to(DEVICE)\n",
        "        cam_K = batch['cam_K'].to(DEVICE)\n",
        "        bbox_centers = batch['bbox_center'].to(DEVICE)\n",
        "\n",
        "        # Forward Pass\n",
        "        pred_rot = model_rot(imgs)\n",
        "        pred_trans = model_trans(imgs, bbox_info)\n",
        "\n",
        "        # Back-Projection\n",
        "        pred_deltas = pred_trans[:, :2]\n",
        "        pred_z = pred_trans[:, 2]\n",
        "        pred_3d_real = inverse_pinhole_projection(\n",
        "            crop_center=bbox_centers,\n",
        "            deltas=pred_deltas,\n",
        "            z=pred_z * 1000,    # Convert to mm\n",
        "            cam_K=cam_K\n",
        "        )\n",
        "\n",
        "        # Loss & Backprop\n",
        "        loss, l_r, l_t = criterion(pred_rot, gt_rot, pred_3d_real, gt_trans_abs)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        pbar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- B. EVALUATION PHASE ---\n",
        "    model_rot.eval()\n",
        "    model_trans.eval()\n",
        "\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50  # <--- too sample in the validation, take a subpart\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "\n",
        "        val_pbar =tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            bbox_info = batch['bbox_info'].to(DEVICE)\n",
        "            gt_rot = batch['rotation'].to(DEVICE)\n",
        "            gt_trans_abs = batch['translation'].to(DEVICE)\n",
        "            cam_K = batch['cam_K'].to(DEVICE)\n",
        "            bbox_centers = batch['bbox_center'].to(DEVICE)\n",
        "\n",
        "            # Forward\n",
        "            pred_rot = model_rot(imgs)\n",
        "            pred_trans = model_trans(imgs, bbox_info)\n",
        "\n",
        "            # Inverse pinhole projection\n",
        "            pred_deltas = pred_trans[:, :2]\n",
        "            pred_z = pred_trans[:, 2]\n",
        "            pred_3d_real = inverse_pinhole_projection(\n",
        "                crop_center=bbox_centers,\n",
        "                deltas=pred_deltas,\n",
        "                z=pred_z * 1000,\n",
        "                cam_K=cam_K\n",
        "            )\n",
        "\n",
        "            # Loss\n",
        "            loss, _, _ = criterion(pred_rot, gt_rot, pred_3d_real, gt_trans_abs)\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            count_batches += 1\n",
        "\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- C. REPORT & SAVE ---\n",
        "    print(f\"üìä Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save Best Model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        save_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_rot': model_rot.state_dict(),\n",
        "            'model_trans': model_trans.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, save_path)\n",
        "        print(f\"üèÜ New Best Model Saved! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save Last Checkpoint\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_rot': model_rot.state_dict(),\n",
        "            'model_trans': model_trans.state_dict(),\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_ep{epoch+1}.pth\"))\n",
        "\n",
        "print(\"\\nüéâ TRAINING COMPLETE! Generating plots...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXtHlPu-tBpR"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Grafico Lineare\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "# best_epoch-1 perch√® i plot partono da indice 0, ma l'epoca √® 1-based\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5, label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Grafico Logaritmico (Utile se la loss scende molto)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5, label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (log scale)')\n",
        "plt.yscale('log')\n",
        "plt.title('Training and Validation Loss (Log Scale)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(run_dir, 'training_history.png')\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Training Statistics:\")\n",
        "print(f\"   Total epochs: {len(train_losses)}\")\n",
        "print(f\"   Best epoch: {best_epoch}\")\n",
        "print(f\"   Best val loss: {best_val_loss:.6f}\")\n",
        "print(f\"   Final train loss: {train_losses[-1]:.6f}\")\n",
        "print(f\"   Final val loss: {val_losses[-1]:.6f}\")\n",
        "\n",
        "# Save training history to JSON\n",
        "history = {\n",
        "    'train_losses': [float(x) for x in train_losses],\n",
        "    'val_losses': [float(x) for x in val_losses],\n",
        "    'best_epoch': int(best_epoch),\n",
        "    'best_val_loss': float(best_val_loss),\n",
        "    'total_epochs': len(train_losses),\n",
        "    'timestamp': timestamp\n",
        "}\n",
        "\n",
        "history_path = os.path.join(run_dir, 'training_history.json')\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Training history saved to: {history_path}\")\n",
        "print(f\"üìà Plot saved to: {plot_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlVenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
