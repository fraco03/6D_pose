{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13909860,"sourceType":"datasetVersion","datasetId":8862865}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown -q\nprint(\"Downloading folder from Drive...\")\n# Downloads the folder structure containing the Linemod dataset\n!gdown \"https://drive.google.com/file/d/1Zwh-gAk_-CBgpOcNLPLdFNxggi3NTh-S/view?usp=drive_link\" --fuzzy\nimport glob\nzip_files = glob.glob(\"**/Linemod_preprocessed.zip\", recursive=True)\n\nif zip_files:\n    zip_path = zip_files[0]\n    print(f\"Unzipping {zip_path}...\")\n    !unzip -q -o \"{zip_path}\"\n    print(\"Extraction complete!\")\nelse:\n    print(\"Error: Linemod_preprocessed.zip not found. Check the download.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oAXrKjNq32c","outputId":"18b06df5-2594-43f9-dade-e6187644f8c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into '6D_pose'...\n","remote: Enumerating objects: 174, done.\u001b[K\n","remote: Counting objects: 100% (174/174), done.\u001b[K\n","remote: Compressing objects: 100% (120/120), done.\u001b[K\n","remote: Total 174 (delta 87), reused 113 (delta 45), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (174/174), 2.23 MiB | 6.95 MiB/s, done.\n","Resolving deltas: 100% (87/87), done.\n","Cloned https://github.com/fraco03/6D_pose.git to /content/6D_pose\n"]}],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\n\n# Clone or pull part\nrepo_url = \"https://github.com/fraco03/6D_pose.git\"\nrepo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\nbranch = \"main\"\n\n# Clone if missing\nif not os.path.exists(repo_dir):\n    !git clone -b {branch} {repo_url}\n    print(f\"Cloned {repo_url} to {repo_dir}\")\nelse:\n    %cd {repo_dir}\n    !git fetch origin\n    !git checkout {branch}\n    !git reset --hard origin/{branch}\n    %cd ..\n    print(f\"Updated {repo_url} to {repo_dir}\")\n\n# Add repository to Python path\nif repo_dir not in sys.path:\n    sys.path.insert(0, repo_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:14:21.079384Z","iopub.execute_input":"2025-12-22T10:14:21.079678Z","iopub.status.idle":"2025-12-22T10:14:22.302027Z","shell.execute_reply.started":"2025-12-22T10:14:21.079651Z","shell.execute_reply":"2025-12-22T10:14:22.301101Z"}},"outputs":[{"name":"stdout","text":"Cloning into '6D_pose'...\nremote: Enumerating objects: 745, done.\u001b[K\nremote: Counting objects: 100% (71/71), done.\u001b[K\nremote: Compressing objects: 100% (56/56), done.\u001b[K\nremote: Total 745 (delta 27), reused 39 (delta 15), pack-reused 674 (from 1)\u001b[K\nReceiving objects: 100% (745/745), 11.19 MiB | 25.92 MiB/s, done.\nResolving deltas: 100% (409/409), done.\nCloned https://github.com/fraco03/6D_pose.git to /kaggle/working/6D_pose\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cancella tutte le cartelle __pycache__ ricorsivamente nella directory di lavoro\n!find . -name \"__pycache__\" -type d -exec rm -rf {} +\nprint(\"ðŸ—‘ï¸ Cache pulita dal disco.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:14:24.781160Z","iopub.execute_input":"2025-12-22T10:14:24.781460Z","iopub.status.idle":"2025-12-22T10:14:24.902362Z","shell.execute_reply.started":"2025-12-22T10:14:24.781430Z","shell.execute_reply":"2025-12-22T10:14:24.901623Z"}},"outputs":[{"name":"stdout","text":"ðŸ—‘ï¸ Cache pulita dal disco.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install plyfile\nfrom src.pose_rgb.dataset import LineModPoseDataset\nfrom src.pose_rgb.model import ResNetRotation, TranslationNet\nfrom src.pose_rgb.pose_utils import quaternion_to_rotation_matrix, convert_rotation_to_quaternion, inverse_pinhole_projection\nfrom src.pose_rgb.test_dataset import *\nfrom src.pose_rgb.loss import CombinedPoseLoss, MultiObjectPointMatchingLoss, TranslationLoss\nfrom torch.utils.data import Dataset, DataLoader\nimport pathlib\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom utils.projection_utils import *\nfrom utils.linemod_config import *\nfrom metrics import compute_ADD_metric_quaternion\n","metadata":{"id":"Ea5j56JR7NjI","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:14:26.372435Z","iopub.execute_input":"2025-12-22T10:14:26.373130Z","iopub.status.idle":"2025-12-22T10:14:38.230650Z","shell.execute_reply.started":"2025-12-22T10:14:26.373093Z","shell.execute_reply":"2025-12-22T10:14:38.229769Z"}},"outputs":[{"name":"stdout","text":"Collecting plyfile\n  Downloading plyfile-1.1.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from plyfile) (2.0.2)\nDownloading plyfile-1.1.3-py3-none-any.whl (36 kB)\nInstalling collected packages: plyfile\nSuccessfully installed plyfile-1.1.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"root_dir = '/kaggle/input/line-mode/Linemod_preprocessed' #Modify here for kaggle\ndayaset_root = root_dir\ndevice = ('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_dataset = LineModPoseDataset(split='train', root_dir=root_dir)\ntest_dataset = LineModPoseDataset(split='test', root_dir=root_dir)\n\n#Dataloder\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrOmeFj_sRID","outputId":"d3a4e969-a16f-4f10-ac1a-e0ffe7eb5e69","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:27:45.938389Z","iopub.execute_input":"2025-12-22T10:27:45.939392Z","iopub.status.idle":"2025-12-22T10:27:55.230588Z","shell.execute_reply.started":"2025-12-22T10:27:45.939340Z","shell.execute_reply":"2025-12-22T10:27:55.229924Z"}},"outputs":[{"name":"stdout","text":" Loaded LineModPoseDataset\n   Split: train (Ratio: 0.80)\n   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n   Total samples: 12610\n Loaded LineModPoseDataset\n   Split: test (Ratio: 0.20)\n   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n   Total samples: 3163\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\n\ndef load_all_object_points(num_points=1000):\n    \"\"\"\n    Loads .ply files for ALL objects and stacks them into a single Tensor.\n    \n    Args:\n        models_dir (str): Folder containing .ply files (e.g., 'obj_01.ply').\n        valid_obj_ids (list): List of integers IDs (e.g., [1, 5, 6...]).\n        num_points (int): Number of points to sample per object.\n        \n    Returns:\n        torch.Tensor: Shape (Num_Classes, num_points, 3).\n                      The index in dimension 0 corresponds to the index in valid_obj_ids.\n    \"\"\"\n    linemod_config = get_linemod_config(dataset_root)\n\n    all_model_points = []\n    VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n    for obj_id in VALID_OBJ_IDS:\n        model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n        if model_points.shape[0] >= NUM_POINTS:\n            choice = np.random.choice(model_points.shape[0], num_points, replace=False)\n        else:\n            choice = np.random.choice(model_points.shape[0], num_points, replace=True)\n        model_points = model_points[choice, :]\n        all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n    all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n    all_model_points = all_model_points.to(device)\n    return all_model_points\n\nVALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \nmax_obj_id = max(VALID_OBJ_IDS)\n\n# Create a lookup table: obj_id -> index\nobj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\nfor idx, obj_id in enumerate(VALID_OBJ_IDS):\n    obj_id_to_idx[obj_id] = idx\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:15:49.922872Z","iopub.execute_input":"2025-12-22T10:15:49.923544Z","iopub.status.idle":"2025-12-22T10:15:49.933250Z","shell.execute_reply.started":"2025-12-22T10:15:49.923513Z","shell.execute_reply":"2025-12-22T10:15:49.932332Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3020695458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Create a lookup table: obj_id -> index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mobj_id_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_obj_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_OBJ_IDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mobj_id_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"],"ename":"NameError","evalue":"name 'device' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"LINEMOD_NAMES = [\n            'ape',         # Index 0 (ID 1)\n            'benchvise',   # Index 1 (ID 2)\n            'camera',      # Index 2 (ID 4)\n            'can',         # Index 3 (ID 5)\n            'cat',         # Index 4 (ID 6)\n            'driller',     # Index 5 (ID 8)\n            'duck',        # Index 6 (ID 9)\n            'eggbox',      # Index 7 (ID 10)\n            'glue',        # Index 8 (ID 11)\n            'holepuncher', # Index 9 (ID 12)\n            'iron',        # Index 10 (ID 13)\n            'lamp',        # Index 11 (ID 14)\n            'phone'        # Index 12 (ID 15)\n        ]\nname_to_idx = {name: i for i, name in enumerate(LINEMOD_NAMES)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:08:04.716399Z","iopub.execute_input":"2025-12-22T10:08:04.717024Z","iopub.status.idle":"2025-12-22T10:08:04.721378Z","shell.execute_reply.started":"2025-12-22T10:08:04.716995Z","shell.execute_reply":"2025-12-22T10:08:04.720534Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# ROTATION ONLY","metadata":{}},{"cell_type":"code","source":"# ONLY ROTATION TRAINING SCRIPT\nimport os\nimport torch\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport json\nfrom datetime import datetime\nfrom itertools import islice\nimport numpy as np\n\n# ==========================================\n# 1. SETUP & HYPERPARAMETERS\n# ==========================================\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 50\n\n# --- PATHS ---\n# Define where your .ply models are located\nMODELS_DIR = '/kaggle/input/line-mode/Linemod_preprocessed/models' \n# List of valid object IDs in your dataset (must match your dataset logic)\nVALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n\n# --- LOGGING SETUP ---\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n# Directory to save checkpoints and logs\nCHECKPOINT_DIR = f'/kaggle/working/run_rotation' \nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nrun_dir = CHECKPOINT_DIR\n\nprint(f\"\\nðŸ”¥ STARTING ROTATION-ONLY TRAINING on {DEVICE}...\")\nprint(f\"ðŸ“ Saving outputs to: {run_dir}\")\n\n# ==========================================\n# 2. INITIALIZE LOSS & MODELS\n# ==========================================\n\n# A. LOAD 3D POINTS FOR LOSS\n# We need to load the point clouds for all objects to use PointMatchingLoss.\nprint(\"ðŸ“¦ Loading 3D Point Clouds for Loss Function...\")\n# Use the helper function we defined earlier to load all ply files\npoint_bank = load_all_object_points(MODELS_DIR, VALID_OBJ_IDS, num_points=1000)\npoint_bank = point_bank.to(DEVICE) # Move entire bank to GPU\n\n\n# B. DEFINE LOSS FUNCTION\n\ncriterion = MultiObjectPointMatchingLoss(point_bank).to(DEVICE)\n\n# C. INITIALIZE MODEL\n# We only use the Rotation Network\nmodel_rot = ResNetRotation(freeze_backbone=False).to(DEVICE)\n\n# D. OPTIMIZER\n# We only optimize the rotation model parameters\noptimizer = optim.Adam(\n    model_rot.parameters(),\n    lr=LEARNING_RATE\n)\n\n# E. METRICS STORAGE\ntrain_losses = []\nval_losses = []\nbest_val_loss = float('inf')\n\n# ==========================================\n# 3. TRAINING LOOP\n# ==========================================\nfor epoch in range(NUM_EPOCHS):\n\n    # --- A. TRAIN PHASE ---\n    model_rot.train()\n    running_train_loss = 0.0\n\n    # Progress Bar\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n\n    for batch in pbar:\n        # 1. Move data to GPU\n        imgs = batch['image'].to(DEVICE)\n        gt_rot = batch['rotation'].to(DEVICE)\n        \n        # We need class indices for the PointMatchingLoss (Index 0 to 12)\n        # Ensure your Dataset returns 'class_id' as a mapped index (0..N), NOT the raw Linemod ID (1,5,8..)\n        obj_ids = batch['object_id'].to(DEVICE)\n        class_ids = obj_id_to_idx[obj_ids]\n        \n        # 2. Forward Pass\n        pred_rot = model_rot(imgs)\n\n        # 3. Calculate Loss\n        # Pass class_ids so the loss knows which 3D model to use for each image in the batch\n        if point_bank is not None:\n            loss = criterion(pred_rot, gt_rot, class_ids)\n        else:\n            loss = criterion(pred_rot, gt_rot) # Fallback doesn't use IDs\n\n        # 4. Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # 5. Logging\n        running_train_loss += loss.item()\n        pbar.set_postfix({'ADD Loss': f\"{loss.item():.4f}\"})\n\n    avg_train_loss = running_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # --- B. EVALUATION PHASE ---\n    model_rot.eval()\n    running_val_loss = 0.0\n    val_batches_limit = 50  # Validate on a subset to save time per epoch\n    count_batches = 0\n\n    with torch.no_grad():\n        val_iterator = islice(test_loader, val_batches_limit)\n        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n\n        for batch in val_pbar:\n            imgs = batch['image'].to(DEVICE)\n            gt_rot = batch['rotation'].to(DEVICE)\n            raw_names_list = batch['class_idx'] # es. ['can', 'ape', 'driller']\n            \n            \n            try:\n                indices = [name_to_idx[name] for name in raw_names_list]\n            except KeyError as e:\n                print(f\"âŒ ERRORE CRITICO: Trovato nome '{e}' non presente nella lista LINEMOD_NAMES!\")\n                raise e\n    \n            \n            class_ids = torch.tensor(indices, dtype=torch.long).to(DEVICE)\n\n            # Forward\n            pred_rot = model_rot(imgs)\n\n            # Loss\n            if point_bank is not None:\n                loss = criterion(pred_rot, gt_rot, class_ids)\n            else:\n                loss = criterion(pred_rot, gt_rot)\n                \n            running_val_loss += loss.item()\n            count_batches += 1\n\n    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0\n    val_losses.append(avg_val_loss)\n\n    # --- C. REPORT & SAVE ---\n    print(f\"ðŸ“Š Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n\n    # Save Best Model\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        save_path = os.path.join(CHECKPOINT_DIR, \"best_model_rot.pth\")\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model_rot.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_loss': best_val_loss\n        }, save_path)\n        print(f\"ðŸ† New Best Rotation Model Saved! (Loss: {best_val_loss:.4f})\")\n\n    # Save Last Checkpoint (for resuming if needed)\n    if (epoch + 1) == NUM_EPOCHS:\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model_rot.state_dict(),\n            'val_loss': avg_val_loss\n        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_last.pth\"))\n\n# --- D. PLOTTING ---\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Train Loss (ADD Metric)')\nplt.plot(val_losses, label='Val Loss (ADD Metric)')\nplt.title('Rotation Training Convergence')\nplt.xlabel('Epochs')\nplt.ylabel('Average Distance (m)')\nplt.legend()\nplt.grid(True)\nplt.savefig(os.path.join(CHECKPOINT_DIR, 'rotation_training_curve.png'))\nprint(\"ðŸŽ‰ TRAINING COMPLETE! Training curve saved.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Translation ONLY","metadata":{}},{"cell_type":"code","source":"# ONLY TRANSLATION TRAINING SCRIPT\nfrom src.pose_rgb import model\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nimport os\nimport numpy as np\n\n# ==========================================\n# 1. CONFIGURATION\n# ==========================================\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 64        # Adjust if you run out of memory\nLR = 0.001             # Constant Learning Rate\nNUM_EPOCHS = 30\nCHECKPOINT_DIR = f'/kaggle/working/run_translation' \nDATA_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed'\n\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# ==========================================\n# 2. MODEL & OPTIMIZER SETUP\n# ==========================================\nprint(f\"ðŸ§  Initializing Model on {DEVICE}...\")\n\n# Initialize your custom TranslationNet\nmodel_transl = TranslationNet()\n\nif torch.cuda.device_count() > 1:\n    print(f\"ðŸ”¥ Using {torch.cuda.device_count()} GPU!\")\n    model_transl = nn.DataParallel(model_transl)\nmodel_transl = model_transl.to(DEVICE)\n\n# Define Loss (Weighted to prioritize Depth Z)\ncriterion = TranslationLoss(z_weight=1) \n\n# Scheduler and optimizer\nLR_MAX = 1e-3\nWEIGHT_DECAY = 1e-2\nEPOCHS = 30\nSTEPS_PER_EPOCH = len(train_loader)\n\noptimizer = optim.AdamW(\n    model_transl.parameters(), \n    lr=LR_MAX / 10,  # OneCycleLR handles the lr\n    weight_decay=WEIGHT_DECAY\n)\n\nscheduler = optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=LR_MAX,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    pct_start=0.3,  # Il 30% del tempo speso a far salire il LR\n    anneal_strategy='cos'\n)\n\n# ==========================================\n# 3. TRAINING LOOP\n# ==========================================\nbest_val_mae = float('inf') # Track the best error to save the best model\n\nprint(\"ðŸš€ Starting Training Loop...\")\n\nfor epoch in range(NUM_EPOCHS):\n    \n    # --- TRAIN PHASE ---\n    model_transl.train()\n    running_loss = 0.0\n    \n    # Progress bar for training\n    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n    \n    for batch in train_loop:\n        # Move data to GPU\n        imgs = batch['image'].to(DEVICE)           # (B, 3, 224, 224)\n        bbox_info = batch['bbox_info'].to(DEVICE)  # (B, 4) Normalized BBox GPS\n        gt_trans = batch['translation'].to(DEVICE) # (B, 3) Absolute Translation in METERS\n\n        # Forward Pass\n        preds = model_transl(imgs, bbox_info)\n        \n        # Calculate Loss\n        loss = criterion(preds, gt_trans)\n        \n        # Backward Pass (Update Weights)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        # Update stats\n        running_loss += loss.item()\n        train_loop.set_postfix(loss=loss.item())\n\n    avg_train_loss = running_loss / len(train_loader)\n\n    # --- VALIDATION PHASE ---\n    model_transl.eval()\n    val_loss = 0.0\n    \n    # Variables to calculate error in Centimeters (for human readability)\n    error_sum_xyz = np.array([0.0, 0.0, 0.0]) \n    total_samples = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Eval]\"):\n            imgs = batch['image'].to(DEVICE)\n            bbox_info = batch['bbox_info'].to(DEVICE)\n            gt_trans = batch['translation'].to(DEVICE)\n\n            # Predict\n            preds = model_transl(imgs, bbox_info)\n            \n            # Calculate Loss\n            loss = criterion(preds, gt_trans)\n            val_loss += loss.item()\n            \n            # Calculate Absolute Error (in Meters)\n            abs_err = torch.abs(preds - gt_trans).cpu().numpy()\n            error_sum_xyz += abs_err.sum(axis=0)\n            total_samples += imgs.shape[0]\n\n    avg_val_loss = val_loss / len(test_loader)\n    \n    # Convert Mean Error to Centimeters\n    mean_error_m = error_sum_xyz / total_samples\n    mean_error_cm = mean_error_m * 100.0\n    total_mae_cm = np.mean(mean_error_cm) # Average error across X, Y, Z\n\n    # --- REPORTING ---\n    print(f\"\\nðŸ“Š REPORT EPOCH {epoch+1}\")\n    print(f\"   Train Loss:    {avg_train_loss:.5f}\")\n    print(f\"   Val Loss:      {avg_val_loss:.5f}\")\n    print(f\"   --------------------------------\")\n    print(f\"   Error X:       {mean_error_cm[0]:.2f} cm\")\n    print(f\"   Error Y:       {mean_error_cm[1]:.2f} cm\")\n    print(f\"   Error Z:       {mean_error_cm[2]:.2f} cm (Depth)\")\n    print(f\"   --------------------------------\")\n    \n    # Save Best Model (if error is lower than previous best)\n    if total_mae_cm < best_val_mae:\n        best_val_mae = total_mae_cm\n        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/best_translation_model.pth\")\n        print(f\"   ðŸ’¾ New Best Model Saved! (Avg Error: {total_mae_cm:.2f} cm)\")\n        \n    # Save periodic checkpoint every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/translation_ep{epoch+1}.pth\")\n\nprint(\"\\nâœ… Training Complete. Best model saved in:\", CHECKPOINT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:28:56.836192Z","iopub.execute_input":"2025-12-22T10:28:56.836509Z","iopub.status.idle":"2025-12-22T10:37:25.797831Z","shell.execute_reply.started":"2025-12-22T10:28:56.836478Z","shell.execute_reply":"2025-12-22T10:37:25.773835Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Initializing Model on cuda...\nðŸ”¥ Using 2 GPU!\nðŸš€ Starting Training Loop...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/30 [Train]:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbccc60b48214b8bb1d3bc6b491a70eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/30 [Eval]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf6355ba9cd4732af5ff75fef5006d6"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š REPORT EPOCH 1\n   Train Loss:    0.06388\n   Val Loss:      0.01302\n   --------------------------------\n   Error X:       6.09 cm\n   Error Y:       4.93 cm\n   Error Z:       11.77 cm (Depth)\n   --------------------------------\n   ðŸ’¾ New Best Model Saved! (Avg Error: 7.60 cm)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/30 [Train]:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bfdab684084bd0953fba0bf6d1208a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/30 [Eval]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eda90a74a65d46f6a1251cfc4d1a25a3"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š REPORT EPOCH 2\n   Train Loss:    0.01763\n   Val Loss:      0.02425\n   --------------------------------\n   Error X:       4.32 cm\n   Error Y:       4.01 cm\n   Error Z:       19.14 cm (Depth)\n   --------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/30 [Train]:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a719b203e44520925a35c6825ceb28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/30 [Eval]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"363b7483dcaf4c2ea0d77e2753fe2ed6"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š REPORT EPOCH 3\n   Train Loss:    0.01219\n   Val Loss:      0.03568\n   --------------------------------\n   Error X:       4.01 cm\n   Error Y:       6.41 cm\n   Error Z:       24.23 cm (Depth)\n   --------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/30 [Train]:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9dd58a863784c1388bc2189abb0082e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/30 [Eval]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ada2a3b73f374932b5d47dafdaff2edd"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š REPORT EPOCH 4\n   Train Loss:    0.00907\n   Val Loss:      0.03789\n   --------------------------------\n   Error X:       3.36 cm\n   Error Y:       4.27 cm\n   Error Z:       25.44 cm (Depth)\n   --------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/30 [Train]:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f4a13a9ca5743c7b446ec2a73e3213a"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2115026057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Move data to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# (B, 3, 224, 224)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../..')","metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from src.pose_rgb.evaluate import evaluate_RGB, evaluate_RGB_rot_only\n\nmodel_path = \"./RGB_run/best_model_rot.pth\"\ndataset_root = \"../../Linemod_preprocessed\"\noutput_path = \"./RGB_run/evaluation_results.csv\"\n\n\ndf = evaluate_RGB_rot_only(\n    model_path=model_path,\n    dataset_root=dataset_root,\n    output_path=output_path\n)\n    \ndf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ“¥ Loading 3D model points and diameters...\n","ðŸ“¦ Loading trained model...\n","ðŸ“š Preparing test dataset and dataloader...\n"," Loaded LineModPoseDepthDataset\n","   Split: test (Ratio: 0.20)\n","   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n","   Total samples: 4867\n","\n","ðŸš€ Starting Comprehensive Benchmark (ADD Error + ADD-0.1d Accuracy)...\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [16:03<00:00, 24.70s/batch]"]},{"name":"stdout","output_type":"stream","text":["\n","ðŸ“Š Evaluation report saved to ./RGB_run/evaluation_results.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"application/vnd.microsoft.datawrangler.viewer.v0+json":{"columns":[{"name":"index","rawType":"int64","type":"integer"},{"name":"Object ID","rawType":"int64","type":"integer"},{"name":"Object Name","rawType":"object","type":"string"},{"name":"Diameter (mm)","rawType":"float64","type":"float"},{"name":"Mean ADD (mm)","rawType":"float32","type":"float"},{"name":"Mean ADD-S (mm)","rawType":"float64","type":"float"},{"name":"Mean ADD-Rot (mm)","rawType":"float32","type":"float"},{"name":"Mean ADD-S-Rot (mm)","rawType":"float64","type":"float"},{"name":"ADD-0.1d Accuracy (%)","rawType":"float64","type":"float"},{"name":"ADD-S-0.1d Accuracy (%)","rawType":"float64","type":"float"}],"ref":"65e66c02-a04f-4a2c-bf74-f4c2ba6a16f3","rows":[["0","1","ape","102.09865663","6.3711176","2.1292544287237","6.3711176","2.1292544287237","86.86440677966102","99.78813559322035"],["1","2","benchvise","247.50624233","12.7289715","5.129824546231763","12.7289715","5.129824546231763","92.14876033057851","100.0"],["2","5","can","201.40358597","10.640517","3.6934506261609434","10.640517","3.6934506261609434","93.9203354297694","99.79035639412997"],["3","6","cat","154.54551808","7.6868267","3.226671479561668","7.6868267","3.226671479561668","92.37472766884531","99.12854030501089"],["4","8","driller","261.47178102","11.04353","5.103863760619234","11.04353","5.103863760619234","96.21052631578947","100.0"],["5","9","duck","108.99920102","8.140133","2.7549539564965917","8.140133","2.7549539564965917","83.60995850622407","99.79253112033194"],["6","10","eggbox","164.62758848","10.934605","3.253343872492656","10.934605","3.253343872492656","87.73148148148148","100.0"],["7","11","glue","175.88933422","8.390186","3.7778694538121496","8.390186","3.7778694538121496","95.16129032258065","100.0"],["8","12","holepuncher","145.54287471","9.141986","2.895302563732996","9.141986","2.895302563732996","85.91836734693878","100.0"],["9","4","camera","172.49224865","8.40986","3.107157819201605","8.40986","3.107157819201605","95.0207468879668","100.0"],["10","13","iron","278.07811733","12.014362","5.025002339360982","12.014362","5.025002339360982","95.23809523809523","100.0"],["11","14","lamp","282.60129399","11.619051","4.726791443154207","11.619051","4.726791443154207","98.36734693877551","100.0"],["12","15","phone","212.35825148","12.144069","4.6267420177680245","12.144069","4.6267420177680245","90.76305220883533","100.0"]],"shape":{"columns":9,"rows":13}},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Object ID</th>\n","      <th>Object Name</th>\n","      <th>Diameter (mm)</th>\n","      <th>Mean ADD (mm)</th>\n","      <th>Mean ADD-S (mm)</th>\n","      <th>Mean ADD-Rot (mm)</th>\n","      <th>Mean ADD-S-Rot (mm)</th>\n","      <th>ADD-0.1d Accuracy (%)</th>\n","      <th>ADD-S-0.1d Accuracy (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>ape</td>\n","      <td>102.098657</td>\n","      <td>6.371118</td>\n","      <td>2.129254</td>\n","      <td>6.371118</td>\n","      <td>2.129254</td>\n","      <td>86.864407</td>\n","      <td>99.788136</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>benchvise</td>\n","      <td>247.506242</td>\n","      <td>12.728971</td>\n","      <td>5.129825</td>\n","      <td>12.728971</td>\n","      <td>5.129825</td>\n","      <td>92.148760</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>can</td>\n","      <td>201.403586</td>\n","      <td>10.640517</td>\n","      <td>3.693451</td>\n","      <td>10.640517</td>\n","      <td>3.693451</td>\n","      <td>93.920335</td>\n","      <td>99.790356</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>cat</td>\n","      <td>154.545518</td>\n","      <td>7.686827</td>\n","      <td>3.226671</td>\n","      <td>7.686827</td>\n","      <td>3.226671</td>\n","      <td>92.374728</td>\n","      <td>99.128540</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>driller</td>\n","      <td>261.471781</td>\n","      <td>11.043530</td>\n","      <td>5.103864</td>\n","      <td>11.043530</td>\n","      <td>5.103864</td>\n","      <td>96.210526</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9</td>\n","      <td>duck</td>\n","      <td>108.999201</td>\n","      <td>8.140133</td>\n","      <td>2.754954</td>\n","      <td>8.140133</td>\n","      <td>2.754954</td>\n","      <td>83.609959</td>\n","      <td>99.792531</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>eggbox</td>\n","      <td>164.627588</td>\n","      <td>10.934605</td>\n","      <td>3.253344</td>\n","      <td>10.934605</td>\n","      <td>3.253344</td>\n","      <td>87.731481</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>11</td>\n","      <td>glue</td>\n","      <td>175.889334</td>\n","      <td>8.390186</td>\n","      <td>3.777869</td>\n","      <td>8.390186</td>\n","      <td>3.777869</td>\n","      <td>95.161290</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>12</td>\n","      <td>holepuncher</td>\n","      <td>145.542875</td>\n","      <td>9.141986</td>\n","      <td>2.895303</td>\n","      <td>9.141986</td>\n","      <td>2.895303</td>\n","      <td>85.918367</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4</td>\n","      <td>camera</td>\n","      <td>172.492249</td>\n","      <td>8.409860</td>\n","      <td>3.107158</td>\n","      <td>8.409860</td>\n","      <td>3.107158</td>\n","      <td>95.020747</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>13</td>\n","      <td>iron</td>\n","      <td>278.078117</td>\n","      <td>12.014362</td>\n","      <td>5.025002</td>\n","      <td>12.014362</td>\n","      <td>5.025002</td>\n","      <td>95.238095</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>14</td>\n","      <td>lamp</td>\n","      <td>282.601294</td>\n","      <td>11.619051</td>\n","      <td>4.726791</td>\n","      <td>11.619051</td>\n","      <td>4.726791</td>\n","      <td>98.367347</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>15</td>\n","      <td>phone</td>\n","      <td>212.358251</td>\n","      <td>12.144069</td>\n","      <td>4.626742</td>\n","      <td>12.144069</td>\n","      <td>4.626742</td>\n","      <td>90.763052</td>\n","      <td>100.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Object ID  Object Name  Diameter (mm)  Mean ADD (mm)  Mean ADD-S (mm)  \\\n","0           1          ape     102.098657       6.371118         2.129254   \n","1           2    benchvise     247.506242      12.728971         5.129825   \n","2           5          can     201.403586      10.640517         3.693451   \n","3           6          cat     154.545518       7.686827         3.226671   \n","4           8      driller     261.471781      11.043530         5.103864   \n","5           9         duck     108.999201       8.140133         2.754954   \n","6          10       eggbox     164.627588      10.934605         3.253344   \n","7          11         glue     175.889334       8.390186         3.777869   \n","8          12  holepuncher     145.542875       9.141986         2.895303   \n","9           4       camera     172.492249       8.409860         3.107158   \n","10         13         iron     278.078117      12.014362         5.025002   \n","11         14         lamp     282.601294      11.619051         4.726791   \n","12         15        phone     212.358251      12.144069         4.626742   \n","\n","    Mean ADD-Rot (mm)  Mean ADD-S-Rot (mm)  ADD-0.1d Accuracy (%)  \\\n","0            6.371118             2.129254              86.864407   \n","1           12.728971             5.129825              92.148760   \n","2           10.640517             3.693451              93.920335   \n","3            7.686827             3.226671              92.374728   \n","4           11.043530             5.103864              96.210526   \n","5            8.140133             2.754954              83.609959   \n","6           10.934605             3.253344              87.731481   \n","7            8.390186             3.777869              95.161290   \n","8            9.141986             2.895303              85.918367   \n","9            8.409860             3.107158              95.020747   \n","10          12.014362             5.025002              95.238095   \n","11          11.619051             4.726791              98.367347   \n","12          12.144069             4.626742              90.763052   \n","\n","    ADD-S-0.1d Accuracy (%)  \n","0                 99.788136  \n","1                100.000000  \n","2                 99.790356  \n","3                 99.128540  \n","4                100.000000  \n","5                 99.792531  \n","6                100.000000  \n","7                100.000000  \n","8                100.000000  \n","9                100.000000  \n","10               100.000000  \n","11               100.000000  \n","12               100.000000  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"execution_count":3},{"cell_type":"code","source":"from src.pose_rgb.dataset import LineModPoseDataset\ndataset_root = \"../../Linemod_preprocessed\"\ntest = LineModPoseDataset(split='test', root_dir=dataset_root)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… LineModConfig initialized: F:\\Magistrale\\Advanced Machine Learning\\6D_pose\\Linemod_preprocessed\n"," Loaded LineModPoseDataset\n","   Split: test (Ratio: 0.20)\n","   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n","   Total samples: 3163\n"]}],"execution_count":3}]}