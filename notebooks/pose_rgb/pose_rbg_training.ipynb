{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oAXrKjNq32c",
        "outputId": "18b06df5-2594-43f9-dade-e6187644f8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6D_pose'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 174 (delta 87), reused 113 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 2.23 MiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Cloned https://github.com/fraco03/6D_pose.git to /content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown -q\n",
        "print(\"Downloading folder from Drive...\")\n",
        "# Downloads the folder structure containing the Linemod dataset\n",
        "!gdown \"https://drive.google.com/file/d/1Zwh-gAk_-CBgpOcNLPLdFNxggi3NTh-S/view?usp=drive_link\" --fuzzy\n",
        "import glob\n",
        "zip_files = glob.glob(\"**/Linemod_preprocessed.zip\", recursive=True)\n",
        "\n",
        "if zip_files:\n",
        "    zip_path = zip_files[0]\n",
        "    print(f\"Unzipping {zip_path}...\")\n",
        "    !unzip -q -o \"{zip_path}\"\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"Error: Linemod_preprocessed.zip not found. Check the download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
        "branch = \"main\"\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancella tutte le cartelle __pycache__ ricorsivamente nella directory di lavoro\n",
        "!find . -name \"__pycache__\" -type d -exec rm -rf {} +\n",
        "print(\"üóëÔ∏è Cache pulita dal disco.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea5j56JR7NjI"
      },
      "outputs": [],
      "source": [
        "!pip install plyfile\n",
        "from src.pose_rgb.dataset import LineModPoseDataset\n",
        "from src.pose_rgb.model import ResNetRotation, TranslationNet\n",
        "from src.pose_rgb.pose_utils import quaternion_to_rotation_matrix, convert_rotation_to_quaternion, inverse_pinhole_projection\n",
        "from src.pose_rgb.test_dataset import *\n",
        "from src.pose_rgb.loss import CombinedPoseLoss, MultiObjectPointMatchingLoss, TranslationLoss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pathlib\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from utils.projection_utils import *\n",
        "from utils.linemod_config import *\n",
        "from metrics import compute_ADD_metric_quaternion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrOmeFj_sRID",
        "outputId": "d3a4e969-a16f-4f10-ac1a-e0ffe7eb5e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded LineModPoseDataset\n",
            "   Split: train\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 3631\n",
            " Loaded LineModPoseDataset\n",
            "   Split: test\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 20528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/kaggle/input/line-mode/Linemod_preprocessed' #Modify here for kaggle\n",
        "\n",
        "train_dataset = LineModPoseDataset(split='train', root_dir=root_dir)\n",
        "test_dataset = LineModPoseDataset(split='test', root_dir=root_dir)\n",
        "\n",
        "#Dataloder\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import os\n",
        "\n",
        "def load_all_object_points(models_dir, valid_obj_ids, num_points=1000):\n",
        "    \"\"\"\n",
        "    Loads .ply files for ALL objects and stacks them into a single Tensor.\n",
        "    \n",
        "    Args:\n",
        "        models_dir (str): Folder containing .ply files (e.g., 'obj_01.ply').\n",
        "        valid_obj_ids (list): List of integers IDs (e.g., [1, 5, 6...]).\n",
        "        num_points (int): Number of points to sample per object.\n",
        "        \n",
        "    Returns:\n",
        "        torch.Tensor: Shape (Num_Classes, num_points, 3).\n",
        "                      The index in dimension 0 corresponds to the index in valid_obj_ids.\n",
        "    \"\"\"\n",
        "    all_points_list = []\n",
        "    \n",
        "    print(f\"üì¶ Loading {len(valid_obj_ids)} 3D models from {models_dir}...\")\n",
        "    \n",
        "    for i, obj_id in enumerate(valid_obj_ids):\n",
        "        # Construct filename assuming LineMod format (e.g., 'obj_01.ply')\n",
        "        ply_name = f\"obj_{obj_id:02d}.ply\" \n",
        "        ply_path = os.path.join(models_dir, ply_name)\n",
        "        \n",
        "        if not os.path.exists(ply_path):\n",
        "            raise FileNotFoundError(f\"Model not found: {ply_path}\")\n",
        "\n",
        "        # Load mesh\n",
        "        mesh = trimesh.load(ply_path)\n",
        "        vertices = np.array(mesh.vertices)\n",
        "        \n",
        "        # Sample points\n",
        "        if len(vertices) > num_points:\n",
        "            idx = np.random.choice(len(vertices), num_points, replace=False)\n",
        "            selected = vertices[idx]\n",
        "        else:\n",
        "            # Padding via repetition if not enough points (rare in LineMod)\n",
        "            choice = np.random.choice(len(vertices), num_points, replace=True)\n",
        "            selected = vertices[choice]\n",
        "            \n",
        "        # Add to list\n",
        "        all_points_list.append(selected)\n",
        "\n",
        "    # Stack into a single tensor\n",
        "    # Shape: (Num_Classes, Num_Points, 3)\n",
        "    # Example: (13, 1000, 3)\n",
        "    bank_tensor = torch.from_numpy(np.array(all_points_list)).float()\n",
        "    \n",
        "    # Unit conversion (mm to meters) if needed\n",
        "    # bank_tensor = bank_tensor / 1000.0 \n",
        "    \n",
        "    return bank_tensor / 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LINEMOD_NAMES = [\n",
        "            'ape',         # Index 0 (ID 1)\n",
        "            'benchvise',   # Index 1 (ID 2)\n",
        "            'camera',      # Index 2 (ID 4)\n",
        "            'can',         # Index 3 (ID 5)\n",
        "            'cat',         # Index 4 (ID 6)\n",
        "            'driller',     # Index 5 (ID 8)\n",
        "            'duck',        # Index 6 (ID 9)\n",
        "            'eggbox',      # Index 7 (ID 10)\n",
        "            'glue',        # Index 8 (ID 11)\n",
        "            'holepuncher', # Index 9 (ID 12)\n",
        "            'iron',        # Index 10 (ID 13)\n",
        "            'lamp',        # Index 11 (ID 14)\n",
        "            'phone'        # Index 12 (ID 15)\n",
        "        ]\n",
        "name_to_idx = {name: i for i, name in enumerate(LINEMOD_NAMES)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONLY ROTATION TRAINING SCRIPT\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & HYPERPARAMETERS\n",
        "# ==========================================\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# --- PATHS ---\n",
        "# Define where your .ply models are located\n",
        "MODELS_DIR = '/kaggle/input/line-mode/Linemod_preprocessed/models' \n",
        "# List of valid object IDs in your dataset (must match your dataset logic)\n",
        "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
        "\n",
        "# --- LOGGING SETUP ---\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "# Directory to save checkpoints and logs\n",
        "CHECKPOINT_DIR = f'/kaggle/working/run_rotation' \n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "run_dir = CHECKPOINT_DIR\n",
        "\n",
        "print(f\"\\nüî• STARTING ROTATION-ONLY TRAINING on {DEVICE}...\")\n",
        "print(f\"üìÅ Saving outputs to: {run_dir}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. INITIALIZE LOSS & MODELS\n",
        "# ==========================================\n",
        "\n",
        "# A. LOAD 3D POINTS FOR LOSS\n",
        "# We need to load the point clouds for all objects to use PointMatchingLoss.\n",
        "print(\"üì¶ Loading 3D Point Clouds for Loss Function...\")\n",
        "# Use the helper function we defined earlier to load all ply files\n",
        "point_bank = load_all_object_points(MODELS_DIR, VALID_OBJ_IDS, num_points=1000)\n",
        "point_bank = point_bank.to(DEVICE) # Move entire bank to GPU\n",
        "\n",
        "\n",
        "# B. DEFINE LOSS FUNCTION\n",
        "\n",
        "criterion = MultiObjectPointMatchingLoss(point_bank).to(DEVICE)\n",
        "\n",
        "# C. INITIALIZE MODEL\n",
        "# We only use the Rotation Network\n",
        "model_rot = ResNetRotation(freeze_backbone=False).to(DEVICE)\n",
        "\n",
        "# D. OPTIMIZER\n",
        "# We only optimize the rotation model parameters\n",
        "optimizer = optim.Adam(\n",
        "    model_rot.parameters(),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# E. METRICS STORAGE\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- A. TRAIN PHASE ---\n",
        "    model_rot.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    # Progress Bar\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # 1. Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)\n",
        "        gt_rot = batch['rotation'].to(DEVICE)\n",
        "        \n",
        "        # We need class indices for the PointMatchingLoss (Index 0 to 12)\n",
        "        # Ensure your Dataset returns 'class_id' as a mapped index (0..N), NOT the raw Linemod ID (1,5,8..)\n",
        "        raw_names_list = batch['class_idx'] # es. ['can', 'ape', 'driller']\n",
        "        \n",
        "        \n",
        "        try:\n",
        "            indices = [name_to_idx[name] for name in raw_names_list]\n",
        "        except KeyError as e:\n",
        "            print(f\"‚ùå ERRORE CRITICO: Trovato nome '{e}' non presente nella lista LINEMOD_NAMES!\")\n",
        "            raise e\n",
        "\n",
        "        \n",
        "        class_ids = torch.tensor(indices, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "        # 2. Forward Pass\n",
        "        pred_rot = model_rot(imgs)\n",
        "\n",
        "        # 3. Calculate Loss\n",
        "        # Pass class_ids so the loss knows which 3D model to use for each image in the batch\n",
        "        if point_bank is not None:\n",
        "            loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "        else:\n",
        "            loss = criterion(pred_rot, gt_rot) # Fallback doesn't use IDs\n",
        "\n",
        "        # 4. Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 5. Logging\n",
        "        running_train_loss += loss.item()\n",
        "        pbar.set_postfix({'ADD Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- B. EVALUATION PHASE ---\n",
        "    model_rot.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50  # Validate on a subset to save time per epoch\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            gt_rot = batch['rotation'].to(DEVICE)\n",
        "            raw_names_list = batch['class_idx'] # es. ['can', 'ape', 'driller']\n",
        "            \n",
        "            \n",
        "            try:\n",
        "                indices = [name_to_idx[name] for name in raw_names_list]\n",
        "            except KeyError as e:\n",
        "                print(f\"‚ùå ERRORE CRITICO: Trovato nome '{e}' non presente nella lista LINEMOD_NAMES!\")\n",
        "                raise e\n",
        "    \n",
        "            \n",
        "            class_ids = torch.tensor(indices, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "            # Forward\n",
        "            pred_rot = model_rot(imgs)\n",
        "\n",
        "            # Loss\n",
        "            if point_bank is not None:\n",
        "                loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "            else:\n",
        "                loss = criterion(pred_rot, gt_rot)\n",
        "                \n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- C. REPORT & SAVE ---\n",
        "    print(f\"üìä Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save Best Model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        save_path = os.path.join(CHECKPOINT_DIR, \"best_model_rot.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, save_path)\n",
        "        print(f\"üèÜ New Best Rotation Model Saved! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save Last Checkpoint (for resuming if needed)\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'val_loss': avg_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_last.pth\"))\n",
        "\n",
        "# --- D. PLOTTING ---\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss (ADD Metric)')\n",
        "plt.plot(val_losses, label='Val Loss (ADD Metric)')\n",
        "plt.title('Rotation Training Convergence')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Distance (m)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'rotation_training_curve.png'))\n",
        "print(\"üéâ TRAINING COMPLETE! Training curve saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import trimesh\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure compute_ADD_metric_quaternion is imported or defined in your notebook\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD 3D MODELS AND DIAMETERS\n",
        "# ==========================================\n",
        "def load_models_info(models_dir, obj_ids, num_points=1000):\n",
        "    \"\"\"\n",
        "    Loads 3D meshes and calculates the DIAMETER for each object.\n",
        "    Returns:\n",
        "        point_cache: {id: points (N, 3)}\n",
        "        diameters:   {id: diameter (float)}\n",
        "    \"\"\"\n",
        "    point_cache = {}\n",
        "    diameters = {}\n",
        "    \n",
        "    unique_ids = sorted(list(set(obj_ids)))\n",
        "    print(f\"‚è≥ Loading info for {len(unique_ids)} 3D models...\")\n",
        "    \n",
        "    for oid in tqdm(unique_ids, desc=\"Mesh Analysis\"):\n",
        "        filename = f\"obj_{int(oid):02d}.ply\"\n",
        "        path = os.path.join(models_dir, filename)\n",
        "        \n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                mesh = trimesh.load(path)\n",
        "                \n",
        "                # 1. Sample Points (for ADD calculation)\n",
        "                points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
        "                point_cache[oid] = points / 1000.0 # Convert mm -> Meters\n",
        "                \n",
        "                # 2. Calculate Diameter (for Accuracy threshold)\n",
        "                # Standard LineMod method: Diagonal of the Bounding Box\n",
        "                extents = mesh.extents / 1000.0 # Meters\n",
        "                diameter = np.linalg.norm(extents)\n",
        "                diameters[oid] = diameter\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error loading {filename}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Missing model file: {path}\")\n",
        "            \n",
        "    return point_cache, diameters\n",
        "\n",
        "# ==========================================\n",
        "# 2. PANDAS EVALUATION FUNCTION\n",
        "# ==========================================\n",
        "def evaluate_with_pandas(model_rot, dataloader, device, models_dir, model_trans=None):\n",
        "    model_rot.eval()\n",
        "    if model_trans: model_trans.eval()\n",
        "    \n",
        "    # 1. Get unique IDs from the dataset to load specific meshes\n",
        "    try:\n",
        "        # Try to extract IDs from dataset if iterable\n",
        "        all_obj_ids = [s['object_id'] for s in dataloader.dataset]\n",
        "    except:\n",
        "        # Fallback if dataset is complex\n",
        "        all_obj_ids = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "\n",
        "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
        "    \n",
        "    # List to accumulate raw results\n",
        "    raw_results = []\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Benchmark (ADD Error + Accuracy)...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Inference\"):\n",
        "            # Move data to GPU\n",
        "            imgs = batch['image'].to(device)\n",
        "            gt_quats = batch['rotation'].to(device)\n",
        "            gt_trans = batch['translation'].to(device)\n",
        "            obj_ids = batch['object_id'] # CPU tensor\n",
        "            \n",
        "            # Predict Rotation\n",
        "            pred_quats = model_rot(imgs)\n",
        "            pred_trans_batch = gt_trans\n",
        "\n",
        "\n",
        "            # Convert to Numpy for metric calculation\n",
        "            pred_quats_np = pred_quats.cpu().numpy()\n",
        "            pred_trans_np = pred_trans_batch.cpu().numpy()\n",
        "            gt_quats_np = gt_quats.cpu().numpy()\n",
        "            gt_trans_np = gt_trans.cpu().numpy()\n",
        "            \n",
        "            # Loop through batch samples\n",
        "            batch_size = imgs.shape[0]\n",
        "            for i in range(batch_size):\n",
        "                curr_id = int(obj_ids[i])\n",
        "                \n",
        "                # Skip if we don't have 3D info for this object\n",
        "                if curr_id not in points_dict: \n",
        "                    continue\n",
        "                \n",
        "                # --- CALCULATE ADD METRIC (in Meters) ---\n",
        "                add_error = compute_ADD_metric_quaternion(\n",
        "                    model_points=points_dict[curr_id],\n",
        "                    gt_quat=gt_quats_np[i],\n",
        "                    gt_translation=gt_trans_np[i],\n",
        "                    pred_quat=pred_quats_np[i],\n",
        "                    pred_translation=pred_trans_np[i]\n",
        "                )\n",
        "                \n",
        "                # --- CALCULATE THRESHOLD & ACCURACY ---\n",
        "                diam = diameters_dict[curr_id]\n",
        "                threshold = diam * 0.1 # 10% of diameter\n",
        "                is_correct = add_error < threshold\n",
        "                \n",
        "                # Save raw result\n",
        "                raw_results.append({\n",
        "                    'obj_id': curr_id,\n",
        "                    'diameter_cm': diam * 100,\n",
        "                    'add_error_m': add_error,\n",
        "                    'add_error_cm': add_error * 100,\n",
        "                    'threshold_cm': threshold * 100,\n",
        "                    'is_correct': is_correct\n",
        "                })\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. GENERATE PANDAS REPORT\n",
        "    # ==========================================\n",
        "    if not raw_results:\n",
        "        print(\"‚ùå No results collected. Check your dataloader or model paths.\")\n",
        "        return None, None\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(raw_results)\n",
        "    \n",
        "    # Group by Object ID and calculate stats\n",
        "    report = df.groupby('obj_id').agg(\n",
        "        Samples=('obj_id', 'count'),\n",
        "        Diameter_cm=('diameter_cm', 'first'), \n",
        "        Mean_Error_cm=('add_error_cm', 'mean'),\n",
        "        Accuracy_pct=('is_correct', 'mean') # Mean of booleans is percentage\n",
        "    )\n",
        "    \n",
        "    # Format Accuracy column (0.69 -> 69.0)\n",
        "    report['Accuracy_pct'] = report['Accuracy_pct'] * 100\n",
        "    \n",
        "    # --- PRINT TABLE ---\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä DETAILED REPORT BY OBJECT\")\n",
        "    print(\"=\"*60)\n",
        "    # Use pandas to_string for nice formatting\n",
        "    print(report.to_string(float_format=\"{:.2f}\".format))\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # --- CALCULATE GLOBAL METRICS ---\n",
        "    total_correct = df['is_correct'].sum()\n",
        "    total_samples = len(df)\n",
        "    global_acc = (total_correct / total_samples) * 100\n",
        "    global_err = df['add_error_cm'].mean()\n",
        "    \n",
        "    print(f\"\\nüèÜ GLOBAL RESULTS (Entire Dataset)\")\n",
        "    print(f\"   ‚û§ Total Samples:       {total_samples}\")\n",
        "    print(f\"   ‚û§ Mean Error (ADD):    {global_err:.2f} cm\")\n",
        "    print(f\"   ‚û§ Accuracy (ADD-0.1d): {global_acc:.2f} %\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return report, df \n",
        "\n",
        "# --- USAGE EXAMPLE ---\n",
        "MODELS_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed/models'\n",
        "\n",
        "# Make sure 'compute_ADD_metric_quaternion' is defined before running\n",
        "report_df, raw_df = evaluate_with_pandas(model_rot, test_loader, DEVICE, MODELS_ROOT, model_trans=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONLY TRANSLATION TRAINING SCRIPT\n",
        "from src.pose_rgb import model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64        # Adjust if you run out of memory\n",
        "LR = 0.001             # Constant Learning Rate\n",
        "NUM_EPOCHS = 60\n",
        "CHECKPOINT_DIR = f'/kaggle/working/run_translation' \n",
        "DATA_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed'\n",
        "\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# ==========================================\n",
        "# 2. MODEL & OPTIMIZER SETUP\n",
        "# ==========================================\n",
        "print(f\"üß† Initializing Model on {DEVICE}...\")\n",
        "\n",
        "# Initialize your custom TranslationNet\n",
        "model_transl = TranslationNet().to(DEVICE)\n",
        "\n",
        "# Define Loss (Weighted to prioritize Depth Z)\n",
        "criterion = TranslationLoss(z_weight=1) \n",
        "\n",
        "# Simple Adam Optimizer (No Scheduler)\n",
        "optimizer = optim.Adam(model_transl.parameters(), lr=LR)\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==========================================\n",
        "best_val_mae = float('inf') # Track the best error to save the best model\n",
        "\n",
        "print(\"üöÄ Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # --- TRAIN PHASE ---\n",
        "    model_transl.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # Progress bar for training\n",
        "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "    \n",
        "    for batch in train_loop:\n",
        "        # Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)           # (B, 3, 224, 224)\n",
        "        bbox_info = batch['bbox_info'].to(DEVICE)  # (B, 4) Normalized BBox GPS\n",
        "        gt_trans = batch['translation'].to(DEVICE) # (B, 3) Absolute Translation in METERS\n",
        "\n",
        "        # Forward Pass\n",
        "        preds = model_transl(imgs, bbox_info)\n",
        "        \n",
        "        # Calculate Loss\n",
        "        loss = criterion(preds, gt_trans)\n",
        "        \n",
        "        # Backward Pass (Update Weights)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update stats\n",
        "        running_loss += loss.item()\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # --- VALIDATION PHASE ---\n",
        "    model_transl.eval()\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # Variables to calculate error in Centimeters (for human readability)\n",
        "    error_sum_xyz = np.array([0.0, 0.0, 0.0]) \n",
        "    total_samples = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Eval]\"):\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            bbox_info = batch['bbox_info'].to(DEVICE)\n",
        "            gt_trans = batch['translation'].to(DEVICE)\n",
        "\n",
        "            # Predict\n",
        "            preds = model_transl(imgs, bbox_info)\n",
        "            \n",
        "            # Calculate Loss\n",
        "            loss = criterion(preds, gt_trans)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            # Calculate Absolute Error (in Meters)\n",
        "            abs_err = torch.abs(preds - gt_trans).cpu().numpy()\n",
        "            error_sum_xyz += abs_err.sum(axis=0)\n",
        "            total_samples += imgs.shape[0]\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    \n",
        "    # Convert Mean Error to Centimeters\n",
        "    mean_error_m = error_sum_xyz / total_samples\n",
        "    mean_error_cm = mean_error_m * 100.0\n",
        "    total_mae_cm = np.mean(mean_error_cm) # Average error across X, Y, Z\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(f\"\\nüìä REPORT EPOCH {epoch+1}\")\n",
        "    print(f\"   Train Loss:    {avg_train_loss:.5f}\")\n",
        "    print(f\"   Val Loss:      {avg_val_loss:.5f}\")\n",
        "    print(f\"   --------------------------------\")\n",
        "    print(f\"   Error X:       {mean_error_cm[0]:.2f} cm\")\n",
        "    print(f\"   Error Y:       {mean_error_cm[1]:.2f} cm\")\n",
        "    print(f\"   Error Z:       {mean_error_cm[2]:.2f} cm (Depth)\")\n",
        "    print(f\"   --------------------------------\")\n",
        "    \n",
        "    # Save Best Model (if error is lower than previous best)\n",
        "    if total_mae_cm < best_val_mae:\n",
        "        best_val_mae = total_mae_cm\n",
        "        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/best_translation_model.pth\")\n",
        "        print(f\"   üíæ New Best Model Saved! (Avg Error: {total_mae_cm:.2f} cm)\")\n",
        "        \n",
        "    # Save periodic checkpoint every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/translation_ep{epoch+1}.pth\")\n",
        "\n",
        "print(\"\\n‚úÖ Training Complete. Best model saved in:\", CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate_translation_only(model_trans, dataloader, device):\n",
        "    \"\"\"\n",
        "    Evaluates only the Translation Model.\n",
        "    Reports Mean Absolute Error (MAE) in cm for X, Y, Z.\n",
        "    \"\"\"\n",
        "    model_trans.eval()\n",
        "    \n",
        "    raw_results = []\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Translation Benchmark...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Inference\"):\n",
        "            imgs = batch['image'].to(device)\n",
        "            bbox_info = batch['bbox_info'].to(device)\n",
        "            gt_trans = batch['translation'].to(device) # (B, 3) in Meters\n",
        "            obj_ids = batch['object_id']\n",
        "            \n",
        "            # Predict Translation\n",
        "            pred_trans = model_trans(imgs, bbox_info) # (B, 3)\n",
        "            \n",
        "            # Calculate Absolute Error (Meters)\n",
        "            # abs_err shape: (B, 3) -> [err_x, err_y, err_z]\n",
        "            abs_err = torch.abs(pred_trans - gt_trans).cpu().numpy()\n",
        "            \n",
        "            gt_np = gt_trans.cpu().numpy()\n",
        "            pred_np = pred_trans.cpu().numpy()\n",
        "            \n",
        "            batch_size = imgs.shape[0]\n",
        "            for i in range(batch_size):\n",
        "                curr_id = int(obj_ids[i])\n",
        "                \n",
        "                raw_results.append({\n",
        "                    'obj_id': curr_id,\n",
        "                    'err_x_cm': abs_err[i, 0] * 100,\n",
        "                    'err_y_cm': abs_err[i, 1] * 100,\n",
        "                    'err_z_cm': abs_err[i, 2] * 100,\n",
        "                    'total_err_cm': np.linalg.norm(abs_err[i]) * 100,\n",
        "                    'gt_z_m': gt_np[i, 2],    # Useful to see if error correlates with depth\n",
        "                    'pred_z_m': pred_np[i, 2]\n",
        "                })\n",
        "\n",
        "    if not raw_results:\n",
        "        print(\"‚ùå No results collected.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(raw_results)\n",
        "    \n",
        "    # Group by Object ID\n",
        "    report = df.groupby('obj_id').agg(\n",
        "        Samples=('obj_id', 'count'),\n",
        "        MAE_X_cm=('err_x_cm', 'mean'),\n",
        "        MAE_Y_cm=('err_y_cm', 'mean'),\n",
        "        MAE_Z_cm=('err_z_cm', 'mean'),\n",
        "        Mean_Total_Error_cm=('total_err_cm', 'mean')\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*65)\n",
        "    print(\"üìä TRANSLATION REPORT (Mean Absolute Error in cm)\")\n",
        "    print(\"=\"*65)\n",
        "    print(report.to_string(float_format=\"{:.2f}\".format))\n",
        "    print(\"=\"*65)\n",
        "    \n",
        "    # Global Stats\n",
        "    print(f\"\\nüèÜ GLOBAL TRANSLATION RESULTS\")\n",
        "    print(f\"   ‚û§ Mean Error X: {df['err_x_cm'].mean():.2f} cm\")\n",
        "    print(f\"   ‚û§ Mean Error Y: {df['err_y_cm'].mean():.2f} cm\")\n",
        "    print(f\"   ‚û§ Mean Error Z: {df['err_z_cm'].mean():.2f} cm (Depth)\")\n",
        "    print(f\"   ‚û§ Mean Euclidean Dist: {df['total_err_cm'].mean():.2f} cm\")\n",
        "    print(\"=\"*65)\n",
        "    \n",
        "    return report, df\n",
        "\n",
        "report_df, raw_df = evaluate_translation_only(model_transl, test_loader, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import trimesh\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# MAIN: FULL 6D EVALUATION\n",
        "# ==========================================\n",
        "def evaluate_full_6d(model_rot, model_trans, dataloader, device, models_dir):\n",
        "    \"\"\"\n",
        "    Evaluates the complete 6D Pose Estimation pipeline.\n",
        "    Combines RotationNet + TranslationNet predictions.\n",
        "    Computes ADD Metric and ADD-0.1d Accuracy.\n",
        "    \"\"\"\n",
        "    model_rot.eval()\n",
        "    model_trans.eval()\n",
        "    \n",
        "    # 1. Load 3D Models Info\n",
        "    try:\n",
        "        all_obj_ids = [s['object_id'] for s in dataloader.dataset]\n",
        "    except:\n",
        "        all_obj_ids = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "\n",
        "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
        "    \n",
        "    raw_results = []\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Full 6D Pose Benchmark...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Inference\"):\n",
        "            # Inputs\n",
        "            imgs = batch['image'].to(device)\n",
        "            bbox_info = batch['bbox_info'].to(device)\n",
        "            obj_ids = batch['object_id']\n",
        "            \n",
        "            # Ground Truth\n",
        "            gt_quats = batch['rotation'].to(device)    # (B, 4)\n",
        "            gt_trans = batch['translation'].to(device) # (B, 3) in Meters\n",
        "            \n",
        "            # --- PREDICTIONS ---\n",
        "            # 1. Predict Rotation\n",
        "            pred_quats = model_rot(imgs)\n",
        "            \n",
        "            # 2. Predict Translation\n",
        "            pred_trans = model_trans(imgs, bbox_info)\n",
        "            \n",
        "            # Convert to Numpy\n",
        "            pred_q_np = pred_quats.cpu().numpy()\n",
        "            pred_t_np = pred_trans.cpu().numpy()\n",
        "            gt_q_np = gt_quats.cpu().numpy()\n",
        "            gt_t_np = gt_trans.cpu().numpy()\n",
        "            \n",
        "            batch_size = imgs.shape[0]\n",
        "            for i in range(batch_size):\n",
        "                curr_id = int(obj_ids[i])\n",
        "                \n",
        "                if curr_id not in points_dict: continue\n",
        "                \n",
        "                # --- METRIC COMPUTATION (ADD) ---\n",
        "                # Computes the average distance between transformed model points\n",
        "                # using GT pose vs Predicted pose.\n",
        "                add_error = compute_ADD_metric_quaternion(\n",
        "                    model_points=points_dict[curr_id],\n",
        "                    gt_quat=gt_q_np[i],\n",
        "                    gt_translation=gt_t_np[i],\n",
        "                    pred_quat=pred_q_np[i],\n",
        "                    pred_translation=pred_t_np[i]\n",
        "                )\n",
        "                \n",
        "                # --- ACCURACY CHECK ---\n",
        "                diam = diameters_dict[curr_id]\n",
        "                threshold = diam * 0.1 # 10% of diameter\n",
        "                is_correct = add_error < threshold\n",
        "                \n",
        "                # Store Data\n",
        "                raw_results.append({\n",
        "                    'obj_id': curr_id,\n",
        "                    'diameter_cm': diam * 100,\n",
        "                    'add_error_cm': add_error * 100,\n",
        "                    'is_correct': is_correct,\n",
        "                    'err_trans_cm': np.linalg.norm(pred_t_np[i] - gt_t_np[i]) * 100 # Trans error only\n",
        "                })\n",
        "\n",
        "    if not raw_results:\n",
        "        print(\"‚ùå No results collected.\")\n",
        "        return None, None\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    df = pd.DataFrame(raw_results)\n",
        "    \n",
        "    report = df.groupby('obj_id').agg(\n",
        "        Samples=('obj_id', 'count'),\n",
        "        Diameter_cm=('diameter_cm', 'first'),\n",
        "        ADD_Error_cm=('add_error_cm', 'mean'), # Combined Error (Rot + Trans)\n",
        "        Trans_Error_cm=('err_trans_cm', 'mean'), # Translation Error only\n",
        "        Accuracy_pct=('is_correct', 'mean')\n",
        "    )\n",
        "    \n",
        "    report['Accuracy_pct'] = report['Accuracy_pct'] * 100\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä FULL 6D POSE REPORT (Rotation + Translation)\")\n",
        "    print(\"=\"*80)\n",
        "    print(report.to_string(float_format=\"{:.2f}\".format))\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Global Stats\n",
        "    total_acc = (df['is_correct'].sum() / len(df)) * 100\n",
        "    print(f\"\\nüèÜ GLOBAL 6D RESULTS\")\n",
        "    print(f\"   ‚û§ Mean ADD Error:      {df['add_error_cm'].mean():.2f} cm\")\n",
        "    print(f\"   ‚û§ Mean Trans. Error:   {df['err_trans_cm'].mean():.2f} cm\")\n",
        "    print(f\"   ‚û§ Final Accuracy:      {total_acc:.2f} %\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    return report, df\n",
        "\n",
        "MODELS_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed/models'\n",
        "report_df, raw_df = evaluate_full_6d(model_rot, model_transl, test_loader, DEVICE, MODELS_ROOT)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlVenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
