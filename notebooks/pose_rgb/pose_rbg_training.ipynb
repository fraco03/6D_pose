{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oAXrKjNq32c",
        "outputId": "18b06df5-2594-43f9-dade-e6187644f8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6D_pose'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 174 (delta 87), reused 113 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 2.23 MiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Cloned https://github.com/fraco03/6D_pose.git to /content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown -q\n",
        "print(\"Downloading folder from Drive...\")\n",
        "# Downloads the folder structure containing the Linemod dataset\n",
        "!gdown \"https://drive.google.com/file/d/1Zwh-gAk_-CBgpOcNLPLdFNxggi3NTh-S/view?usp=drive_link\" --fuzzy\n",
        "import glob\n",
        "zip_files = glob.glob(\"**/Linemod_preprocessed.zip\", recursive=True)\n",
        "\n",
        "if zip_files:\n",
        "    zip_path = zip_files[0]\n",
        "    print(f\"Unzipping {zip_path}...\")\n",
        "    !unzip -q -o \"{zip_path}\"\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"Error: Linemod_preprocessed.zip not found. Check the download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
        "branch = \"main\"\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancella tutte le cartelle __pycache__ ricorsivamente nella directory di lavoro\n",
        "!find . -name \"__pycache__\" -type d -exec rm -rf {} +\n",
        "print(\"ðŸ—‘ï¸ Cache pulita dal disco.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea5j56JR7NjI"
      },
      "outputs": [],
      "source": [
        "!pip install plyfile\n",
        "from src.pose_rgb.dataset import LineModPoseDataset\n",
        "from src.pose_rgb.model import ResNetRotation, TranslationNet\n",
        "from src.pose_rgb.pose_utils import quaternion_to_rotation_matrix, convert_rotation_to_quaternion, inverse_pinhole_projection\n",
        "from src.pose_rgb.test_dataset import *\n",
        "from src.pose_rgb.loss import CombinedPoseLoss, MultiObjectPointMatchingLoss, TranslationLoss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pathlib\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from utils.projection_utils import *\n",
        "from utils.linemod_config import *\n",
        "from metrics import compute_ADD_metric_quaternion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrOmeFj_sRID",
        "outputId": "d3a4e969-a16f-4f10-ac1a-e0ffe7eb5e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded LineModPoseDataset\n",
            "   Split: train\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 3631\n",
            " Loaded LineModPoseDataset\n",
            "   Split: test\n",
            "   Dir : [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 20528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/kaggle/input/line-mode/Linemod_preprocessed' #Modify here for kaggle\n",
        "\n",
        "train_dataset = LineModPoseDataset(split='train', root_dir=root_dir)\n",
        "test_dataset = LineModPoseDataset(split='test', root_dir=root_dir)\n",
        "\n",
        "#Dataloder\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import os\n",
        "\n",
        "def load_all_object_points(models_dir, valid_obj_ids, num_points=1000):\n",
        "    \"\"\"\n",
        "    Loads .ply files for ALL objects and stacks them into a single Tensor.\n",
        "    \n",
        "    Args:\n",
        "        models_dir (str): Folder containing .ply files (e.g., 'obj_01.ply').\n",
        "        valid_obj_ids (list): List of integers IDs (e.g., [1, 5, 6...]).\n",
        "        num_points (int): Number of points to sample per object.\n",
        "        \n",
        "    Returns:\n",
        "        torch.Tensor: Shape (Num_Classes, num_points, 3).\n",
        "                      The index in dimension 0 corresponds to the index in valid_obj_ids.\n",
        "    \"\"\"\n",
        "    all_points_list = []\n",
        "    \n",
        "    print(f\"ðŸ“¦ Loading {len(valid_obj_ids)} 3D models from {models_dir}...\")\n",
        "    \n",
        "    for i, obj_id in enumerate(valid_obj_ids):\n",
        "        # Construct filename assuming LineMod format (e.g., 'obj_01.ply')\n",
        "        ply_name = f\"obj_{obj_id:02d}.ply\" \n",
        "        ply_path = os.path.join(models_dir, ply_name)\n",
        "        \n",
        "        if not os.path.exists(ply_path):\n",
        "            raise FileNotFoundError(f\"Model not found: {ply_path}\")\n",
        "\n",
        "        # Load mesh\n",
        "        mesh = trimesh.load(ply_path)\n",
        "        vertices = np.array(mesh.vertices)\n",
        "        \n",
        "        # Sample points\n",
        "        if len(vertices) > num_points:\n",
        "            idx = np.random.choice(len(vertices), num_points, replace=False)\n",
        "            selected = vertices[idx]\n",
        "        else:\n",
        "            # Padding via repetition if not enough points (rare in LineMod)\n",
        "            choice = np.random.choice(len(vertices), num_points, replace=True)\n",
        "            selected = vertices[choice]\n",
        "            \n",
        "        # Add to list\n",
        "        all_points_list.append(selected)\n",
        "\n",
        "    # Stack into a single tensor\n",
        "    # Shape: (Num_Classes, Num_Points, 3)\n",
        "    # Example: (13, 1000, 3)\n",
        "    bank_tensor = torch.from_numpy(np.array(all_points_list)).float()\n",
        "    \n",
        "    # Unit conversion (mm to meters) if needed\n",
        "    # bank_tensor = bank_tensor / 1000.0 \n",
        "    \n",
        "    return bank_tensor / 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LINEMOD_NAMES = [\n",
        "            'ape',         # Index 0 (ID 1)\n",
        "            'benchvise',   # Index 1 (ID 2)\n",
        "            'camera',      # Index 2 (ID 4)\n",
        "            'can',         # Index 3 (ID 5)\n",
        "            'cat',         # Index 4 (ID 6)\n",
        "            'driller',     # Index 5 (ID 8)\n",
        "            'duck',        # Index 6 (ID 9)\n",
        "            'eggbox',      # Index 7 (ID 10)\n",
        "            'glue',        # Index 8 (ID 11)\n",
        "            'holepuncher', # Index 9 (ID 12)\n",
        "            'iron',        # Index 10 (ID 13)\n",
        "            'lamp',        # Index 11 (ID 14)\n",
        "            'phone'        # Index 12 (ID 15)\n",
        "        ]\n",
        "name_to_idx = {name: i for i, name in enumerate(LINEMOD_NAMES)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROTATION ONLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONLY ROTATION TRAINING SCRIPT\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & HYPERPARAMETERS\n",
        "# ==========================================\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# --- PATHS ---\n",
        "# Define where your .ply models are located\n",
        "MODELS_DIR = '/kaggle/input/line-mode/Linemod_preprocessed/models' \n",
        "# List of valid object IDs in your dataset (must match your dataset logic)\n",
        "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
        "\n",
        "# --- LOGGING SETUP ---\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "# Directory to save checkpoints and logs\n",
        "CHECKPOINT_DIR = f'/kaggle/working/run_rotation' \n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "run_dir = CHECKPOINT_DIR\n",
        "\n",
        "print(f\"\\nðŸ”¥ STARTING ROTATION-ONLY TRAINING on {DEVICE}...\")\n",
        "print(f\"ðŸ“ Saving outputs to: {run_dir}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. INITIALIZE LOSS & MODELS\n",
        "# ==========================================\n",
        "\n",
        "# A. LOAD 3D POINTS FOR LOSS\n",
        "# We need to load the point clouds for all objects to use PointMatchingLoss.\n",
        "print(\"ðŸ“¦ Loading 3D Point Clouds for Loss Function...\")\n",
        "# Use the helper function we defined earlier to load all ply files\n",
        "point_bank = load_all_object_points(MODELS_DIR, VALID_OBJ_IDS, num_points=1000)\n",
        "point_bank = point_bank.to(DEVICE) # Move entire bank to GPU\n",
        "\n",
        "\n",
        "# B. DEFINE LOSS FUNCTION\n",
        "\n",
        "criterion = MultiObjectPointMatchingLoss(point_bank).to(DEVICE)\n",
        "\n",
        "# C. INITIALIZE MODEL\n",
        "# We only use the Rotation Network\n",
        "model_rot = ResNetRotation(freeze_backbone=False).to(DEVICE)\n",
        "\n",
        "# D. OPTIMIZER\n",
        "# We only optimize the rotation model parameters\n",
        "optimizer = optim.Adam(\n",
        "    model_rot.parameters(),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# E. METRICS STORAGE\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- A. TRAIN PHASE ---\n",
        "    model_rot.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    # Progress Bar\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # 1. Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)\n",
        "        gt_rot = batch['rotation'].to(DEVICE)\n",
        "        \n",
        "        # We need class indices for the PointMatchingLoss (Index 0 to 12)\n",
        "        # Ensure your Dataset returns 'class_id' as a mapped index (0..N), NOT the raw Linemod ID (1,5,8..)\n",
        "        raw_names_list = batch['class_idx'] # es. ['can', 'ape', 'driller']\n",
        "        \n",
        "        \n",
        "        try:\n",
        "            indices = [name_to_idx[name] for name in raw_names_list]\n",
        "        except KeyError as e:\n",
        "            print(f\"âŒ ERRORE CRITICO: Trovato nome '{e}' non presente nella lista LINEMOD_NAMES!\")\n",
        "            raise e\n",
        "\n",
        "        \n",
        "        class_ids = torch.tensor(indices, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "        # 2. Forward Pass\n",
        "        pred_rot = model_rot(imgs)\n",
        "\n",
        "        # 3. Calculate Loss\n",
        "        # Pass class_ids so the loss knows which 3D model to use for each image in the batch\n",
        "        if point_bank is not None:\n",
        "            loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "        else:\n",
        "            loss = criterion(pred_rot, gt_rot) # Fallback doesn't use IDs\n",
        "\n",
        "        # 4. Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 5. Logging\n",
        "        running_train_loss += loss.item()\n",
        "        pbar.set_postfix({'ADD Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- B. EVALUATION PHASE ---\n",
        "    model_rot.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50  # Validate on a subset to save time per epoch\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            gt_rot = batch['rotation'].to(DEVICE)\n",
        "            raw_names_list = batch['class_idx'] # es. ['can', 'ape', 'driller']\n",
        "            \n",
        "            \n",
        "            try:\n",
        "                indices = [name_to_idx[name] for name in raw_names_list]\n",
        "            except KeyError as e:\n",
        "                print(f\"âŒ ERRORE CRITICO: Trovato nome '{e}' non presente nella lista LINEMOD_NAMES!\")\n",
        "                raise e\n",
        "    \n",
        "            \n",
        "            class_ids = torch.tensor(indices, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "            # Forward\n",
        "            pred_rot = model_rot(imgs)\n",
        "\n",
        "            # Loss\n",
        "            if point_bank is not None:\n",
        "                loss = criterion(pred_rot, gt_rot, class_ids)\n",
        "            else:\n",
        "                loss = criterion(pred_rot, gt_rot)\n",
        "                \n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- C. REPORT & SAVE ---\n",
        "    print(f\"ðŸ“Š Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save Best Model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        save_path = os.path.join(CHECKPOINT_DIR, \"best_model_rot.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, save_path)\n",
        "        print(f\"ðŸ† New Best Rotation Model Saved! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save Last Checkpoint (for resuming if needed)\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_rot.state_dict(),\n",
        "            'val_loss': avg_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_last.pth\"))\n",
        "\n",
        "# --- D. PLOTTING ---\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss (ADD Metric)')\n",
        "plt.plot(val_losses, label='Val Loss (ADD Metric)')\n",
        "plt.title('Rotation Training Convergence')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Distance (m)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'rotation_training_curve.png'))\n",
        "print(\"ðŸŽ‰ TRAINING COMPLETE! Training curve saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Translation ONLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONLY TRANSLATION TRAINING SCRIPT\n",
        "from src.pose_rgb import model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64        # Adjust if you run out of memory\n",
        "LR = 0.001             # Constant Learning Rate\n",
        "NUM_EPOCHS = 60\n",
        "CHECKPOINT_DIR = f'/kaggle/working/run_translation' \n",
        "DATA_ROOT = '/kaggle/input/line-mode/Linemod_preprocessed'\n",
        "\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# ==========================================\n",
        "# 2. MODEL & OPTIMIZER SETUP\n",
        "# ==========================================\n",
        "print(f\"ðŸ§  Initializing Model on {DEVICE}...\")\n",
        "\n",
        "# Initialize your custom TranslationNet\n",
        "model_transl = TranslationNet().to(DEVICE)\n",
        "\n",
        "# Define Loss (Weighted to prioritize Depth Z)\n",
        "criterion = TranslationLoss(z_weight=1) \n",
        "\n",
        "# Simple Adam Optimizer (No Scheduler)\n",
        "optimizer = optim.Adam(model_transl.parameters(), lr=LR)\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==========================================\n",
        "best_val_mae = float('inf') # Track the best error to save the best model\n",
        "\n",
        "print(\"ðŸš€ Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # --- TRAIN PHASE ---\n",
        "    model_transl.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # Progress bar for training\n",
        "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "    \n",
        "    for batch in train_loop:\n",
        "        # Move data to GPU\n",
        "        imgs = batch['image'].to(DEVICE)           # (B, 3, 224, 224)\n",
        "        bbox_info = batch['bbox_info'].to(DEVICE)  # (B, 4) Normalized BBox GPS\n",
        "        gt_trans = batch['translation'].to(DEVICE) # (B, 3) Absolute Translation in METERS\n",
        "\n",
        "        # Forward Pass\n",
        "        preds = model_transl(imgs, bbox_info)\n",
        "        \n",
        "        # Calculate Loss\n",
        "        loss = criterion(preds, gt_trans)\n",
        "        \n",
        "        # Backward Pass (Update Weights)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update stats\n",
        "        running_loss += loss.item()\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # --- VALIDATION PHASE ---\n",
        "    model_transl.eval()\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # Variables to calculate error in Centimeters (for human readability)\n",
        "    error_sum_xyz = np.array([0.0, 0.0, 0.0]) \n",
        "    total_samples = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Eval]\"):\n",
        "            imgs = batch['image'].to(DEVICE)\n",
        "            bbox_info = batch['bbox_info'].to(DEVICE)\n",
        "            gt_trans = batch['translation'].to(DEVICE)\n",
        "\n",
        "            # Predict\n",
        "            preds = model_transl(imgs, bbox_info)\n",
        "            \n",
        "            # Calculate Loss\n",
        "            loss = criterion(preds, gt_trans)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            # Calculate Absolute Error (in Meters)\n",
        "            abs_err = torch.abs(preds - gt_trans).cpu().numpy()\n",
        "            error_sum_xyz += abs_err.sum(axis=0)\n",
        "            total_samples += imgs.shape[0]\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    \n",
        "    # Convert Mean Error to Centimeters\n",
        "    mean_error_m = error_sum_xyz / total_samples\n",
        "    mean_error_cm = mean_error_m * 100.0\n",
        "    total_mae_cm = np.mean(mean_error_cm) # Average error across X, Y, Z\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(f\"\\nðŸ“Š REPORT EPOCH {epoch+1}\")\n",
        "    print(f\"   Train Loss:    {avg_train_loss:.5f}\")\n",
        "    print(f\"   Val Loss:      {avg_val_loss:.5f}\")\n",
        "    print(f\"   --------------------------------\")\n",
        "    print(f\"   Error X:       {mean_error_cm[0]:.2f} cm\")\n",
        "    print(f\"   Error Y:       {mean_error_cm[1]:.2f} cm\")\n",
        "    print(f\"   Error Z:       {mean_error_cm[2]:.2f} cm (Depth)\")\n",
        "    print(f\"   --------------------------------\")\n",
        "    \n",
        "    # Save Best Model (if error is lower than previous best)\n",
        "    if total_mae_cm < best_val_mae:\n",
        "        best_val_mae = total_mae_cm\n",
        "        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/best_translation_model.pth\")\n",
        "        print(f\"   ðŸ’¾ New Best Model Saved! (Avg Error: {total_mae_cm:.2f} cm)\")\n",
        "        \n",
        "    # Save periodic checkpoint every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        torch.save(model_transl.state_dict(), f\"{CHECKPOINT_DIR}/translation_ep{epoch+1}.pth\")\n",
        "\n",
        "print(\"\\nâœ… Training Complete. Best model saved in:\", CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¥ Loading 3D model points and diameters...\n",
            "ðŸ“¦ Loading trained model...\n",
            "ðŸ“š Preparing test dataset and dataloader...\n",
            " Loaded LineModPoseDepthDataset\n",
            "   Split: test (Ratio: 0.20)\n",
            "   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 4867\n",
            "\n",
            "ðŸš€ Starting Comprehensive Benchmark (ADD Error + ADD-0.1d Accuracy)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [16:03<00:00, 24.70s/batch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Evaluation report saved to ./RGB_run/evaluation_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Object ID",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Object Name",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Diameter (mm)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Mean ADD (mm)",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "Mean ADD-S (mm)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Mean ADD-Rot (mm)",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "Mean ADD-S-Rot (mm)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ADD-0.1d Accuracy (%)",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ADD-S-0.1d Accuracy (%)",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "65e66c02-a04f-4a2c-bf74-f4c2ba6a16f3",
              "rows": [
                [
                  "0",
                  "1",
                  "ape",
                  "102.09865663",
                  "6.3711176",
                  "2.1292544287237",
                  "6.3711176",
                  "2.1292544287237",
                  "86.86440677966102",
                  "99.78813559322035"
                ],
                [
                  "1",
                  "2",
                  "benchvise",
                  "247.50624233",
                  "12.7289715",
                  "5.129824546231763",
                  "12.7289715",
                  "5.129824546231763",
                  "92.14876033057851",
                  "100.0"
                ],
                [
                  "2",
                  "5",
                  "can",
                  "201.40358597",
                  "10.640517",
                  "3.6934506261609434",
                  "10.640517",
                  "3.6934506261609434",
                  "93.9203354297694",
                  "99.79035639412997"
                ],
                [
                  "3",
                  "6",
                  "cat",
                  "154.54551808",
                  "7.6868267",
                  "3.226671479561668",
                  "7.6868267",
                  "3.226671479561668",
                  "92.37472766884531",
                  "99.12854030501089"
                ],
                [
                  "4",
                  "8",
                  "driller",
                  "261.47178102",
                  "11.04353",
                  "5.103863760619234",
                  "11.04353",
                  "5.103863760619234",
                  "96.21052631578947",
                  "100.0"
                ],
                [
                  "5",
                  "9",
                  "duck",
                  "108.99920102",
                  "8.140133",
                  "2.7549539564965917",
                  "8.140133",
                  "2.7549539564965917",
                  "83.60995850622407",
                  "99.79253112033194"
                ],
                [
                  "6",
                  "10",
                  "eggbox",
                  "164.62758848",
                  "10.934605",
                  "3.253343872492656",
                  "10.934605",
                  "3.253343872492656",
                  "87.73148148148148",
                  "100.0"
                ],
                [
                  "7",
                  "11",
                  "glue",
                  "175.88933422",
                  "8.390186",
                  "3.7778694538121496",
                  "8.390186",
                  "3.7778694538121496",
                  "95.16129032258065",
                  "100.0"
                ],
                [
                  "8",
                  "12",
                  "holepuncher",
                  "145.54287471",
                  "9.141986",
                  "2.895302563732996",
                  "9.141986",
                  "2.895302563732996",
                  "85.91836734693878",
                  "100.0"
                ],
                [
                  "9",
                  "4",
                  "camera",
                  "172.49224865",
                  "8.40986",
                  "3.107157819201605",
                  "8.40986",
                  "3.107157819201605",
                  "95.0207468879668",
                  "100.0"
                ],
                [
                  "10",
                  "13",
                  "iron",
                  "278.07811733",
                  "12.014362",
                  "5.025002339360982",
                  "12.014362",
                  "5.025002339360982",
                  "95.23809523809523",
                  "100.0"
                ],
                [
                  "11",
                  "14",
                  "lamp",
                  "282.60129399",
                  "11.619051",
                  "4.726791443154207",
                  "11.619051",
                  "4.726791443154207",
                  "98.36734693877551",
                  "100.0"
                ],
                [
                  "12",
                  "15",
                  "phone",
                  "212.35825148",
                  "12.144069",
                  "4.6267420177680245",
                  "12.144069",
                  "4.6267420177680245",
                  "90.76305220883533",
                  "100.0"
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 13
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Object ID</th>\n",
              "      <th>Object Name</th>\n",
              "      <th>Diameter (mm)</th>\n",
              "      <th>Mean ADD (mm)</th>\n",
              "      <th>Mean ADD-S (mm)</th>\n",
              "      <th>Mean ADD-Rot (mm)</th>\n",
              "      <th>Mean ADD-S-Rot (mm)</th>\n",
              "      <th>ADD-0.1d Accuracy (%)</th>\n",
              "      <th>ADD-S-0.1d Accuracy (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ape</td>\n",
              "      <td>102.098657</td>\n",
              "      <td>6.371118</td>\n",
              "      <td>2.129254</td>\n",
              "      <td>6.371118</td>\n",
              "      <td>2.129254</td>\n",
              "      <td>86.864407</td>\n",
              "      <td>99.788136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>benchvise</td>\n",
              "      <td>247.506242</td>\n",
              "      <td>12.728971</td>\n",
              "      <td>5.129825</td>\n",
              "      <td>12.728971</td>\n",
              "      <td>5.129825</td>\n",
              "      <td>92.148760</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>can</td>\n",
              "      <td>201.403586</td>\n",
              "      <td>10.640517</td>\n",
              "      <td>3.693451</td>\n",
              "      <td>10.640517</td>\n",
              "      <td>3.693451</td>\n",
              "      <td>93.920335</td>\n",
              "      <td>99.790356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>cat</td>\n",
              "      <td>154.545518</td>\n",
              "      <td>7.686827</td>\n",
              "      <td>3.226671</td>\n",
              "      <td>7.686827</td>\n",
              "      <td>3.226671</td>\n",
              "      <td>92.374728</td>\n",
              "      <td>99.128540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>driller</td>\n",
              "      <td>261.471781</td>\n",
              "      <td>11.043530</td>\n",
              "      <td>5.103864</td>\n",
              "      <td>11.043530</td>\n",
              "      <td>5.103864</td>\n",
              "      <td>96.210526</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9</td>\n",
              "      <td>duck</td>\n",
              "      <td>108.999201</td>\n",
              "      <td>8.140133</td>\n",
              "      <td>2.754954</td>\n",
              "      <td>8.140133</td>\n",
              "      <td>2.754954</td>\n",
              "      <td>83.609959</td>\n",
              "      <td>99.792531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>eggbox</td>\n",
              "      <td>164.627588</td>\n",
              "      <td>10.934605</td>\n",
              "      <td>3.253344</td>\n",
              "      <td>10.934605</td>\n",
              "      <td>3.253344</td>\n",
              "      <td>87.731481</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11</td>\n",
              "      <td>glue</td>\n",
              "      <td>175.889334</td>\n",
              "      <td>8.390186</td>\n",
              "      <td>3.777869</td>\n",
              "      <td>8.390186</td>\n",
              "      <td>3.777869</td>\n",
              "      <td>95.161290</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12</td>\n",
              "      <td>holepuncher</td>\n",
              "      <td>145.542875</td>\n",
              "      <td>9.141986</td>\n",
              "      <td>2.895303</td>\n",
              "      <td>9.141986</td>\n",
              "      <td>2.895303</td>\n",
              "      <td>85.918367</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>camera</td>\n",
              "      <td>172.492249</td>\n",
              "      <td>8.409860</td>\n",
              "      <td>3.107158</td>\n",
              "      <td>8.409860</td>\n",
              "      <td>3.107158</td>\n",
              "      <td>95.020747</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13</td>\n",
              "      <td>iron</td>\n",
              "      <td>278.078117</td>\n",
              "      <td>12.014362</td>\n",
              "      <td>5.025002</td>\n",
              "      <td>12.014362</td>\n",
              "      <td>5.025002</td>\n",
              "      <td>95.238095</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>14</td>\n",
              "      <td>lamp</td>\n",
              "      <td>282.601294</td>\n",
              "      <td>11.619051</td>\n",
              "      <td>4.726791</td>\n",
              "      <td>11.619051</td>\n",
              "      <td>4.726791</td>\n",
              "      <td>98.367347</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>phone</td>\n",
              "      <td>212.358251</td>\n",
              "      <td>12.144069</td>\n",
              "      <td>4.626742</td>\n",
              "      <td>12.144069</td>\n",
              "      <td>4.626742</td>\n",
              "      <td>90.763052</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Object ID  Object Name  Diameter (mm)  Mean ADD (mm)  Mean ADD-S (mm)  \\\n",
              "0           1          ape     102.098657       6.371118         2.129254   \n",
              "1           2    benchvise     247.506242      12.728971         5.129825   \n",
              "2           5          can     201.403586      10.640517         3.693451   \n",
              "3           6          cat     154.545518       7.686827         3.226671   \n",
              "4           8      driller     261.471781      11.043530         5.103864   \n",
              "5           9         duck     108.999201       8.140133         2.754954   \n",
              "6          10       eggbox     164.627588      10.934605         3.253344   \n",
              "7          11         glue     175.889334       8.390186         3.777869   \n",
              "8          12  holepuncher     145.542875       9.141986         2.895303   \n",
              "9           4       camera     172.492249       8.409860         3.107158   \n",
              "10         13         iron     278.078117      12.014362         5.025002   \n",
              "11         14         lamp     282.601294      11.619051         4.726791   \n",
              "12         15        phone     212.358251      12.144069         4.626742   \n",
              "\n",
              "    Mean ADD-Rot (mm)  Mean ADD-S-Rot (mm)  ADD-0.1d Accuracy (%)  \\\n",
              "0            6.371118             2.129254              86.864407   \n",
              "1           12.728971             5.129825              92.148760   \n",
              "2           10.640517             3.693451              93.920335   \n",
              "3            7.686827             3.226671              92.374728   \n",
              "4           11.043530             5.103864              96.210526   \n",
              "5            8.140133             2.754954              83.609959   \n",
              "6           10.934605             3.253344              87.731481   \n",
              "7            8.390186             3.777869              95.161290   \n",
              "8            9.141986             2.895303              85.918367   \n",
              "9            8.409860             3.107158              95.020747   \n",
              "10          12.014362             5.025002              95.238095   \n",
              "11          11.619051             4.726791              98.367347   \n",
              "12          12.144069             4.626742              90.763052   \n",
              "\n",
              "    ADD-S-0.1d Accuracy (%)  \n",
              "0                 99.788136  \n",
              "1                100.000000  \n",
              "2                 99.790356  \n",
              "3                 99.128540  \n",
              "4                100.000000  \n",
              "5                 99.792531  \n",
              "6                100.000000  \n",
              "7                100.000000  \n",
              "8                100.000000  \n",
              "9                100.000000  \n",
              "10               100.000000  \n",
              "11               100.000000  \n",
              "12               100.000000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.pose_rgb.evaluate import evaluate_RGB, evaluate_RGB_rot_only\n",
        "\n",
        "model_path = \"./RGB_run/best_model_rot.pth\"\n",
        "dataset_root = \"../../Linemod_preprocessed\"\n",
        "output_path = \"./RGB_run/evaluation_results.csv\"\n",
        "\n",
        "\n",
        "df = evaluate_RGB_rot_only(\n",
        "    model_path=model_path,\n",
        "    dataset_root=dataset_root,\n",
        "    output_path=output_path\n",
        ")\n",
        "    \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LineModConfig initialized: F:\\Magistrale\\Advanced Machine Learning\\6D_pose\\Linemod_preprocessed\n",
            " Loaded LineModPoseDataset\n",
            "   Split: test (Ratio: 0.20)\n",
            "   Objects: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "   Total samples: 3163\n"
          ]
        }
      ],
      "source": [
        "from src.pose_rgb.dataset import LineModPoseDataset\n",
        "dataset_root = \"../../Linemod_preprocessed\"\n",
        "test = LineModPoseDataset(split='test', root_dir=dataset_root)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlVenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
