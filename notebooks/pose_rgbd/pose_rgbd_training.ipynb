{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RSmCHsiKpedw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:36:38.948664Z",
     "iopub.status.busy": "2025-12-19T17:36:38.947931Z",
     "iopub.status.idle": "2025-12-19T17:36:38.953280Z",
     "shell.execute_reply": "2025-12-19T17:36:38.952701Z",
     "shell.execute_reply.started": "2025-12-19T17:36:38.948634Z"
    },
    "id": "RSmCHsiKpedw",
    "outputId": "1607c3d0-06b6-49cf-a79f-341a28e59ccc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9d769-d620-4a8d-8bac-0dadc377f860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:49:46.165767Z",
     "iopub.status.busy": "2025-12-19T17:49:46.165144Z",
     "iopub.status.idle": "2025-12-19T17:49:46.362309Z",
     "shell.execute_reply": "2025-12-19T17:49:46.361509Z",
     "shell.execute_reply.started": "2025-12-19T17:49:46.165733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%rm -rf 6D_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xEYIdHR9pfkm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEYIdHR9pfkm",
    "outputId": "bf5cf3c2-c59b-4fc9-e48f-7fbd3d0d8a75"
   },
   "outputs": [],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25573688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:49:54.794887Z",
     "iopub.status.busy": "2025-12-19T17:49:54.794107Z",
     "iopub.status.idle": "2025-12-19T17:49:55.725496Z",
     "shell.execute_reply": "2025-12-19T17:49:55.724762Z",
     "shell.execute_reply.started": "2025-12-19T17:49:54.794854Z"
    },
    "id": "25573688",
    "outputId": "72321497-6c3a-436b-90f0-fd5df011e398",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull part\n",
    "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
    "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
    "branch = \"pose_rgbd\"\n",
    "\n",
    "# Clone if missing\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -b {branch} {repo_url}\n",
    "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
    "else:\n",
    "    %cd {repo_dir}\n",
    "    !git fetch origin\n",
    "    !git checkout {branch}\n",
    "    !git reset --hard origin/{branch}\n",
    "    # %cd ..\n",
    "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
    "\n",
    "# Add repository to Python path\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdEhRyP0oHcN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "execution_failed": "2025-12-19T18:50:36.463Z"
    },
    "id": "MdEhRyP0oHcN",
    "outputId": "777a0c2c-83d7-4db1-b21c-05a812fa8bc0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1zNthSyiBdPUfn7BmUKPbKoGgQdG1vGnS/view?usp=drive_link -O Linemod_preprocessed.zip\n",
    "!unzip Linemod_preprocessed.zip\n",
    "%cd 6D_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mdcx-6-aogqF",
   "metadata": {
    "id": "Mdcx-6-aogqF"
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%mv Linemod_preprocessed /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1977a",
   "metadata": {
    "id": "20f1977a"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e78866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e78866",
    "outputId": "b5cd53ec-326c-40a1-a4d8-f7fec238b55d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from utils.load_data import mount_drive\n",
    "\n",
    "# Mounting part\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd0dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:50:02.167797Z",
     "iopub.status.busy": "2025-12-19T17:50:02.167481Z",
     "iopub.status.idle": "2025-12-19T17:50:02.173030Z",
     "shell.execute_reply": "2025-12-19T17:50:02.172247Z",
     "shell.execute_reply.started": "2025-12-19T17:50:02.167765Z"
    },
    "id": "d6bbd0dc",
    "outputId": "a3326ecf-a530-4f9e-d68f-a8ba83bcabb8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
    "dataset_root = \"../../Linemod_preprocessed\"\n",
    "# dataset_root = \"/content/Linemod_preprocessed\"\n",
    "# dataset_root = \"/kaggle/working/Linemod_preprocessed\"\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")\n",
    "print(f\"ðŸ“ Dataset path: {dataset_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728378e",
   "metadata": {
    "id": "4728378e"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598da66d-fc4d-4d42-b8d8-52104f3947c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T16:29:25.943772Z",
     "iopub.status.busy": "2025-12-19T16:29:25.943473Z",
     "iopub.status.idle": "2025-12-19T16:29:43.917596Z",
     "shell.execute_reply": "2025-12-19T16:29:43.916652Z",
     "shell.execute_reply.started": "2025-12-19T16:29:25.943738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed ./working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4gbKJycp4vr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T16:28:28.024953Z",
     "iopub.status.busy": "2025-12-19T16:28:28.024660Z",
     "iopub.status.idle": "2025-12-19T16:28:34.211778Z",
     "shell.execute_reply": "2025-12-19T16:28:34.211067Z",
     "shell.execute_reply.started": "2025-12-19T16:28:28.024927Z"
    },
    "id": "b4gbKJycp4vr",
    "outputId": "1a37cca0-76ab-4675-df0b-becd827133ce",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(sys.modules['src.pose_rgbd.dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc69f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:37:08.380521Z",
     "iopub.status.busy": "2025-12-19T17:37:08.379660Z",
     "iopub.status.idle": "2025-12-19T17:38:13.752688Z",
     "shell.execute_reply": "2025-12-19T17:38:13.752074Z",
     "shell.execute_reply.started": "2025-12-19T17:37:08.380490Z"
    },
    "id": "75cc69f7",
    "outputId": "4a87d952-f2cf-4e57-d26c-eeabf1bdc09d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_rgbd.loss import GeodesicLoss\n",
    "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
    "\n",
    "train_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "test_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea679a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:38:23.270506Z",
     "iopub.status.busy": "2025-12-19T17:38:23.269615Z",
     "iopub.status.idle": "2025-12-19T17:38:23.294699Z",
     "shell.execute_reply": "2025-12-19T17:38:23.293977Z",
     "shell.execute_reply.started": "2025-12-19T17:38:23.270474Z"
    },
    "id": "0aea679a",
    "outputId": "9280a363-50e8-45a0-c1d1-32a7f0ff340d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "print(f\"Depth shape: {sample['depth'].shape}\")\n",
    "print(f\"RGB shape: {sample['image'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01874d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:53:08.980441Z",
     "iopub.status.busy": "2025-12-19T17:53:08.979863Z",
     "iopub.status.idle": "2025-12-19T17:53:08.985123Z",
     "shell.execute_reply": "2025-12-19T17:53:08.984402Z",
     "shell.execute_reply.started": "2025-12-19T17:53:08.980408Z"
    },
    "id": "fb01874d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a727c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:56:14.064891Z",
     "iopub.status.busy": "2025-12-19T17:56:14.064109Z",
     "iopub.status.idle": "2025-12-19T17:56:14.069935Z",
     "shell.execute_reply": "2025-12-19T17:56:14.069195Z",
     "shell.execute_reply.started": "2025-12-19T17:56:14.064861Z"
    },
    "id": "82a727c4",
    "outputId": "2eb9ff33-3511-4a32-8d88-73e9c3dec89a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "# from src.pose_rgbd.model import RotationPredictionModel\n",
    "from src.pose_rgbd.model import RGBDRotationModel\n",
    "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
    "from src.pose_rgbd.loss import GeodesicLoss\n",
    "\n",
    "\n",
    "# Configurazione del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce6568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:56:24.657304Z",
     "iopub.status.busy": "2025-12-19T17:56:24.656535Z",
     "iopub.status.idle": "2025-12-19T17:56:24.674158Z",
     "shell.execute_reply": "2025-12-19T17:56:24.673507Z",
     "shell.execute_reply.started": "2025-12-19T17:56:24.657271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.linemod_config import get_linemod_config\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# dataset_root = \"../../Linemod_preprocessed_small\"  # Adjust path as needed\n",
    "linemod_config = get_linemod_config(dataset_root)\n",
    "\n",
    "all_model_points = []\n",
    "NUM_POINTS = 1000  # Number of points to sample from each model\n",
    "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
    "for obj_id in VALID_OBJ_IDS:\n",
    "    model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n",
    "    if model_points.shape[0] >= NUM_POINTS:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=True)\n",
    "    model_points = model_points[choice, :]\n",
    "    all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n",
    "all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n",
    "all_model_points = all_model_points.to(device)\n",
    "\n",
    "max_obj_id = max(VALID_OBJ_IDS)\n",
    "\n",
    "# Create a lookup table: obj_id -> index\n",
    "obj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\n",
    "for idx, obj_id in enumerate(VALID_OBJ_IDS):\n",
    "    obj_id_to_idx[obj_id] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b1b58-4804-474a-8116-8c1f089220a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:56:26.481177Z",
     "iopub.status.busy": "2025-12-19T17:56:26.480414Z",
     "iopub.status.idle": "2025-12-19T17:56:26.485565Z",
     "shell.execute_reply": "2025-12-19T17:56:26.485020Z",
     "shell.execute_reply.started": "2025-12-19T17:56:26.481147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220786c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:59:13.566451Z",
     "iopub.status.busy": "2025-12-19T17:59:13.566116Z",
     "iopub.status.idle": "2025-12-19T17:59:14.036852Z",
     "shell.execute_reply": "2025-12-19T17:59:14.036075Z",
     "shell.execute_reply.started": "2025-12-19T17:59:13.566416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_rgbd.loss import MultiObjectPointMatchingLoss\n",
    "\n",
    "model = RGBDRotationModel(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = MultiObjectPointMatchingLoss(all_model_points)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666a692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:59:16.364077Z",
     "iopub.status.busy": "2025-12-19T17:59:16.363729Z",
     "iopub.status.idle": "2025-12-19T18:46:24.841518Z",
     "shell.execute_reply": "2025-12-19T18:46:24.840652Z",
     "shell.execute_reply.started": "2025-12-19T17:59:16.364041Z"
    },
    "id": "6666a692",
    "outputId": "ab3b40a4-1a5d-4ce0-b172-17a7b1994075",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "\n",
    "# Load best model\n",
    "\n",
    "# Ciclo di training\n",
    "num_epochs = 50\n",
    "best_test_loss = float('inf')\n",
    "# checkpoint_dir = \"checkpoints\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# checkpoint_dir = f'/content/drive/MyDrive/runs/POINT_MATCH_{timestamp}' # modify here for kaggle\n",
    "checkpoint_dir = f'/kaggle/working/POINT_MATCH_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "val_batches_limit = 50\n",
    "\n",
    "# Track losses for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
    "    for batch in train_pbar:\n",
    "        rgb = batch['image'].to(device)  # RGB image (B, 3, H, W)\n",
    "        depth = batch['depth'].to(device)  # Depth (B, 1, H, W)\n",
    "        rotations = batch['rotation'].to(device)  # GT quaternion (B, 4)\n",
    "        obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
    "        obj_ids = obj_id_to_idx[obj_ids]  # Map to indices (B,)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth)\n",
    "\n",
    "        # Calcolo della loss\n",
    "        loss = criterion(outputs, rotations, obj_ids)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': epoch_loss / (train_pbar.n + 1)})\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    val_iterator = islice(test_loader, val_batches_limit)\n",
    "    val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
    "    count_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            rgb = batch['image'].to(device)\n",
    "            depth = batch['depth'].to(device)\n",
    "            rotations = batch['rotation'].to(device)\n",
    "            obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
    "            obj_ids = obj_id_to_idx[obj_ids].to(device)  # Map to indices (B,)\n",
    "\n",
    "            outputs = model(rgb, depth)\n",
    "            loss = criterion(outputs, rotations, obj_ids)\n",
    "            test_loss += loss.item()\n",
    "            val_pbar.set_postfix({'loss': test_loss / (val_pbar.n + 1)})\n",
    "            count_batches+=1\n",
    "\n",
    "    avg_test_loss = test_loss / count_batches if count_batches > 0 else 0\n",
    "    test_losses.append(avg_test_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint if test loss improved\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_loss': avg_test_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"âœ… Checkpoint saved! Best Test Loss: {best_test_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  No improvement. Best Test Loss: {best_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T18:46:24.843772Z",
     "iopub.status.busy": "2025-12-19T18:46:24.843483Z",
     "iopub.status.idle": "2025-12-19T18:46:26.724794Z",
     "shell.execute_reply": "2025-12-19T18:46:26.723853Z",
     "shell.execute_reply.started": "2025-12-19T18:46:24.843743Z"
    },
    "id": "d2823bc9",
    "outputId": "ef287fb9-80b6-4626-8107-2d4e958acdbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots directory\n",
    "# plots_dir = \"plots\"\n",
    "plots_dir = checkpoint_dir\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Training vs Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, len(test_losses)+1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {loss_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Only Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
    "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {train_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Only Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Test Loss', fontsize=12)\n",
    "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
    "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {test_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… All plots saved in '{plots_dir}' directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OEDg_DQr32yn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:46:26.726530Z",
     "iopub.status.busy": "2025-12-19T18:46:26.725941Z",
     "iopub.status.idle": "2025-12-19T18:46:26.730545Z",
     "shell.execute_reply": "2025-12-19T18:46:26.729961Z",
     "shell.execute_reply.started": "2025-12-19T18:46:26.726507Z"
    },
    "id": "OEDg_DQr32yn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save losses\n",
    "import pickle\n",
    "\n",
    "\n",
    "losses_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses\n",
    "}\n",
    "\n",
    "losses_path = os.path.join(checkpoint_dir, \"losses.pkl\")\n",
    "with open(losses_path, 'wb') as f:\n",
    "    pickle.dump(losses_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dcf9c",
   "metadata": {
    "id": "da3dcf9c"
   },
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-19T17:13:59.287886Z",
     "iopub.status.busy": "2025-12-19T17:13:59.287327Z",
     "iopub.status.idle": "2025-12-19T17:14:00.313899Z",
     "shell.execute_reply": "2025-12-19T17:14:00.313208Z",
     "shell.execute_reply.started": "2025-12-19T17:13:59.287855Z"
    },
    "id": "cad99042",
    "outputId": "8870604a-00eb-4a86-ef5d-8708e035b204",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison, get_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup projection utils\n",
    "setup_projection_utils(dataset_root)\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "checkpoint = torch.load(best_checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"âœ… Loaded best model from epoch {checkpoint['epoch']} with test loss: {checkpoint['test_loss']:.4f}\")\n",
    "\n",
    "# Select a random sample from test dataset\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "sample = test_dataset[random_idx]\n",
    "\n",
    "print(f\"\\nðŸ“· Visualizing sample {random_idx}:\")\n",
    "print(f\"   Object ID: {sample['object_id']}\")\n",
    "print(f\"   Image ID: {sample['img_id']}\")\n",
    "\n",
    "# Get the original image\n",
    "img_path = sample['img_path']\n",
    "image_rgb = cv2.imread(str(img_path))\n",
    "# image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare input for model\n",
    "rgb = sample['image'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "depth = sample['depth'].unsqueeze(0).to(device)  # Add batch and channel dimensions\n",
    "\n",
    "# Get model prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_rotation = model(rgb, depth)[0].cpu().numpy()\n",
    "\n",
    "# Get ground truth\n",
    "gt_rotation = sample['rotation'].numpy()\n",
    "gt_translation = sample['translation'].numpy()\n",
    "\n",
    "# Get camera intrinsics\n",
    "cam_K = sample['cam_K'].numpy()\n",
    "\n",
    "print(f\"\\nðŸ“Š Ground Truth vs Prediction:\")\n",
    "print(f\"   GT Rotation: {gt_rotation}\")\n",
    "print(f\"   Pred Rotation: {pred_rotation}\")\n",
    "print(f\"   GT Translation: {gt_translation}\")\n",
    "\n",
    "# Visualize pose comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "img_vis = visualize_pose_comparison(\n",
    "    image_rgb,\n",
    "    object_id=sample['object_id'],\n",
    "    cam_K=cam_K,\n",
    "    gt_rotation=gt_rotation,\n",
    "    gt_translation=gt_translation,\n",
    "    pred_rotation=pred_rotation,\n",
    "    pred_translation=gt_translation  # Using GT translation for now\n",
    ")\n",
    "\n",
    "# Convert BGR to RGB for matplotlib\n",
    "img_vis_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
    "ax.imshow(img_vis_rgb)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"Pose Visualization - Object {sample['object_id']}, Image {sample['img_id']}\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(plots_dir, f\"pose_visualization_sample_{random_idx}.png\"), dpi=150, bbox_inches='tight')\n",
    "print(f\"\\nâœ… Visualization saved!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862c6a3-6c12-4c90-b228-9ea1a1a47518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:46:26.732344Z",
     "iopub.status.busy": "2025-12-19T18:46:26.732126Z",
     "iopub.status.idle": "2025-12-19T18:46:27.088697Z",
     "shell.execute_reply": "2025-12-19T18:46:27.087732Z",
     "shell.execute_reply.started": "2025-12-19T18:46:26.732322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#### import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from metrics.ADD_metric import compute_ADD_metric_quaternion, compute_ADDs_metric_quaternion\n",
    "from src.pose_rgbd.model import RGBDRotationModel\n",
    "\n",
    "# ==========================================\n",
    "# 1. CARICAMENTO DATI E DIAMETRI\n",
    "# ==========================================\n",
    "def load_models_info(models_dir, obj_ids, num_points=1000):\n",
    "    \"\"\"\n",
    "    Carica i punti e calcola il DIAMETRO di ogni oggetto.\n",
    "    Restituisce:\n",
    "      - point_cache: {id: punti_m}\n",
    "      - diameters: {id: diametro_m}\n",
    "    \"\"\"\n",
    "    point_cache = {}\n",
    "    diameters = {}\n",
    "    \n",
    "    unique_ids = list(set(obj_ids))\n",
    "    print(f\"â³ Caricamento info per {len(unique_ids)} modelli...\")\n",
    "    \n",
    "    for oid in tqdm(unique_ids, desc=\"Mesh Analysis\"):\n",
    "        filename = f\"obj_{int(oid):02d}.ply\"\n",
    "        path = os.path.join(models_dir, filename)\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            mesh = trimesh.load(path)\n",
    "            \n",
    "            # 1. Punti per ADD\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "            point_cache[oid] = points / 1000.0 # Metri\n",
    "            \n",
    "            # 2. Calcolo Diametro (Distanza massima tra due vertici o diagonale bbox)\n",
    "            # Metodo standard LineMod: Diagonale della Bounding Box\n",
    "            extents = mesh.extents / 1000.0 # Metri\n",
    "            diameter = np.linalg.norm(extents)\n",
    "            diameters[oid] = diameter\n",
    "        else:\n",
    "            print(f\"âš ï¸ Modello mancante: {path}\")\n",
    "            \n",
    "    return point_cache, diameters\n",
    "\n",
    "# ==========================================\n",
    "# 2. VALUTAZIONE IBRIDA (ERROR + ACCURACY)\n",
    "# ==========================================\n",
    "def evaluate_comprehensive(model_rot, dataloader, device, models_dir, model_trans=None):\n",
    "    model_rot.eval()\n",
    "    if model_trans: model_trans.eval()\n",
    "    \n",
    "    # Raccogli ID e carica dati\n",
    "    all_obj_ids = [1,2,4,5,6,8,9,10,11,12,13,14,15]\n",
    "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
    "    \n",
    "    # Strutture dati\n",
    "    # errors_dict: lista di errori in metri per ogni oggetto\n",
    "    # correct_preds: contatore di quante volte errore < 0.1 * diametro\n",
    "    # total_preds: contatore totale campioni\n",
    "    errors_dict = defaultdict(list)\n",
    "    accuracy_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "    SYMMETRIC_OBJECTS = [10, 11]\n",
    "    \n",
    "    print(\"\\nðŸš€ Avvio Benchmark Completo (ADD Error + ADD-0.1d Accuracy)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            imgs = batch['image'].to(device)\n",
    "            depths = batch['depth'].to(device)\n",
    "            gt_quats = batch['rotation'].to(device)\n",
    "            gt_trans = batch['translation'].to(device)\n",
    "            obj_ids = batch['object_id']\n",
    "            \n",
    "            pred_quats = model_rot(imgs, depths)\n",
    "            \n",
    "            # if model_trans:\n",
    "            #     if 'bbox_info' in batch:\n",
    "            #         bbox_info = batch['bbox_info'].to(device)\n",
    "            #         pred_trans_batch = model_trans(imgs, bbox_info)\n",
    "            #     else:\n",
    "            #         pred_trans_batch = gt_trans\n",
    "            # else:\n",
    "            #     pred_trans_batch = gt_trans # Fallback GT\n",
    "\n",
    "            # Loop sui singoli sample\n",
    "            batch_size = imgs.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                curr_id = int(obj_ids[i])\n",
    "                if curr_id not in points_dict: continue\n",
    "\n",
    "                metric = compute_ADDs_metric_quaternion if curr_id in SYMMETRIC_OBJECTS else compute_ADD_metric_quaternion\n",
    "                \n",
    "                # Calcola ADD Error (Metri) o ADD-S\n",
    "                add_error = metric(\n",
    "                    model_points=points_dict[curr_id],\n",
    "                    gt_quat=gt_quats[i].cpu().numpy(),\n",
    "                    gt_translation=gt_trans[i].cpu().numpy(),\n",
    "                    pred_quat=pred_quats[i].cpu().numpy(),\n",
    "                    pred_translation=gt_trans[i].cpu().numpy()\n",
    "                )\n",
    "                \n",
    "                # Salva errore assoluto\n",
    "                errors_dict[curr_id].append(add_error)\n",
    "                \n",
    "                # --- CALCOLO ACCURACY (La parte nuova) ---\n",
    "                # Soglia = 10% del diametro\n",
    "                threshold = diameters_dict[curr_id] * 0.1\n",
    "                \n",
    "                accuracy_stats[curr_id][\"total\"] += 1\n",
    "                if add_error < threshold:\n",
    "                    accuracy_stats[curr_id][\"correct\"] += 1\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. REPORT FINALE (CONFRONTABILE)\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*85)\n",
    "    print(f\"{'ID':<3} | {'DIAMETER':<10} | {'ADD ERROR (cm)':<15} | {'ACCURACY (ADD-0.1d)':<20} | {'SAMPLES':<8}\")\n",
    "    print(\"=\"*85)\n",
    "    \n",
    "    total_acc_correct = 0\n",
    "    total_acc_count = 0\n",
    "    \n",
    "    sorted_ids = sorted(errors_dict.keys())\n",
    "    for oid in sorted_ids:\n",
    "        # Error stats\n",
    "        mean_err_m = np.mean(errors_dict[oid])\n",
    "        mean_err_cm = mean_err_m * 100\n",
    "        \n",
    "        # Accuracy stats\n",
    "        stats = accuracy_stats[oid]\n",
    "        acc_perc = (stats[\"correct\"] / stats[\"total\"]) * 100\n",
    "        \n",
    "        total_acc_correct += stats[\"correct\"]\n",
    "        total_acc_count += stats[\"total\"]\n",
    "        \n",
    "        diam_cm = diameters_dict[oid] * 100\n",
    "        \n",
    "        print(f\"{oid:<3} | {diam_cm:.1f} cm     | {mean_err_cm:.2f} cm          | {acc_perc:.2f} %               | {stats['total']}\")\n",
    "        \n",
    "    print(\"=\"*85)\n",
    "    global_acc = (total_acc_correct / total_acc_count) * 100\n",
    "    print(f\"ðŸ† MEDIA TOTALE: Errore Medio = ??? cm | Accuratezza Globale = {global_acc:.2f} %\")\n",
    "    print(\"=\"*85)\n",
    "\n",
    "# --- USO ---\n",
    "MODELS_ROOT = '/kaggle/working/Linemod_preprocessed/models'\n",
    "\n",
    "data = torch.load(checkpoint_dir + \"/best_model.pth\")\n",
    "\n",
    "model = RGBDRotationModel()\n",
    "model.load_state_dict(data['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "evaluate_comprehensive(model, test_loader, device, MODELS_ROOT, model_trans=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f6551-4ff6-4c50-a53c-3df31e51a190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:24:29.626727Z",
     "iopub.status.busy": "2025-12-19T17:24:29.626211Z",
     "iopub.status.idle": "2025-12-19T17:24:29.806950Z",
     "shell.execute_reply": "2025-12-19T17:24:29.806130Z",
     "shell.execute_reply.started": "2025-12-19T17:24:29.626694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# /kaggle/output/Linemod_preprocessed/models/obj_15.ply\n",
    "%ls /kaggle/working/Linemod_preprocessed/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c81d2-a3e0-4f6a-a098-fef8315392b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:23:14.173945Z",
     "iopub.status.busy": "2025-12-19T17:23:14.173367Z",
     "iopub.status.idle": "2025-12-19T17:23:14.989693Z",
     "shell.execute_reply": "2025-12-19T17:23:14.988894Z",
     "shell.execute_reply.started": "2025-12-19T17:23:14.173918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18240b-01e2-4692-9fe1-63b6427316a3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
