{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25573688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull part\n",
    "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
    "repo_dir = \"/content/6D_pose\"   #Modify here for kaggle\n",
    "branch = \"main\"\n",
    "\n",
    "# Clone if missing\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -b {branch} {repo_url}\n",
    "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
    "else:\n",
    "    %cd {repo_dir}\n",
    "    !git fetch origin\n",
    "    !git checkout {branch}\n",
    "    !git reset --hard origin/{branch}\n",
    "    %cd ..\n",
    "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
    "\n",
    "# Add repository to Python path\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e78866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from utils.load_data import mount_drive\n",
    "\n",
    "# Mounting part\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
    "dataset_root = \"../../Linemod_preprocessed_small\"\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")\n",
    "print(f\"üìÅ Dataset path: {dataset_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pose_rgbd.loss import GeodesicLoss\n",
    "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
    "\n",
    "train_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "test_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "print(f\"Depth shape: {sample['depth'].shape}\")\n",
    "print(f\"RGB shape: {sample['image'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a727c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from src.pose_rgbd.model import RotationPredictionModel\n",
    "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
    "from src.pose_rgbd.loss import GeodesicLoss\n",
    "\n",
    "# Configurazione del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e51a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RotationPredictionModel(pretrained=True, freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = GeodesicLoss() \n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Ciclo di training\n",
    "num_epochs = 50\n",
    "best_test_loss = float('inf')\n",
    "# checkpoint_dir = \"checkpoints\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "checkpoint_dir = f'/content/drive/MyDrive/runs/{timestamp}' # modify here for kaggle\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Track losses for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
    "    for batch in train_pbar:\n",
    "        rgb = batch['image'].to(device)  # RGB image (B, 3, H, W)\n",
    "        depth = batch['depth'].unsqueeze(1).to(device)  # Depth (B, 1, H, W)\n",
    "        rotations = batch['rotation'].to(device)  # GT quaternion (B, 4)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth)\n",
    "        \n",
    "        # Calcolo della loss\n",
    "        loss = criterion(outputs, rotations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': epoch_loss / (train_pbar.n + 1)})\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    test_pbar = tqdm(test_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Testing\")\n",
    "    with torch.no_grad():\n",
    "        for batch in test_pbar:\n",
    "            rgb = batch['image'].to(device)\n",
    "            depth = batch['depth'].unsqueeze(1).to(device)\n",
    "            rotations = batch['rotation'].to(device)\n",
    "            \n",
    "            outputs = model(rgb, depth)\n",
    "            loss = criterion(outputs, rotations)\n",
    "            test_loss += loss.item()\n",
    "            test_pbar.set_postfix({'loss': test_loss / (test_pbar.n + 1)})\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    # Save checkpoint if test loss improved\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_loss': avg_test_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"‚úÖ Checkpoint saved! Best Test Loss: {best_test_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No improvement. Best Test Loss: {best_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots directory\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Training vs Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.plot(epochs_range, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "plt.plot(epochs_range, test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {loss_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Only Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
    "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {train_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Only Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, test_losses, 'r-s', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Test Loss', fontsize=12)\n",
    "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
    "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {test_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ All plots saved in '{plots_dir}' directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dcf9c",
   "metadata": {},
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison, get_image\n",
    "\n",
    "# Setup projection utils\n",
    "setup_projection_utils(dataset_root)\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "checkpoint = torch.load(best_checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']} with test loss: {checkpoint['test_loss']:.4f}\")\n",
    "\n",
    "# Select a random sample from test dataset\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "sample = test_dataset[random_idx]\n",
    "\n",
    "print(f\"\\nüì∑ Visualizing sample {random_idx}:\")\n",
    "print(f\"   Object ID: {sample['object_id']}\")\n",
    "print(f\"   Image ID: {sample['img_id']}\")\n",
    "\n",
    "# Get the original image\n",
    "img_path = sample['img_path']\n",
    "image_rgb = cv2.imread(str(img_path))\n",
    "image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare input for model\n",
    "rgb = sample['image'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "depth = sample['depth'].unsqueeze(0).unsqueeze(0).to(device)  # Add batch and channel dimensions\n",
    "\n",
    "# Get model prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_rotation = model(rgb, depth)[0].cpu().numpy()\n",
    "\n",
    "# Get ground truth\n",
    "gt_rotation = sample['rotation'].numpy()\n",
    "gt_translation = sample['translation'].numpy()\n",
    "\n",
    "# Get camera intrinsics\n",
    "cam_K = sample['cam_K'].numpy()\n",
    "\n",
    "print(f\"\\nüìä Ground Truth vs Prediction:\")\n",
    "print(f\"   GT Rotation: {gt_rotation}\")\n",
    "print(f\"   Pred Rotation: {pred_rotation}\")\n",
    "print(f\"   GT Translation: {gt_translation}\")\n",
    "\n",
    "# Visualize pose comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "img_vis = visualize_pose_comparison(\n",
    "    image_rgb,\n",
    "    object_id=sample['object_id'],\n",
    "    cam_K=cam_K,\n",
    "    gt_rotation=gt_rotation,\n",
    "    gt_translation=gt_translation,\n",
    "    pred_rotation=pred_rotation,\n",
    "    pred_translation=gt_translation  # Using GT translation for now\n",
    ")\n",
    "\n",
    "# Convert BGR to RGB for matplotlib\n",
    "img_vis_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
    "ax.imshow(img_vis_rgb)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"Pose Visualization - Object {sample['object_id']}, Image {sample['img_id']}\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(plots_dir, f\"pose_visualization_sample_{random_idx}.png\"), dpi=150, bbox_inches='tight')\n",
    "print(f\"\\n‚úÖ Visualization saved!\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
