{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25573688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:48:35.081902Z",
     "iopub.status.busy": "2025-12-20T09:48:35.081636Z",
     "iopub.status.idle": "2025-12-20T09:48:36.348328Z",
     "shell.execute_reply": "2025-12-20T09:48:36.347472Z",
     "shell.execute_reply.started": "2025-12-20T09:48:35.081871Z"
    },
    "id": "25573688",
    "outputId": "72321497-6c3a-436b-90f0-fd5df011e398",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull part\n",
    "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
    "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
    "branch = \"pose_rgbd\"\n",
    "\n",
    "# Clone if missing\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -b {branch} {repo_url}\n",
    "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
    "else:\n",
    "    %cd {repo_dir}\n",
    "    !git fetch origin\n",
    "    !git checkout {branch}\n",
    "    !git reset --hard origin/{branch}\n",
    "    # %cd ..\n",
    "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
    "\n",
    "# Add repository to Python path\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdEhRyP0oHcN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "execution_failed": "2025-12-20T11:15:16.832Z"
    },
    "id": "MdEhRyP0oHcN",
    "outputId": "777a0c2c-83d7-4db1-b21c-05a812fa8bc0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1zNthSyiBdPUfn7BmUKPbKoGgQdG1vGnS/view?usp=drive_link -O Linemod_preprocessed.zip\n",
    "!unzip Linemod_preprocessed.zip\n",
    "%cd 6D_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e78866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e78866",
    "outputId": "b5cd53ec-326c-40a1-a4d8-f7fec238b55d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from utils.load_data import mount_drive\n",
    "\n",
    "# Mounting part\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e2b0-ebc6-412b-b2db-6f36c33f0b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:57:27.976090Z",
     "iopub.status.busy": "2025-12-20T09:57:27.975476Z",
     "iopub.status.idle": "2025-12-20T09:57:46.017384Z",
     "shell.execute_reply": "2025-12-20T09:57:46.016449Z",
     "shell.execute_reply.started": "2025-12-20T09:57:27.976041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd0dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:57:56.004631Z",
     "iopub.status.busy": "2025-12-20T09:57:56.004331Z",
     "iopub.status.idle": "2025-12-20T09:57:56.009639Z",
     "shell.execute_reply": "2025-12-20T09:57:56.009064Z",
     "shell.execute_reply.started": "2025-12-20T09:57:56.004599Z"
    },
    "id": "d6bbd0dc",
    "outputId": "a3326ecf-a530-4f9e-d68f-a8ba83bcabb8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
    "# dataset_root = \"../../Linemod_preprocessed\"\n",
    "# dataset_root = \"/content/Linemod_preprocessed\"\n",
    "dataset_root = \"/kaggle/working/Linemod_preprocessed\"\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")\n",
    "print(f\"ðŸ“ Dataset path: {dataset_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728378e",
   "metadata": {
    "id": "4728378e"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598da66d-fc4d-4d42-b8d8-52104f3947c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T16:29:25.943772Z",
     "iopub.status.busy": "2025-12-19T16:29:25.943473Z",
     "iopub.status.idle": "2025-12-19T16:29:43.917596Z",
     "shell.execute_reply": "2025-12-19T16:29:43.916652Z",
     "shell.execute_reply.started": "2025-12-19T16:29:25.943738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed ./working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4gbKJycp4vr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:58:01.763290Z",
     "iopub.status.busy": "2025-12-20T09:58:01.762971Z",
     "iopub.status.idle": "2025-12-20T09:58:13.038336Z",
     "shell.execute_reply": "2025-12-20T09:58:13.037425Z",
     "shell.execute_reply.started": "2025-12-20T09:58:01.763264Z"
    },
    "id": "b4gbKJycp4vr",
    "outputId": "1a37cca0-76ab-4675-df0b-becd827133ce",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(sys.modules['src.pose_rgbd.dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc69f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:58:13.040156Z",
     "iopub.status.busy": "2025-12-20T09:58:13.039868Z",
     "iopub.status.idle": "2025-12-20T09:59:31.633511Z",
     "shell.execute_reply": "2025-12-20T09:59:31.632667Z",
     "shell.execute_reply.started": "2025-12-20T09:58:13.040128Z"
    },
    "id": "75cc69f7",
    "outputId": "4a87d952-f2cf-4e57-d26c-eeabf1bdc09d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_rgbd.loss import GeodesicLoss\n",
    "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
    "\n",
    "train_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "test_dataset = LineModPoseDepthDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea679a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:44.816475Z",
     "iopub.status.busy": "2025-12-20T09:59:44.816059Z",
     "iopub.status.idle": "2025-12-20T09:59:44.862578Z",
     "shell.execute_reply": "2025-12-20T09:59:44.861972Z",
     "shell.execute_reply.started": "2025-12-20T09:59:44.816448Z"
    },
    "id": "0aea679a",
    "outputId": "9280a363-50e8-45a0-c1d1-32a7f0ff340d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "print(f\"Depth shape: {sample['depth'].shape}\")\n",
    "print(f\"RGB shape: {sample['image'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a727c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:49.255635Z",
     "iopub.status.busy": "2025-12-20T09:59:49.255341Z",
     "iopub.status.idle": "2025-12-20T09:59:49.338644Z",
     "shell.execute_reply": "2025-12-20T09:59:49.338069Z",
     "shell.execute_reply.started": "2025-12-20T09:59:49.255610Z"
    },
    "id": "82a727c4",
    "outputId": "2eb9ff33-3511-4a32-8d88-73e9c3dec89a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.pose_rgbd.model import RGBDRotationModel\n",
    "\n",
    "\n",
    "# Configurazione del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce6568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:52.153424Z",
     "iopub.status.busy": "2025-12-20T09:59:52.153133Z",
     "iopub.status.idle": "2025-12-20T09:59:58.457722Z",
     "shell.execute_reply": "2025-12-20T09:59:58.456928Z",
     "shell.execute_reply.started": "2025-12-20T09:59:52.153399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.linemod_config import get_linemod_config\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# dataset_root = \"../../Linemod_preprocessed_small\"  # Adjust path as needed\n",
    "linemod_config = get_linemod_config(dataset_root)\n",
    "\n",
    "all_model_points = []\n",
    "NUM_POINTS = 1000  # Number of points to sample from each model\n",
    "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
    "for obj_id in VALID_OBJ_IDS:\n",
    "    model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n",
    "    if model_points.shape[0] >= NUM_POINTS:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=True)\n",
    "    model_points = model_points[choice, :]\n",
    "    all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n",
    "all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n",
    "all_model_points = all_model_points.to(device)\n",
    "\n",
    "max_obj_id = max(VALID_OBJ_IDS)\n",
    "\n",
    "# Create a lookup table: obj_id -> index\n",
    "obj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\n",
    "for idx, obj_id in enumerate(VALID_OBJ_IDS):\n",
    "    obj_id_to_idx[obj_id] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b1b58-4804-474a-8116-8c1f089220a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:58.459260Z",
     "iopub.status.busy": "2025-12-20T09:59:58.458914Z",
     "iopub.status.idle": "2025-12-20T09:59:58.464527Z",
     "shell.execute_reply": "2025-12-20T09:59:58.463735Z",
     "shell.execute_reply.started": "2025-12-20T09:59:58.459224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220786c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:20.945503Z",
     "iopub.status.busy": "2025-12-20T10:15:20.944832Z",
     "iopub.status.idle": "2025-12-20T10:15:21.398296Z",
     "shell.execute_reply": "2025-12-20T10:15:21.397691Z",
     "shell.execute_reply.started": "2025-12-20T10:15:20.945472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_rgbd.loss import MultiObjectPointMatchingLoss\n",
    "import torch.nn as nn\n",
    "\n",
    "model = RGBDRotationModel(pretrained=True)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ðŸ”¥ Using {torch.cuda.device_count()} GPU!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "backbone_params = [p for n, p in model.named_parameters() if 'backbone' in n]\n",
    "head_params = [p for n, p in model.named_parameters() if 'rot_head' in n]\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = MultiObjectPointMatchingLoss(all_model_points)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\n",
    "        'params': backbone_params, \n",
    "        'lr': 3e-5  # Low: preserves knowledge, adapts only depth\n",
    "    },\n",
    "    {\n",
    "        'params': head_params,     \n",
    "        'lr': 1e-3  # High: learn to predict quaternions from scratch\n",
    "    }\n",
    "], weight_decay=1e-4) # Global regularization\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',       # We want to minimize the validation loss\n",
    "    factor=0.5,       # Halve the learning rate when triggered\n",
    "    patience=3,       # Wait 3 epochs of stagnation (small dataset -> low patience)\n",
    "    verbose=True,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4ae51-b4ce-4a9b-87d5-1fbe4b19e6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:22.482439Z",
     "iopub.status.busy": "2025-12-20T10:15:22.481626Z",
     "iopub.status.idle": "2025-12-20T10:15:22.486608Z",
     "shell.execute_reply": "2025-12-20T10:15:22.485877Z",
     "shell.execute_reply.started": "2025-12-20T10:15:22.482409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32  #double GPU\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666a692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:24.125859Z",
     "iopub.status.busy": "2025-12-20T10:15:24.125144Z",
     "iopub.status.idle": "2025-12-20T10:53:54.454215Z",
     "shell.execute_reply": "2025-12-20T10:53:54.453401Z",
     "shell.execute_reply.started": "2025-12-20T10:15:24.125832Z"
    },
    "id": "6666a692",
    "outputId": "ab3b40a4-1a5d-4ce0-b172-17a7b1994075",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "\n",
    "# Load best model\n",
    "\n",
    "# Ciclo di training\n",
    "num_epochs = 15\n",
    "best_test_loss = float('inf')\n",
    "# checkpoint_dir = \"checkpoints\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# checkpoint_dir = f'/content/drive/MyDrive/runs/POINT_MATCH_{timestamp}' # modify here for kaggle\n",
    "checkpoint_dir = f'/kaggle/working/POINT_MATCH_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "# val_batches_limit = 50\n",
    "\n",
    "# Track losses for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
    "    for batch in train_pbar:\n",
    "        rgb = batch['image'].to(device)  # RGB image (B, 3, H, W)\n",
    "        depth = batch['depth'].to(device)  # Depth (B, 1, H, W)\n",
    "        rotations = batch['rotation'].to(device)  # GT quaternion (B, 4)\n",
    "        obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
    "        obj_ids = obj_id_to_idx[obj_ids]  # Map to indices (B,)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth)\n",
    "\n",
    "        # Calcolo della loss\n",
    "        loss = criterion(outputs, rotations, obj_ids)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': epoch_loss / (train_pbar.n + 1)})\n",
    "\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    val_pbar = tqdm(test_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Validating\")\n",
    "    count_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            rgb = batch['image'].to(device)\n",
    "            depth = batch['depth'].to(device)\n",
    "            rotations = batch['rotation'].to(device)\n",
    "            obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
    "            obj_ids = obj_id_to_idx[obj_ids].to(device)  # Map to indices (B,)\n",
    "\n",
    "            outputs = model(rgb, depth)\n",
    "            loss = criterion(outputs, rotations, obj_ids)\n",
    "            test_loss += loss.item()\n",
    "            val_pbar.set_postfix({'loss': test_loss / (val_pbar.n + 1)})\n",
    "            count_batches+=1\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_test_loss)\n",
    "\n",
    "    # Save checkpoint if test loss improved\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_loss': avg_test_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"âœ… Checkpoint saved! Best Test Loss: {best_test_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  No improvement. Best Test Loss: {best_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T10:53:58.626482Z",
     "iopub.status.busy": "2025-12-20T10:53:58.626146Z",
     "iopub.status.idle": "2025-12-20T10:54:00.560764Z",
     "shell.execute_reply": "2025-12-20T10:54:00.560032Z",
     "shell.execute_reply.started": "2025-12-20T10:53:58.626448Z"
    },
    "id": "d2823bc9",
    "outputId": "ef287fb9-80b6-4626-8107-2d4e958acdbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots directory\n",
    "# plots_dir = \"plots\"\n",
    "plots_dir = checkpoint_dir\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Training vs Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, len(test_losses)+1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {loss_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Only Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
    "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {train_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Only Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Test Loss', fontsize=12)\n",
    "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
    "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Plot saved: {test_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… All plots saved in '{plots_dir}' directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OEDg_DQr32yn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:54:12.535178Z",
     "iopub.status.busy": "2025-12-20T10:54:12.534582Z",
     "iopub.status.idle": "2025-12-20T10:54:12.539879Z",
     "shell.execute_reply": "2025-12-20T10:54:12.539172Z",
     "shell.execute_reply.started": "2025-12-20T10:54:12.535147Z"
    },
    "id": "OEDg_DQr32yn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save losses\n",
    "import pickle\n",
    "\n",
    "\n",
    "losses_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses\n",
    "}\n",
    "\n",
    "losses_path = os.path.join(checkpoint_dir, \"losses.pkl\")\n",
    "with open(losses_path, 'wb') as f:\n",
    "    pickle.dump(losses_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dcf9c",
   "metadata": {
    "id": "da3dcf9c"
   },
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T11:01:38.744094Z",
     "iopub.status.busy": "2025-12-20T11:01:38.743779Z",
     "iopub.status.idle": "2025-12-20T11:01:39.607462Z",
     "shell.execute_reply": "2025-12-20T11:01:39.606597Z",
     "shell.execute_reply.started": "2025-12-20T11:01:38.744066Z"
    },
    "id": "cad99042",
    "outputId": "8870604a-00eb-4a86-ef5d-8708e035b204",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison, get_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup projection utils\n",
    "setup_projection_utils(dataset_root)\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "checkpoint = torch.load(best_checkpoint_path)\n",
    "\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# 2. Crea un nuovo dizionario senza il prefisso 'module.'\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k, v in state_dict.items():\n",
    "    # Rimuovi 'module.' se presente all'inizio della chiave\n",
    "    name = k[7:] if k.startswith('module.') else k \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "print(f\"âœ… Loaded best model from epoch {checkpoint['epoch']} with test loss: {checkpoint['test_loss']:.4f}\")\n",
    "\n",
    "# Select a random sample from test dataset\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "sample = test_dataset[random_idx]\n",
    "\n",
    "print(f\"\\nðŸ“· Visualizing sample {random_idx}:\")\n",
    "print(f\"   Object ID: {sample['object_id']}\")\n",
    "print(f\"   Image ID: {sample['img_id']}\")\n",
    "\n",
    "# Get the original image\n",
    "img_path = sample['img_path']\n",
    "image_rgb = cv2.imread(str(img_path))\n",
    "# image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare input for model\n",
    "rgb = sample['image'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "depth = sample['depth'].unsqueeze(0).to(device)  # Add batch and channel dimensions\n",
    "\n",
    "# Get model prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_rotation = model(rgb, depth)[0].cpu().numpy()\n",
    "\n",
    "# Get ground truth\n",
    "gt_rotation = sample['rotation'].numpy()\n",
    "gt_translation = sample['translation'].numpy()\n",
    "\n",
    "# Get camera intrinsics\n",
    "cam_K = sample['cam_K'].numpy()\n",
    "\n",
    "print(f\"\\nðŸ“Š Ground Truth vs Prediction:\")\n",
    "print(f\"   GT Rotation: {gt_rotation}\")\n",
    "print(f\"   Pred Rotation: {pred_rotation}\")\n",
    "print(f\"   GT Translation: {gt_translation}\")\n",
    "\n",
    "# Visualize pose comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "img_vis = visualize_pose_comparison(\n",
    "    image_rgb,\n",
    "    object_id=sample['object_id'],\n",
    "    cam_K=cam_K,\n",
    "    gt_rotation=gt_rotation,\n",
    "    gt_translation=gt_translation,\n",
    "    pred_rotation=pred_rotation,\n",
    "    pred_translation=gt_translation  # Using GT translation for now\n",
    ")\n",
    "\n",
    "# Convert BGR to RGB for matplotlib\n",
    "img_vis_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
    "ax.imshow(img_vis_rgb)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"Pose Visualization - Object {sample['object_id']}, Image {sample['img_id']}\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(plots_dir, f\"pose_visualization_sample_{random_idx}.png\"), dpi=150, bbox_inches='tight')\n",
    "print(f\"\\nâœ… Visualization saved!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94026f01",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pose_rgbd.evaluate import evaluate_RGBD\n",
    "MODEL_PATH = \"./RGBD_run/best_model.pth\"            # Path to the trained model\n",
    "DATASET_ROOT = \"../../Linemod_preprocessed\"  # Path to the Linemod dataset\n",
    "OUTPUT_PATH = \"./RGBD_run/linemod_evaluation_report.csv\"  # Path to save the evaluation report\n",
    "\n",
    "df = evaluate_RGBD(\n",
    "    model_path=MODEL_PATH,\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    output_path=OUTPUT_PATH\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e987e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9081703,
     "sourceId": 14235088,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
