{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RSmCHsiKpedw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RSmCHsiKpedw",
        "outputId": "1607c3d0-06b6-49cf-a79f-341a28e59ccc"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xEYIdHR9pfkm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEYIdHR9pfkm",
        "outputId": "bf5cf3c2-c59b-4fc9-e48f-7fbd3d0d8a75"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25573688",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25573688",
        "outputId": "72321497-6c3a-436b-90f0-fd5df011e398"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/content/6D_pose\"   #Modify here for kaggle\n",
        "branch = \"pose_rgbd\"\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    # %cd ..\n",
        "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
        "\n",
        "# Add repository to Python path\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MdEhRyP0oHcN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MdEhRyP0oHcN",
        "outputId": "777a0c2c-83d7-4db1-b21c-05a812fa8bc0"
      },
      "outputs": [],
      "source": [
        "# %cd ..\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1Zwh-gAk_-CBgpOcNLPLdFNxggi3NTh-S/view?usp=sharing -O Linemod_preprocessed.zip\n",
        "!unzip Linemod_preprocessed.zip\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mdcx-6-aogqF",
      "metadata": {
        "id": "Mdcx-6-aogqF"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "%mv Linemod_preprocessed /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f1977a",
      "metadata": {
        "id": "20f1977a"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428d0988",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e78866",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e78866",
        "outputId": "b5cd53ec-326c-40a1-a4d8-f7fec238b55d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from utils.load_data import mount_drive\n",
        "\n",
        "# Mounting part\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6bbd0dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6bbd0dc",
        "outputId": "a3326ecf-a530-4f9e-d68f-a8ba83bcabb8"
      },
      "outputs": [],
      "source": [
        "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
        "dataset_root = \"../../Linemod_preprocessed_small\"\n",
        "# dataset_root = \"/content/Linemod_preprocessed\"\n",
        "\n",
        "print(\"\\nâœ… Setup complete!\")\n",
        "print(f\"ðŸ“ Dataset path: {dataset_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4728378e",
      "metadata": {
        "id": "4728378e"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4gbKJycp4vr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4gbKJycp4vr",
        "outputId": "1a37cca0-76ab-4675-df0b-becd827133ce"
      },
      "outputs": [],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cc69f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75cc69f7",
        "outputId": "4a87d952-f2cf-4e57-d26c-eeabf1bdc09d"
      },
      "outputs": [],
      "source": [
        "from src.pose_rgbd.loss import GeodesicLoss\n",
        "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
        "\n",
        "train_dataset = LineModPoseDepthDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "test_dataset = LineModPoseDepthDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split=\"test\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aea679a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aea679a",
        "outputId": "9280a363-50e8-45a0-c1d1-32a7f0ff340d"
      },
      "outputs": [],
      "source": [
        "sample = train_dataset[0]\n",
        "\n",
        "print(f\"Sample keys: {sample.keys()}\")\n",
        "print(f\"Depth shape: {sample['depth'].shape}\")\n",
        "print(f\"RGB shape: {sample['image'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb01874d",
      "metadata": {
        "id": "fb01874d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a727c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82a727c4",
        "outputId": "2eb9ff33-3511-4a32-8d88-73e9c3dec89a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import MSELoss\n",
        "from src.pose_rgbd.model import RotationPredictionModel\n",
        "from src.pose_rgbd.dataset import LineModPoseDepthDataset\n",
        "from src.pose_rgbd.loss import GeodesicLoss\n",
        "\n",
        "\n",
        "# Configurazione del dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ce6568",
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.linemod_config import get_linemod_config\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# dataset_root = \"../../Linemod_preprocessed_small\"  # Adjust path as needed\n",
        "linemod_config = get_linemod_config(dataset_root)\n",
        "\n",
        "all_model_points = []\n",
        "NUM_POINTS = 1000  # Number of points to sample from each model\n",
        "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
        "for obj_id in VALID_OBJ_IDS:\n",
        "    model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n",
        "    if model_points.shape[0] >= NUM_POINTS:\n",
        "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=False)\n",
        "    else:\n",
        "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=True)\n",
        "    model_points = model_points[choice, :]\n",
        "    all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n",
        "all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n",
        "all_model_points = all_model_points.to(device)\n",
        "\n",
        "max_obj_id = max(VALID_OBJ_IDS)\n",
        "\n",
        "# Create a lookup table: obj_id -> index\n",
        "obj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\n",
        "for idx, obj_id in enumerate(VALID_OBJ_IDS):\n",
        "    obj_id_to_idx[obj_id] = idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f220786c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.pose_rgbd.loss import MultiObjectPointMatchingLoss\n",
        "\n",
        "model = RotationPredictionModel(pretrained=True, freeze_backbone=False)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = MultiObjectPointMatchingLoss(all_model_points)\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6666a692",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6666a692",
        "outputId": "ab3b40a4-1a5d-4ce0-b172-17a7b1994075"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "from itertools import islice\n",
        "from datetime import datetime\n",
        "\n",
        "# Load best model\n",
        "\n",
        "# Ciclo di training\n",
        "num_epochs = 50\n",
        "best_test_loss = float('inf')\n",
        "# checkpoint_dir = \"checkpoints\"\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "checkpoint_dir = f'/content/drive/MyDrive/runs/POINT_MATCH_{timestamp}' # modify here for kaggle\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "val_batches_limit = 50\n",
        "\n",
        "# Track losses for plotting\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
        "    for batch in train_pbar:\n",
        "        rgb = batch['image'].to(device)  # RGB image (B, 3, H, W)\n",
        "        depth = batch['depth'].to(device)  # Depth (B, 1, H, W)\n",
        "        rotations = batch['rotation'].to(device)  # GT quaternion (B, 4)\n",
        "        obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
        "        obj_ids = obj_id_to_idx[obj_ids]  # Map to indices (B,)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(rgb, depth)\n",
        "\n",
        "        # Calcolo della loss\n",
        "        loss = criterion(outputs, rotations, obj_ids)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        train_pbar.set_postfix({'loss': epoch_loss / (train_pbar.n + 1)})\n",
        "\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "\n",
        "    val_iterator = islice(test_loader, val_batches_limit)\n",
        "    val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_pbar:\n",
        "            rgb = batch['image'].to(device)\n",
        "            depth = batch['depth'].to(device)\n",
        "            rotations = batch['rotation'].to(device)\n",
        "            obj_ids = batch['object_id'].to(device)  # Object IDs (B,)\n",
        "            obj_ids = obj_id_to_idx[obj_ids]  # Map to indices (B,)\n",
        "\n",
        "            outputs = model(rgb, depth)\n",
        "            loss = criterion(outputs, rotations, obj_ids)\n",
        "            test_loss += loss.item()\n",
        "            val_pbar.set_postfix({'loss': test_loss / (val_pbar.n + 1)})\n",
        "\n",
        "    avg_test_loss = test_loss / len(val_iterator)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "    # Save checkpoint if test loss improved\n",
        "    if avg_test_loss < best_test_loss:\n",
        "        best_test_loss = avg_test_loss\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'test_loss': avg_test_loss,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"âœ… Checkpoint saved! Best Test Loss: {best_test_loss:.4f}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  No improvement. Best Test Loss: {best_test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2823bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d2823bc9",
        "outputId": "ef287fb9-80b6-4626-8107-2d4e958acdbd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create plots directory\n",
        "# plots_dir = \"plots\"\n",
        "plots_dir = checkpoint_dir\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "# Plot 1: Training vs Test Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "epochs_range = range(1, num_epochs + 1)\n",
        "plt.plot(epochs_range, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
        "plt.plot(epochs_range, test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
        "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Plot saved: {loss_plot_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Only Training Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_range, train_losses, 'b-o', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Training Loss', fontsize=12)\n",
        "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
        "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Plot saved: {train_loss_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Only Test Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_range, test_losses, 'r-s', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Test Loss', fontsize=12)\n",
        "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tight_layout()\n",
        "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
        "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Plot saved: {test_loss_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nâœ… All plots saved in '{plots_dir}' directory!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OEDg_DQr32yn",
      "metadata": {
        "id": "OEDg_DQr32yn"
      },
      "outputs": [],
      "source": [
        "# Save losses\n",
        "import pickle\n",
        "\n",
        "test_mod = [t * len(test_dataset) / (50 * 32) for t in test_losses]\n",
        "\n",
        "losses_dict = {\n",
        "    'train_losses': train_losses,\n",
        "    'test_losses': test_mod\n",
        "}\n",
        "\n",
        "losses_path = os.path.join(checkpoint_dir, \"losses.pkl\")\n",
        "with open(losses_path, 'wb') as f:\n",
        "    pickle.dump(losses_dict, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3dcf9c",
      "metadata": {
        "id": "da3dcf9c"
      },
      "source": [
        "# Visualize samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad99042",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cad99042",
        "outputId": "8870604a-00eb-4a86-ef5d-8708e035b204"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import cv2\n",
        "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison, get_image\n",
        "\n",
        "# Setup projection utils\n",
        "setup_projection_utils(dataset_root)\n",
        "\n",
        "# Load best model\n",
        "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
        "checkpoint = torch.load(best_checkpoint_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"âœ… Loaded best model from epoch {checkpoint['epoch']} with test loss: {checkpoint['test_loss']:.4f}\")\n",
        "\n",
        "# Select a random sample from test dataset\n",
        "random_idx = random.randint(0, len(test_dataset) - 1)\n",
        "sample = test_dataset[random_idx]\n",
        "\n",
        "print(f\"\\nðŸ“· Visualizing sample {random_idx}:\")\n",
        "print(f\"   Object ID: {sample['object_id']}\")\n",
        "print(f\"   Image ID: {sample['img_id']}\")\n",
        "\n",
        "# Get the original image\n",
        "img_path = sample['img_path']\n",
        "image_rgb = cv2.imread(str(img_path))\n",
        "# image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Prepare input for model\n",
        "rgb = sample['image'].unsqueeze(0).to(device)  # Add batch dimension\n",
        "depth = sample['depth'].unsqueeze(0).to(device)  # Add batch and channel dimensions\n",
        "\n",
        "# Get model prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_rotation = model(rgb, depth)[0].cpu().numpy()\n",
        "\n",
        "# Get ground truth\n",
        "gt_rotation = sample['rotation'].numpy()\n",
        "gt_translation = sample['translation'].numpy()\n",
        "\n",
        "# Get camera intrinsics\n",
        "cam_K = sample['cam_K'].numpy()\n",
        "\n",
        "print(f\"\\nðŸ“Š Ground Truth vs Prediction:\")\n",
        "print(f\"   GT Rotation: {gt_rotation}\")\n",
        "print(f\"   Pred Rotation: {pred_rotation}\")\n",
        "print(f\"   GT Translation: {gt_translation}\")\n",
        "\n",
        "# Visualize pose comparison\n",
        "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
        "img_vis = visualize_pose_comparison(\n",
        "    image_rgb,\n",
        "    object_id=sample['object_id'],\n",
        "    cam_K=cam_K,\n",
        "    gt_rotation=gt_rotation,\n",
        "    gt_translation=gt_translation,\n",
        "    pred_rotation=pred_rotation,\n",
        "    pred_translation=gt_translation  # Using GT translation for now\n",
        ")\n",
        "\n",
        "# Convert BGR to RGB for matplotlib\n",
        "img_vis_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
        "ax.imshow(img_vis_rgb)\n",
        "ax.axis('off')\n",
        "ax.set_title(f\"Pose Visualization - Object {sample['object_id']}, Image {sample['img_id']}\", fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "# plt.savefig(os.path.join(plots_dir, f\"pose_visualization_sample_{random_idx}.png\"), dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nâœ… Visualization saved!\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlVenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
