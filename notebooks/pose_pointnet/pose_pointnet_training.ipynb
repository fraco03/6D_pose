{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25573688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:48:35.081902Z",
     "iopub.status.busy": "2025-12-20T09:48:35.081636Z",
     "iopub.status.idle": "2025-12-20T09:48:36.348328Z",
     "shell.execute_reply": "2025-12-20T09:48:36.347472Z",
     "shell.execute_reply.started": "2025-12-20T09:48:35.081871Z"
    },
    "id": "25573688",
    "outputId": "72321497-6c3a-436b-90f0-fd5df011e398",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull part\n",
    "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
    "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
    "branch = \"pose_rgbd\"\n",
    "\n",
    "# Clone if missing\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -b {branch} {repo_url}\n",
    "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
    "else:\n",
    "    %cd {repo_dir}\n",
    "    !git fetch origin\n",
    "    !git checkout {branch}\n",
    "    !git reset --hard origin/{branch}\n",
    "    # %cd ..\n",
    "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
    "\n",
    "# Add repository to Python path\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdEhRyP0oHcN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "execution_failed": "2025-12-20T11:15:16.832Z"
    },
    "id": "MdEhRyP0oHcN",
    "outputId": "777a0c2c-83d7-4db1-b21c-05a812fa8bc0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1zNthSyiBdPUfn7BmUKPbKoGgQdG1vGnS/view?usp=drive_link -O Linemod_preprocessed.zip\n",
    "!unzip Linemod_preprocessed.zip\n",
    "%cd 6D_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e78866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e78866",
    "outputId": "b5cd53ec-326c-40a1-a4d8-f7fec238b55d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from utils.load_data import mount_drive\n",
    "\n",
    "# Mounting part\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e2b0-ebc6-412b-b2db-6f36c33f0b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:57:27.976090Z",
     "iopub.status.busy": "2025-12-20T09:57:27.975476Z",
     "iopub.status.idle": "2025-12-20T09:57:46.017384Z",
     "shell.execute_reply": "2025-12-20T09:57:46.016449Z",
     "shell.execute_reply.started": "2025-12-20T09:57:27.976041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd0dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:57:56.004631Z",
     "iopub.status.busy": "2025-12-20T09:57:56.004331Z",
     "iopub.status.idle": "2025-12-20T09:57:56.009639Z",
     "shell.execute_reply": "2025-12-20T09:57:56.009064Z",
     "shell.execute_reply.started": "2025-12-20T09:57:56.004599Z"
    },
    "id": "d6bbd0dc",
    "outputId": "a3326ecf-a530-4f9e-d68f-a8ba83bcabb8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
    "dataset_root = \"../../Linemod_preprocessed_small\"\n",
    "# dataset_root = \"/content/Linemod_preprocessed\"\n",
    "# dataset_root = \"/kaggle/working/Linemod_preprocessed\"\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")\n",
    "print(f\"üìÅ Dataset path: {dataset_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728378e",
   "metadata": {
    "id": "4728378e"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598da66d-fc4d-4d42-b8d8-52104f3947c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T16:29:25.943772Z",
     "iopub.status.busy": "2025-12-19T16:29:25.943473Z",
     "iopub.status.idle": "2025-12-19T16:29:43.917596Z",
     "shell.execute_reply": "2025-12-19T16:29:43.916652Z",
     "shell.execute_reply.started": "2025-12-19T16:29:25.943738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed ./working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4gbKJycp4vr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:58:01.763290Z",
     "iopub.status.busy": "2025-12-20T09:58:01.762971Z",
     "iopub.status.idle": "2025-12-20T09:58:13.038336Z",
     "shell.execute_reply": "2025-12-20T09:58:13.037425Z",
     "shell.execute_reply.started": "2025-12-20T09:58:01.763264Z"
    },
    "id": "b4gbKJycp4vr",
    "outputId": "1a37cca0-76ab-4675-df0b-becd827133ce",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc69f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:58:13.040156Z",
     "iopub.status.busy": "2025-12-20T09:58:13.039868Z",
     "iopub.status.idle": "2025-12-20T09:59:31.633511Z",
     "shell.execute_reply": "2025-12-20T09:59:31.632667Z",
     "shell.execute_reply.started": "2025-12-20T09:58:13.040128Z"
    },
    "id": "75cc69f7",
    "outputId": "4a87d952-f2cf-4e57-d26c-eeabf1bdc09d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_pointnet.dataset import PointNetLineModDataset\n",
    "\n",
    "train_dataset = PointNetLineModDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "test_dataset = PointNetLineModDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea679a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:44.816475Z",
     "iopub.status.busy": "2025-12-20T09:59:44.816059Z",
     "iopub.status.idle": "2025-12-20T09:59:44.862578Z",
     "shell.execute_reply": "2025-12-20T09:59:44.861972Z",
     "shell.execute_reply.started": "2025-12-20T09:59:44.816448Z"
    },
    "id": "0aea679a",
    "outputId": "9280a363-50e8-45a0-c1d1-32a7f0ff340d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: Tensor of shape {value.shape} and dtype {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value)} with value {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a727c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:49.255635Z",
     "iopub.status.busy": "2025-12-20T09:59:49.255341Z",
     "iopub.status.idle": "2025-12-20T09:59:49.338644Z",
     "shell.execute_reply": "2025-12-20T09:59:49.338069Z",
     "shell.execute_reply.started": "2025-12-20T09:59:49.255610Z"
    },
    "id": "82a727c4",
    "outputId": "2eb9ff33-3511-4a32-8d88-73e9c3dec89a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce6568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:52.153424Z",
     "iopub.status.busy": "2025-12-20T09:59:52.153133Z",
     "iopub.status.idle": "2025-12-20T09:59:58.457722Z",
     "shell.execute_reply": "2025-12-20T09:59:58.456928Z",
     "shell.execute_reply.started": "2025-12-20T09:59:52.153399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.linemod_config import get_linemod_config\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "linemod_config = get_linemod_config(dataset_root)\n",
    "\n",
    "all_model_points = []\n",
    "NUM_POINTS = 1000  # Number of points to sample from each model\n",
    "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
    "for obj_id in VALID_OBJ_IDS:\n",
    "    model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n",
    "    if model_points.shape[0] >= NUM_POINTS:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=True)\n",
    "    model_points = model_points[choice, :]\n",
    "    all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n",
    "all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n",
    "all_model_points = all_model_points.to(device)\n",
    "\n",
    "max_obj_id = max(VALID_OBJ_IDS)\n",
    "\n",
    "# Create a lookup table: obj_id -> index\n",
    "obj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\n",
    "for idx, obj_id in enumerate(VALID_OBJ_IDS):\n",
    "    obj_id_to_idx[obj_id] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b1b58-4804-474a-8116-8c1f089220a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:59:58.459260Z",
     "iopub.status.busy": "2025-12-20T09:59:58.458914Z",
     "iopub.status.idle": "2025-12-20T09:59:58.464527Z",
     "shell.execute_reply": "2025-12-20T09:59:58.463735Z",
     "shell.execute_reply.started": "2025-12-20T09:59:58.459224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220786c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:20.945503Z",
     "iopub.status.busy": "2025-12-20T10:15:20.944832Z",
     "iopub.status.idle": "2025-12-20T10:15:21.398296Z",
     "shell.execute_reply": "2025-12-20T10:15:21.397691Z",
     "shell.execute_reply.started": "2025-12-20T10:15:20.945472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.pose_pointnet.loss import MultiObjectPointMatchingLoss\n",
    "import torch.nn as nn\n",
    "from src.pose_pointnet.model import PointNetPoseModel\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = PointNetPoseModel()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"üî• Using {torch.cuda.device_count()} GPU!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = MultiObjectPointMatchingLoss(all_model_points)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4ae51-b4ce-4a9b-87d5-1fbe4b19e6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:22.482439Z",
     "iopub.status.busy": "2025-12-20T10:15:22.481626Z",
     "iopub.status.idle": "2025-12-20T10:15:22.486608Z",
     "shell.execute_reply": "2025-12-20T10:15:22.485877Z",
     "shell.execute_reply.started": "2025-12-20T10:15:22.482409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64  #double GPU\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666a692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T10:15:24.125859Z",
     "iopub.status.busy": "2025-12-20T10:15:24.125144Z",
     "iopub.status.idle": "2025-12-20T10:53:54.454215Z",
     "shell.execute_reply": "2025-12-20T10:53:54.453401Z",
     "shell.execute_reply.started": "2025-12-20T10:15:24.125832Z"
    },
    "id": "6666a692",
    "outputId": "ab3b40a4-1a5d-4ce0-b172-17a7b1994075",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================================\n",
    "# 0. SETUP AND CONFIGURATION\n",
    "# ==========================================\n",
    "num_epochs = 25  # PointNet converges relatively fast\n",
    "best_test_loss = float('inf')\n",
    "batch_size = 32  # Adjust based on your GPU VRAM\n",
    "\n",
    "# Setup checkpoint directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# checkpoint_dir = f'/kaggle/working/POINTNET_{timestamp}'\n",
    "checkpoint_dir = f'./POINTNET_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Trackers for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"üöÄ Starting PointNet Training on {device}\")\n",
    "print(f\"üìÅ Checkpoints will be saved to: {checkpoint_dir}\")\n",
    "print(f\"üó∫Ô∏è  Object ID Mapping created for {len(obj_id_to_idx)} objects.\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. TRAINING LOOP\n",
    "# ==========================================\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Initialize progress bar\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
    "    \n",
    "    for batch in train_pbar:\n",
    "        # Move data to GPU\n",
    "        # PointNet input: (Batch, 3, Num_Points)\n",
    "        points = batch['points'].to(device)  \n",
    "        \n",
    "        # Auxiliary data for reconstruction and loss\n",
    "        centroids = batch['centroid'].to(device)       # (B, 3)\n",
    "        gt_rotations = batch['rotation'].to(device)    # (B, 4)\n",
    "        gt_t_absolute = batch['gt_translation'].to(device) # (B, 3) - Absolute target\n",
    "        \n",
    "        # Handle Object IDs for Loss Indexing\n",
    "        raw_obj_ids = batch['object_id'].tolist()\n",
    "        # Map raw IDs (e.g., 15) to buffer indices (e.g., 12)\n",
    "        target_indices = torch.tensor(\n",
    "            [obj_id_to_idx[oid] for oid in raw_obj_ids], \n",
    "            dtype=torch.long, device=device\n",
    "        )\n",
    "\n",
    "        # --- FORWARD PASS ---\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # The network predicts: \n",
    "        # 1. Quaternion (pred_q)\n",
    "        # 2. Residual Translation relative to centroid (pred_t_res)\n",
    "        pred_q, pred_t_res = model(points)\n",
    "\n",
    "        # --- RECONSTRUCTION ---\n",
    "        # Reconstruct absolute translation for the ADD Loss\n",
    "        # Absolute_Pos = Centroid + Residual\n",
    "        pred_t_abs = centroids + pred_t_res\n",
    "\n",
    "        # --- LOSS CALCULATION ---\n",
    "        # Using MultiObjectPointMatchingLoss (ADD metric)\n",
    "        loss = criterion(\n",
    "            pred_q=pred_q, \n",
    "            pred_t=pred_t_abs,   # Pass the reconstructed absolute translation\n",
    "            gt_q=gt_rotations, \n",
    "            gt_t=gt_t_absolute, \n",
    "            class_indices=target_indices\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update stats\n",
    "        epoch_loss += loss.item()\n",
    "        train_pbar.set_postfix({'ADD Loss (m)': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. VALIDATION LOOP\n",
    "    # ==========================================\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    val_pbar = tqdm(test_loader, desc=\"Validating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            # Move data to GPU\n",
    "            points = batch['points'].to(device)\n",
    "            centroids = batch['centroid'].to(device)\n",
    "            gt_rotations = batch['rotation'].to(device)\n",
    "            gt_t_absolute = batch['gt_translation'].to(device)\n",
    "            \n",
    "            # Map IDs\n",
    "            raw_obj_ids = batch['object_id'].tolist()\n",
    "            target_indices = torch.tensor(\n",
    "                [obj_id_to_idx[oid] for oid in raw_obj_ids], \n",
    "                dtype=torch.long, device=device\n",
    "            )\n",
    "\n",
    "            # Forward\n",
    "            pred_q, pred_t_res = model(points)\n",
    "\n",
    "            # Reconstruction\n",
    "            pred_t_abs = centroids + pred_t_res\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(\n",
    "                pred_q=pred_q, \n",
    "                pred_t=pred_t_abs, \n",
    "                gt_q=gt_rotations, \n",
    "                gt_t=gt_t_absolute, \n",
    "                class_indices=target_indices\n",
    "            )\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            val_pbar.set_postfix({'Val Loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    \n",
    "    print(f\"üìä Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} m | Val Loss: {avg_test_loss:.4f} m\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. CHECKPOINT SAVING\n",
    "    # ==========================================\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        \n",
    "        # Handle DataParallel state_dict if necessary\n",
    "        model_state = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model_state,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_test_loss,\n",
    "            'config': { \n",
    "                'num_points': 1024, # Useful for inference\n",
    "                'obj_map': obj_id_to_idx\n",
    "            }\n",
    "        }, checkpoint_path)\n",
    "        print(f\"‚úÖ New Record! Model saved with Loss: {best_test_loss:.4f} m\")\n",
    "    else:\n",
    "        print(f\"‚è≥ No improvement (Best: {best_test_loss:.4f} m)\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T10:53:58.626482Z",
     "iopub.status.busy": "2025-12-20T10:53:58.626146Z",
     "iopub.status.idle": "2025-12-20T10:54:00.560764Z",
     "shell.execute_reply": "2025-12-20T10:54:00.560032Z",
     "shell.execute_reply.started": "2025-12-20T10:53:58.626448Z"
    },
    "id": "d2823bc9",
    "outputId": "ef287fb9-80b6-4626-8107-2d4e958acdbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots directory\n",
    "# plots_dir = \"plots\"\n",
    "plots_dir = checkpoint_dir\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Training vs Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, len(test_losses)+1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {loss_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Only Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
    "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {train_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Only Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Test Loss', fontsize=12)\n",
    "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
    "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {test_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ All plots saved in '{plots_dir}' directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OEDg_DQr32yn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T10:54:12.535178Z",
     "iopub.status.busy": "2025-12-20T10:54:12.534582Z",
     "iopub.status.idle": "2025-12-20T10:54:12.539879Z",
     "shell.execute_reply": "2025-12-20T10:54:12.539172Z",
     "shell.execute_reply.started": "2025-12-20T10:54:12.535147Z"
    },
    "id": "OEDg_DQr32yn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save losses\n",
    "import pickle\n",
    "\n",
    "\n",
    "losses_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses\n",
    "}\n",
    "\n",
    "losses_path = os.path.join(checkpoint_dir, \"losses.pkl\")\n",
    "with open(losses_path, 'wb') as f:\n",
    "    pickle.dump(losses_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dcf9c",
   "metadata": {
    "id": "da3dcf9c"
   },
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-20T11:01:38.744094Z",
     "iopub.status.busy": "2025-12-20T11:01:38.743779Z",
     "iopub.status.idle": "2025-12-20T11:01:39.607462Z",
     "shell.execute_reply": "2025-12-20T11:01:39.606597Z",
     "shell.execute_reply.started": "2025-12-20T11:01:38.744066Z"
    },
    "id": "cad99042",
    "outputId": "8870604a-00eb-4a86-ef5d-8708e035b204",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP E CARICAMENTO MODELLO\n",
    "# ==========================================\n",
    "\n",
    "# Setup projection utils (assumiamo dataset_root sia definito)\n",
    "setup_projection_utils(dataset_root)\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "if not os.path.exists(best_checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint non trovato: {best_checkpoint_path}\")\n",
    "\n",
    "print(f\"üìÇ Caricamento checkpoint da: {best_checkpoint_path}\")\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location=device)\n",
    "\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# Rimuovi il prefisso 'module.' se il modello era in DataParallel\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# Inizializza il modello (Assumiamo PointNetPoseModel sia importata)\n",
    "# model = PointNetPoseModel(num_points=1024).to(device) # Scommenta se devi instanziare\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Modello caricato dall'epoca {checkpoint.get('epoch', '?')} con loss: {checkpoint.get('best_val_loss', '?'):.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. SELEZIONE E PREPARAZIONE SAMPLE\n",
    "# ==========================================\n",
    "\n",
    "# Seleziona un indice casuale dal test dataset\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "sample = test_dataset[random_idx]\n",
    "\n",
    "print(f\"\\nüì∑ Visualizing Sample {random_idx}:\")\n",
    "print(f\"   Object ID: {sample['object_id']}\")\n",
    "# Gestione robusta nel caso 'img_id' manchi (vecchi dataset)\n",
    "img_id_display = sample.get('img_id', 'N/A')\n",
    "print(f\"   Image ID: {img_id_display}\")\n",
    "\n",
    "# Recuperiamo l'immagine RGB originale per disegnare sopra\n",
    "# Nel dataset PointNet non carichiamo l'RGB nel __getitem__, quindi dobbiamo farlo a mano qui\n",
    "# Costruiamo il path usando le info nel sample o nel config\n",
    "if 'img_path' in sample:\n",
    "    img_path = sample['img_path']\n",
    "else:\n",
    "    # Fallback: ricostruiamo il path se non √® nel sample\n",
    "    # (Assumendo struttura LineMod standard)\n",
    "    obj_id = sample['object_id']\n",
    "    img_id = sample['img_id']\n",
    "    img_path = os.path.join(dataset_root, 'data', f\"{obj_id:02d}\", 'rgb', f\"{img_id:04d}.png\")\n",
    "\n",
    "image_bgr = cv2.imread(str(img_path))\n",
    "if image_bgr is None:\n",
    "    raise FileNotFoundError(f\"Impossibile caricare immagine da: {img_path}\")\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ==========================================\n",
    "# 3. INFERENZA POINTNET\n",
    "# ==========================================\n",
    "\n",
    "# Prepara i tensori (Aggiungi dimensione batch)\n",
    "points = sample['points'].unsqueeze(0).to(device)       # (1, 3, N)\n",
    "centroid = sample['centroid'].unsqueeze(0).to(device)   # (1, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Il modello restituisce rotazione E residuo traslazione\n",
    "    pred_q, pred_t_res = model(points)\n",
    "    \n",
    "    # Ricostruzione Traslazione Assoluta\n",
    "    # T_abs = Centroid + Residual\n",
    "    pred_trans_abs = centroid + pred_t_res\n",
    "\n",
    "# Converti in numpy per visualizzazione\n",
    "pred_rotation = pred_q[0].cpu().numpy()\n",
    "pred_translation = pred_trans_abs[0].cpu().numpy()\n",
    "\n",
    "# Ground Truth\n",
    "gt_rotation = sample['rotation'].numpy()\n",
    "gt_translation = sample['gt_translation'].numpy() # O sample['translation']\n",
    "cam_K = sample['cam_K'].numpy()\n",
    "\n",
    "print(f\"\\nüìä Ground Truth vs Prediction:\")\n",
    "print(f\"   GT Rotation:   {gt_rotation}\")\n",
    "print(f\"   Pred Rotation: {pred_rotation}\")\n",
    "print(f\"   GT Trans (m):   {gt_translation}\")\n",
    "print(f\"   Pred Trans (m): {pred_translation}\")\n",
    "\n",
    "# Calcola errore distanza (solo per curiosit√†)\n",
    "dist_error = np.linalg.norm(gt_translation - pred_translation)\n",
    "print(f\"   Translation Error: {dist_error*100:.2f} cm\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. VISUALIZZAZIONE\n",
    "# ==========================================\n",
    "\n",
    "# Visualizza confronto pose\n",
    "# Nota: La funzione visualize_pose_comparison si aspetta un'immagine RGB (numpy)\n",
    "img_vis = visualize_pose_comparison(\n",
    "    image_rgb,\n",
    "    object_id=sample['object_id'],\n",
    "    cam_K=cam_K,\n",
    "    gt_rotation=gt_rotation,\n",
    "    gt_translation=gt_translation,\n",
    "    pred_rotation=pred_rotation,\n",
    "    pred_translation=pred_translation  # <-- ORA USIAMO LA TRASLAZIONE PREDETTA!\n",
    ")\n",
    "\n",
    "# Plot con Matplotlib\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "# visualize_pose_comparison ritorna RGB se gli passi RGB, quindi ok\n",
    "ax.imshow(img_vis)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"PointNet Pose - Obj {sample['object_id']} (Err: {dist_error*100:.1f}cm)\", fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Visualizzazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5fe35-d2eb-4efc-aa76-5c0eb70a98f6",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862c6a3-6c12-4c90-b228-9ea1a1a47518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T11:12:25.657821Z",
     "iopub.status.busy": "2025-12-20T11:12:25.657497Z",
     "iopub.status.idle": "2025-12-20T11:12:58.649734Z",
     "shell.execute_reply": "2025-12-20T11:12:58.648942Z",
     "shell.execute_reply.started": "2025-12-20T11:12:25.657786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from metrics.ADD_metric import compute_ADD_metric_quaternion, compute_ADDs_metric_quaternion\n",
    "# Ensure you import the correct PointNet model class here\n",
    "from src.pose_pointnet.model import PointNetPoseModel \n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA AND DIAMETERS\n",
    "# ==========================================\n",
    "def load_models_info(models_dir, obj_ids, num_points=1000):\n",
    "    \"\"\"\n",
    "    Loads sampled points and calculates the DIAMETER of each object.\n",
    "    (This function remains unchanged as it works on .ply files).\n",
    "    \"\"\"\n",
    "    point_cache = {}\n",
    "    diameters = {}\n",
    "    \n",
    "    unique_ids = list(set(obj_ids))\n",
    "    print(f\"‚è≥ Loading info for {len(unique_ids)} models...\")\n",
    "    \n",
    "    for oid in tqdm(unique_ids, desc=\"Mesh Analysis\"):\n",
    "        filename = f\"obj_{int(oid):02d}.ply\"\n",
    "        path = os.path.join(models_dir, filename)\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            mesh = trimesh.load(path)\n",
    "            # 1. Sample points for ADD metric calculation\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "            point_cache[oid] = points / 1000.0  # Convert mm to Meters\n",
    "            \n",
    "            # 2. Diameter Calculation (Max distance in the mesh)\n",
    "            extents = mesh.extents / 1000.0  # Meters\n",
    "            diameter = np.linalg.norm(extents)\n",
    "            diameters[oid] = diameter\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing model file: {path}\")\n",
    "            \n",
    "    return point_cache, diameters\n",
    "\n",
    "# ==========================================\n",
    "# 2. COMPREHENSIVE EVALUATION (POINTNET VERSION)\n",
    "# ==========================================\n",
    "def evaluate_comprehensive(model, dataloader, device, models_dir, output_csv=\"evaluation_results.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluates the PointNet model using ADD and ADD-S metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # --- MAPPING ID TO NAMES (LineMOD Standard) ---\n",
    "    id_to_name = {\n",
    "        1: 'ape', 2: 'benchvise', 4: 'camera', 5: 'can', 6: 'cat',\n",
    "        8: 'driller', 9: 'duck', 10: 'eggbox', 11: 'glue',\n",
    "        12: 'holepuncher', 13: 'iron', 14: 'lamp', 15: 'phone'\n",
    "    }\n",
    "\n",
    "    # Define IDs to evaluate\n",
    "    all_obj_ids = list(id_to_name.keys())\n",
    "    \n",
    "    # Load mesh data (Points and Diameters)\n",
    "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
    "    \n",
    "    # Data Structures for logging\n",
    "    errors_dict = defaultdict(list)\n",
    "    accuracy_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "    # Objects requiring ADD-S (Symmetric objects)\n",
    "    SYMMETRIC_OBJECTS = [10, 11]  # Eggbox, Glue\n",
    "    \n",
    "    print(\"\\nüöÄ Starting Comprehensive Benchmark (ADD Error + ADD-0.1d Accuracy)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # --- UPDATED INPUTS FOR POINTNET ---\n",
    "            # We load points and centroids, not images\n",
    "            points = batch['points'].to(device)           # (B, 3, N)\n",
    "            centroids = batch['centroid'].to(device)      # (B, 3)\n",
    "            \n",
    "            gt_quats = batch['rotation'].to(device)       # (B, 4)\n",
    "            gt_trans = batch['gt_translation'].to(device) # (B, 3) - Absolute GT\n",
    "            obj_ids = batch['object_id']\n",
    "            \n",
    "            # --- FORWARD PASS ---\n",
    "            # Predict Rotation and Residual Translation\n",
    "            pred_quats, pred_t_res = model(points)\n",
    "            \n",
    "            # --- RECONSTRUCT ABSOLUTE TRANSLATION ---\n",
    "            # Abs_Trans = Centroid + Residual\n",
    "            pred_trans_abs = centroids + pred_t_res\n",
    "            \n",
    "            batch_size = points.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                curr_id = int(obj_ids[i])\n",
    "                if curr_id not in points_dict: continue\n",
    "\n",
    "                # Select Metric: ADD-S for symmetric, ADD for others\n",
    "                metric = compute_ADDs_metric_quaternion if curr_id in SYMMETRIC_OBJECTS else compute_ADD_metric_quaternion\n",
    "                \n",
    "                # --- CALCULATE ERROR ---\n",
    "                # We pass the PREDICTED translation (pred_trans_abs), not the GT one!\n",
    "                # This evaluates the full 6D pose (Rot + Trans).\n",
    "                add_error = metric(\n",
    "                    model_points=points_dict[curr_id],\n",
    "                    gt_quat=gt_quats[i].cpu().numpy(),\n",
    "                    gt_translation=gt_trans[i].cpu().numpy(),\n",
    "                    pred_quat=pred_quats[i].cpu().numpy(),\n",
    "                    pred_translation=pred_trans_abs[i].cpu().numpy() \n",
    "                )\n",
    "                \n",
    "                # Store absolute error\n",
    "                errors_dict[curr_id].append(add_error)\n",
    "                \n",
    "                # Calculate Accuracy (Threshold = 10% of diameter)\n",
    "                threshold = diameters_dict[curr_id] * 0.1\n",
    "                accuracy_stats[curr_id][\"total\"] += 1\n",
    "                if add_error < threshold:\n",
    "                    accuracy_stats[curr_id][\"correct\"] += 1\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. PANDAS REPORT GENERATION\n",
    "    # ==========================================\n",
    "    results_data = []\n",
    "    \n",
    "    total_acc_correct = 0\n",
    "    total_acc_count = 0\n",
    "    total_errors = []\n",
    "\n",
    "    sorted_ids = sorted(errors_dict.keys())\n",
    "    \n",
    "    for oid in sorted_ids:\n",
    "        # Error stats\n",
    "        mean_err_m = np.mean(errors_dict[oid])\n",
    "        mean_err_cm = mean_err_m * 100.0\n",
    "        total_errors.extend(errors_dict[oid])\n",
    "        \n",
    "        # Accuracy stats\n",
    "        stats = accuracy_stats[oid]\n",
    "        acc_perc = (stats[\"correct\"] / stats[\"total\"]) * 100.0 if stats[\"total\"] > 0 else 0.0\n",
    "        \n",
    "        total_acc_correct += stats[\"correct\"]\n",
    "        total_acc_count += stats[\"total\"]\n",
    "        \n",
    "        diam_cm = diameters_dict[oid] * 100.0\n",
    "        \n",
    "        # Get Class Name\n",
    "        class_name = id_to_name.get(oid, \"Unknown\")\n",
    "\n",
    "        # Append to list\n",
    "        results_data.append({\n",
    "            \"Object ID\": oid,\n",
    "            \"Class Name\": class_name,\n",
    "            \"Diameter (cm)\": round(diam_cm, 2),\n",
    "            \"Mean ADD Error (cm)\": round(mean_err_cm, 2),\n",
    "            \"Accuracy (%)\": round(acc_perc, 2),\n",
    "            \"Samples\": stats['total']\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results_data)\n",
    "\n",
    "    # Calculate Global Stats\n",
    "    global_mean_error_cm = np.mean(total_errors) * 100.0 if total_errors else 0.0\n",
    "    global_accuracy = (total_acc_correct / total_acc_count * 100.0) if total_acc_count > 0 else 0.0\n",
    "\n",
    "    # Add Global Row\n",
    "    global_row = pd.DataFrame([{\n",
    "        \"Object ID\": \"GLOBAL\",\n",
    "        \"Class Name\": \"ALL\", \n",
    "        \"Diameter (cm)\": \"-\",\n",
    "        \"Mean ADD Error (cm)\": round(global_mean_error_cm, 2),\n",
    "        \"Accuracy (%)\": round(global_accuracy, 2),\n",
    "        \"Samples\": total_acc_count\n",
    "    }])\n",
    "    \n",
    "    df = pd.concat([df, global_row], ignore_index=True)\n",
    "\n",
    "    # Print and Save\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL EVALUATION REPORT (POINTNET)\")\n",
    "    print(\"=\"*80)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbdf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USAGE ---\n",
    "\n",
    "# 1. Define Paths\n",
    "# MODELS_ROOT = '/kaggle/working/Linemod_preprocessed/models'\n",
    "MODELS_ROOT = '../../Linemod_preprocessed_small/models'\n",
    "checkpoint_path = checkpoint_dir + \"/best_model.pth\"\n",
    "\n",
    "# 2. Load Checkpoint\n",
    "print(f\"üìÇ Loading checkpoint from: {checkpoint_path}\")\n",
    "data = torch.load(checkpoint_path, map_location=device)\n",
    "state_dict = data['model_state_dict']\n",
    "\n",
    "# 3. Clean State Dict (Remove 'module.' prefix from DataParallel)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# 4. Initialize and Load Model\n",
    "model = PointNetPoseModel()\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.to(device)\n",
    "\n",
    "# 5. Run Evaluation\n",
    "evaluate_comprehensive(\n",
    "    model, \n",
    "    test_loader, \n",
    "    device, \n",
    "    MODELS_ROOT, \n",
    "    output_csv=checkpoint_dir + '/linemod_results.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10409e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9081703,
     "sourceId": 14235088,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
