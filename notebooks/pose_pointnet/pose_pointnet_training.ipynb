{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25573688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:28:34.793435Z",
     "iopub.status.busy": "2025-12-22T13:28:34.792413Z",
     "iopub.status.idle": "2025-12-22T13:28:35.516051Z",
     "shell.execute_reply": "2025-12-22T13:28:35.515177Z",
     "shell.execute_reply.started": "2025-12-22T13:28:34.793394Z"
    },
    "id": "25573688",
    "outputId": "72321497-6c3a-436b-90f0-fd5df011e398",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/6D_pose\n",
      "Already on 'pose_Pointnet'\n",
      "Your branch is up to date with 'origin/pose_Pointnet'.\n",
      "HEAD is now at 69de04a Feat: added RGB eval and fix issues\n",
      "Updated https://github.com/fraco03/6D_pose.git to /kaggle/working/6D_pose\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull part\n",
    "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
    "repo_dir = \"/kaggle/working/6D_pose\"   #Modify here for kaggle\n",
    "branch = \"pose_Pointnet\"\n",
    "\n",
    "# Clone if missing\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -b {branch} {repo_url}\n",
    "    print(f\"Cloned {repo_url} to {repo_dir}\")\n",
    "else:\n",
    "    %cd {repo_dir}\n",
    "    !git fetch origin\n",
    "    !git checkout {branch}\n",
    "    !git reset --hard origin/{branch}\n",
    "    # %cd ..\n",
    "    print(f\"Updated {repo_url} to {repo_dir}\")\n",
    "\n",
    "# Add repository to Python path\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607d2f50-66f8-4df1-883c-3435ae98f202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:53:42.045490Z",
     "iopub.status.busy": "2025-12-22T12:53:42.044550Z",
     "iopub.status.idle": "2025-12-22T12:53:42.049949Z",
     "shell.execute_reply": "2025-12-22T12:53:42.049039Z",
     "shell.execute_reply.started": "2025-12-22T12:53:42.045441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"/kaggle/working/6D_pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdEhRyP0oHcN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdEhRyP0oHcN",
    "outputId": "777a0c2c-83d7-4db1-b21c-05a812fa8bc0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# AVOID RUNNING IN KAGGLE!\n",
    "\n",
    "%cd ..\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1zNthSyiBdPUfn7BmUKPbKoGgQdG1vGnS/view?usp=drive_link -O Linemod_preprocessed.zip\n",
    "!unzip Linemod_preprocessed.zip\n",
    "%cd 6D_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e78866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-21T14:23:12.580683Z",
     "iopub.status.busy": "2025-12-21T14:23:12.580016Z",
     "iopub.status.idle": "2025-12-21T14:23:12.616331Z",
     "shell.execute_reply": "2025-12-21T14:23:12.615246Z",
     "shell.execute_reply.started": "2025-12-21T14:23:12.580653Z"
    },
    "id": "35e78866",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b5cd53ec-326c-40a1-a4d8-f7fec238b55d",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4820/2848321250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mounting part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmount_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kaggle/working/6D_pose/utils/load_data.py\u001b[0m in \u001b[0;36mmount_drive\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Drive mounted at /content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/hostname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;34m'Mounting drive is unsupported in this environment. Use PyDrive2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m' instead. See examples at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2."
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from utils.load_data import mount_drive\n",
    "\n",
    "# Mounting part\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e2b0-ebc6-412b-b2db-6f36c33f0b5e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6bbd0dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:28:46.113593Z",
     "iopub.status.busy": "2025-12-22T13:28:46.112936Z",
     "iopub.status.idle": "2025-12-22T13:28:46.118064Z",
     "shell.execute_reply": "2025-12-22T13:28:46.117342Z",
     "shell.execute_reply.started": "2025-12-22T13:28:46.113556Z"
    },
    "id": "d6bbd0dc",
    "outputId": "a3326ecf-a530-4f9e-d68f-a8ba83bcabb8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Setup complete!\n",
      "üìÅ Dataset path: /kaggle/input/line-mode/Linemod_preprocessed\n"
     ]
    }
   ],
   "source": [
    "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\" #Modify here for kaggle\n",
    "# dataset_root = \"../../Linemod_preprocessed_small\"\n",
    "# dataset_root = \"/content/Linemod_preprocessed\"\n",
    "# dataset_root = \"/kaggle/working/Linemod_preprocessed\"\n",
    "dataset_root = \"/kaggle/input/line-mode/Linemod_preprocessed\"\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")\n",
    "print(f\"üìÅ Dataset path: {dataset_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728378e",
   "metadata": {
    "id": "4728378e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598da66d-fc4d-4d42-b8d8-52104f3947c9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%mv Linemod_preprocessed ./working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4gbKJycp4vr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:28:49.538663Z",
     "iopub.status.busy": "2025-12-22T13:28:49.537923Z",
     "iopub.status.idle": "2025-12-22T13:28:52.624489Z",
     "shell.execute_reply": "2025-12-22T13:28:52.623539Z",
     "shell.execute_reply.started": "2025-12-22T13:28:49.538630Z"
    },
    "id": "b4gbKJycp4vr",
    "outputId": "1a37cca0-76ab-4675-df0b-becd827133ce",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plyfile in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from plyfile) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a443ec54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:29:58.613471Z",
     "iopub.status.busy": "2025-12-22T13:29:58.612737Z",
     "iopub.status.idle": "2025-12-22T13:29:58.617293Z",
     "shell.execute_reply": "2025-12-22T13:29:58.616473Z",
     "shell.execute_reply.started": "2025-12-22T13:29:58.613434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc69f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:01.024143Z",
     "iopub.status.busy": "2025-12-22T13:30:01.023837Z",
     "iopub.status.idle": "2025-12-22T13:30:25.959449Z",
     "shell.execute_reply": "2025-12-22T13:30:25.958794Z",
     "shell.execute_reply.started": "2025-12-22T13:30:01.024115Z"
    },
    "id": "75cc69f7",
    "outputId": "4a87d952-f2cf-4e57-d26c-eeabf1bdc09d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded PointNetLineModDataset\n",
      "   Split: train (Ratio: 0.8)\n",
      "   Num Points: 1024\n",
      "   Total samples: 12634\n",
      "‚úÖ Loaded PointNetLineModDataset\n",
      "   Split: test (Ratio: 0.8)\n",
      "   Num Points: 1024\n",
      "   Total samples: 3166\n"
     ]
    }
   ],
   "source": [
    "from src.pose_pointnet.dataset import PointNetLineModDataset\n",
    "\n",
    "train_dataset = PointNetLineModDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"train\",\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "test_dataset = PointNetLineModDataset(\n",
    "    root_dir=dataset_root,\n",
    "    split=\"test\",\n",
    "    augment=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aea679a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:25.972539Z",
     "iopub.status.busy": "2025-12-22T13:30:25.972355Z",
     "iopub.status.idle": "2025-12-22T13:30:25.981641Z",
     "shell.execute_reply": "2025-12-22T13:30:25.981062Z",
     "shell.execute_reply.started": "2025-12-22T13:30:25.972521Z"
    },
    "id": "0aea679a",
    "outputId": "9280a363-50e8-45a0-c1d1-32a7f0ff340d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys: dict_keys(['points', 'centroid', 'rotation', 't_residual', 'gt_translation', 'object_id', 'class_idx', 'img_id', 'cam_K'])\n",
      "  points: Tensor of shape torch.Size([3, 1024]) and dtype torch.float32\n",
      "  centroid: Tensor of shape torch.Size([3]) and dtype torch.float32\n",
      "  rotation: Tensor of shape torch.Size([4]) and dtype torch.float32\n",
      "  t_residual: Tensor of shape torch.Size([3]) and dtype torch.float32\n",
      "  gt_translation: Tensor of shape torch.Size([3]) and dtype torch.float32\n",
      "  object_id: <class 'int'> with value 1\n",
      "  class_idx: <class 'str'> with value ape\n",
      "  img_id: <class 'int'> with value 987\n",
      "  cam_K: Tensor of shape torch.Size([3, 3]) and dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {sample.keys()}\")\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: Tensor of shape {value.shape} and dtype {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value)} with value {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82a727c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:25.983523Z",
     "iopub.status.busy": "2025-12-22T13:30:25.983025Z",
     "iopub.status.idle": "2025-12-22T13:30:25.989554Z",
     "shell.execute_reply": "2025-12-22T13:30:25.988916Z",
     "shell.execute_reply.started": "2025-12-22T13:30:25.983499Z"
    },
    "id": "82a727c4",
    "outputId": "2eb9ff33-3511-4a32-8d88-73e9c3dec89a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12ce6568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:25.990708Z",
     "iopub.status.busy": "2025-12-22T13:30:25.990456Z",
     "iopub.status.idle": "2025-12-22T13:30:26.007833Z",
     "shell.execute_reply": "2025-12-22T13:30:26.007287Z",
     "shell.execute_reply.started": "2025-12-22T13:30:25.990688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.linemod_config import get_linemod_config\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "linemod_config = get_linemod_config(dataset_root)\n",
    "\n",
    "all_model_points = []\n",
    "NUM_POINTS = 1000  # Number of points to sample from each model\n",
    "VALID_OBJ_IDS = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15] \n",
    "for obj_id in VALID_OBJ_IDS:\n",
    "    model_points = linemod_config.get_model_3d(obj_id, unit='m')  # (N, 3)\n",
    "    if model_points.shape[0] >= NUM_POINTS:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(model_points.shape[0], NUM_POINTS, replace=True)\n",
    "    model_points = model_points[choice, :]\n",
    "    all_model_points.append(torch.tensor(model_points, dtype=torch.float32))\n",
    "all_model_points = torch.stack(all_model_points, dim=0)  # (Num_Classes, NUM_POINTS, 3)\n",
    "all_model_points = all_model_points.to(device)\n",
    "\n",
    "max_obj_id = max(VALID_OBJ_IDS)\n",
    "\n",
    "# Create a lookup table: obj_id -> index\n",
    "obj_id_to_idx = torch.full((max_obj_id + 1,), -1, dtype=torch.long, device=device)\n",
    "for idx, obj_id in enumerate(VALID_OBJ_IDS):\n",
    "    obj_id_to_idx[obj_id] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87b1b58-4804-474a-8116-8c1f089220a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:26.603802Z",
     "iopub.status.busy": "2025-12-22T13:30:26.602979Z",
     "iopub.status.idle": "2025-12-22T13:30:26.608836Z",
     "shell.execute_reply": "2025-12-22T13:30:26.608181Z",
     "shell.execute_reply.started": "2025-12-22T13:30:26.603771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1000, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f220786c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:32.103288Z",
     "iopub.status.busy": "2025-12-22T13:30:32.102941Z",
     "iopub.status.idle": "2025-12-22T13:30:32.121431Z",
     "shell.execute_reply": "2025-12-22T13:30:32.120763Z",
     "shell.execute_reply.started": "2025-12-22T13:30:32.103258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using 2 GPU!\n"
     ]
    }
   ],
   "source": [
    "from src.pose_pointnet.loss import MultiObjectPointMatchingLoss\n",
    "import torch.nn as nn\n",
    "from src.pose_pointnet.model import PointNetPoseModel\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "model = PointNetPoseModel()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"üî• Using {torch.cuda.device_count()} GPU!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = MultiObjectPointMatchingLoss(all_model_points)\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.001, \n",
    "    betas=(0.9, 0.999), \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=100,      # Imposta il numero delle tue epoche totali qui!\n",
    "    eta_min=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62482a0e-ba6c-4ec0-8682-5bfbbe6978dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:34.993597Z",
     "iopub.status.busy": "2025-12-22T13:30:34.993309Z",
     "iopub.status.idle": "2025-12-22T13:30:34.998410Z",
     "shell.execute_reply": "2025-12-22T13:30:34.997610Z",
     "shell.execute_reply.started": "2025-12-22T13:30:34.993571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_bn_momentum_default(curr_epoch, total_epochs, model):\n",
    "    \"\"\"\n",
    "    Decade il momentum della Batch Norm da 0.1 a 0.01 seguendo una curva a step o coseno.\n",
    "    In PyTorch il default momentum √® 0.1.\n",
    "    \"\"\"\n",
    "    # Formula originale PointNet: decade del 50% ogni tot step\n",
    "    # Qui usiamo una versione coseno pi√π moderna e fluida\n",
    "    \n",
    "    # Calcola il momentum target: parte da 0.1 e scende a 0.01\n",
    "    start_mom = 0.1\n",
    "    end_mom = 0.01\n",
    "    \n",
    "    # Interpolazione semplice basata sull'epoca\n",
    "    momentum = end_mom + (start_mom - end_mom) * (1 - (curr_epoch / total_epochs))\n",
    "    \n",
    "    # Applica a tutti i layer di Batch Norm nel modello\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "            m.momentum = momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbf4ae51-b4ce-4a9b-87d5-1fbe4b19e6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:39.872622Z",
     "iopub.status.busy": "2025-12-22T13:30:39.872059Z",
     "iopub.status.idle": "2025-12-22T13:30:39.877157Z",
     "shell.execute_reply": "2025-12-22T13:30:39.876434Z",
     "shell.execute_reply.started": "2025-12-22T13:30:39.872591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128  #double GPU\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True,\n",
    "                          persistent_workers=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         pin_memory=True,\n",
    "                         persistent_workers=True,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ec090c-2fc4-4010-9698-726f3b8b4c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:57:32.762310Z",
     "iopub.status.busy": "2025-12-22T12:57:32.761588Z",
     "iopub.status.idle": "2025-12-22T12:57:32.768025Z",
     "shell.execute_reply": "2025-12-22T12:57:32.767358Z",
     "shell.execute_reply.started": "2025-12-22T12:57:32.762282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoupledPoseLoss(nn.Module):\n",
    "    def __init__(self, rot_weight=1.0, trans_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.rot_weight = rot_weight\n",
    "        self.trans_weight = trans_weight\n",
    "        # Log per vedere i valori separati\n",
    "        self.last_rot_loss = 0.0\n",
    "        self.last_trans_loss = 0.0\n",
    "\n",
    "    def forward(self, pred_q, pred_t, gt_q, gt_t):\n",
    "        \"\"\"\n",
    "        pred_t e gt_t devono essere entrambi assoluti (o entrambi residui).\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- 1. LOSS TRASLAZIONE (MSE o L1) ---\n",
    "        # MSE √® pi√π aggressivo sugli errori grandi, L1 √® pi√π stabile\n",
    "        loss_trans = F.mse_loss(pred_t, gt_t)\n",
    "        \n",
    "        # --- 2. LOSS ROTAZIONE (Cosine Distance) ---\n",
    "        # I quaternioni q e -q rappresentano la stessa rotazione.\n",
    "        # Quindi vogliamo massimizzare il valore assoluto del prodotto scalare.\n",
    "        # Loss = 1 - |<q1, q2>|\n",
    "        dot_product = torch.sum(pred_q * gt_q, dim=1)\n",
    "        loss_rot = 1.0 - torch.mean(torch.abs(dot_product))\n",
    "        \n",
    "        # --- 3. SOMMA PESATA ---\n",
    "        total_loss = (self.trans_weight * loss_trans) + (self.rot_weight * loss_rot)\n",
    "        \n",
    "        # Salviamo i valori per stamparli (opzionale)\n",
    "        self.last_trans_loss = loss_trans.item()\n",
    "        self.last_rot_loss = loss_rot.item()\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6305bcff-a30d-4b9b-8bec-341ce3d406fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:57:36.720287Z",
     "iopub.status.busy": "2025-12-22T12:57:36.719704Z",
     "iopub.status.idle": "2025-12-22T12:57:36.724669Z",
     "shell.execute_reply": "2025-12-22T12:57:36.723951Z",
     "shell.execute_reply.started": "2025-12-22T12:57:36.720257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_rotation_error(pred_q, gt_q):\n",
    "    \"\"\"\n",
    "    Calcola l'errore angolare medio in GRADI tra due batch di quaternioni.\n",
    "    \"\"\"\n",
    "    # Prodotto scalare tra i quaternioni (q1 * q2)\n",
    "    # clamp serve per evitare errori numerici se il valore supera 1.0 per pochissimo\n",
    "    dot_product = torch.sum(pred_q * gt_q, dim=1)\n",
    "    dot_product = torch.clamp(torch.abs(dot_product), max=1.0) \n",
    "    \n",
    "    # Formula: 2 * arccos(|dot|)\n",
    "    theta_rad = 2 * torch.acos(dot_product)\n",
    "    theta_deg = torch.rad2deg(theta_rad)\n",
    "    \n",
    "    return theta_deg.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca2887-2a73-445b-a5d2-8cade07c3cc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-22T13:30:52.287658Z",
     "iopub.status.busy": "2025-12-22T13:30:52.286934Z",
     "iopub.status.idle": "2025-12-22T14:14:02.418370Z",
     "shell.execute_reply": "2025-12-22T14:14:02.417477Z",
     "shell.execute_reply.started": "2025-12-22T13:30:52.287626Z"
    },
    "id": "6666a692",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ab3b40a4-1a5d-4ce0-b172-17a7b1994075",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================================\n",
    "# 0. SETUP AND CONFIGURATION\n",
    "# ==========================================\n",
    "num_epochs = 100  # PointNet converges relatively fast\n",
    "best_test_loss = float('inf')\n",
    "batch_size = 32  # Adjust based on your GPU VRAM\n",
    "\n",
    "# Setup checkpoint directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "checkpoint_dir = f'/kaggle/working/POINTNET_{timestamp}'\n",
    "# checkpoint_dir = f'./POINTNET_{timestamp}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Trackers for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"üöÄ Starting PointNet Training on {device}\")\n",
    "print(f\"üìÅ Checkpoints will be saved to: {checkpoint_dir}\")\n",
    "print(f\"üó∫Ô∏è  Object ID Mapping created for {len(obj_id_to_idx)} objects.\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. TRAINING LOOP\n",
    "# ==========================================\n",
    "for epoch in range(num_epochs):\n",
    "    set_bn_momentum_default(epoch, num_epochs, model)\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Initialize progress bar\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] - Training\")\n",
    "    \n",
    "    for batch in train_pbar:\n",
    "        # Move data to GPU\n",
    "        # PointNet input: (Batch, 3, Num_Points)\n",
    "        points = batch['points'].to(device)  \n",
    "        \n",
    "        # Auxiliary data for reconstruction and loss\n",
    "        centroids = batch['centroid'].to(device)       # (B, 3)\n",
    "        gt_rotations = batch['rotation'].to(device)    # (B, 4)\n",
    "        gt_t_absolute = batch['gt_translation'].to(device) # (B, 3) - Absolute target\n",
    "        \n",
    "        # Handle Object IDs for Loss Indexing\n",
    "        raw_obj_ids = batch['object_id'].tolist()\n",
    "        # Map raw IDs (e.g., 15) to buffer indices (e.g., 12)\n",
    "        target_indices = torch.tensor(\n",
    "            [obj_id_to_idx[oid] for oid in raw_obj_ids], \n",
    "            dtype=torch.long, device=device\n",
    "        )\n",
    "\n",
    "        # --- FORWARD PASS ---\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # The network predicts: \n",
    "        # 1. Quaternion (pred_q)\n",
    "        # 2. Residual Translation relative to centroid (pred_t_res)\n",
    "        pred_q, pred_t_res = model(points)\n",
    "\n",
    "        # --- RECONSTRUCTION ---\n",
    "        # Reconstruct absolute translation for the ADD Loss\n",
    "        # Absolute_Pos = Centroid + Residual\n",
    "        pred_t_abs = centroids + pred_t_res\n",
    "\n",
    "        # --- LOSS CALCULATION ---\n",
    "        # Using MultiObjectPointMatchingLoss (ADD metric)\n",
    "        loss_add = criterion(\n",
    "            pred_q=pred_q, \n",
    "            pred_t=pred_t_abs,   # Pass the reconstructed absolute translation\n",
    "            gt_q=gt_rotations, \n",
    "            gt_t=gt_t_absolute, \n",
    "            class_indices=target_indices\n",
    "        )\n",
    "\n",
    "        # pure loss on quaternions\n",
    "        # dot = torch.sum(pred_q * gt_rotations, dim=1)\n",
    "        # loss_rot_pure = 1.0 - torch.mean(torch.abs(dot))\n",
    "        \n",
    "        # Final Hybrid Loss\n",
    "        loss = loss_add # + (2.0 * loss_rot_pure)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update stats\n",
    "        epoch_loss += loss.item()\n",
    "        train_pbar.set_postfix({'ADD Loss (m)': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. VALIDATION LOOP\n",
    "    # ==========================================\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    val_pbar = tqdm(test_loader, desc=\"Validating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            # Move data to GPU\n",
    "            points = batch['points'].to(device)\n",
    "            centroids = batch['centroid'].to(device)\n",
    "            gt_rotations = batch['rotation'].to(device)\n",
    "            gt_t_absolute = batch['gt_translation'].to(device)\n",
    "            \n",
    "            # Map IDs\n",
    "            raw_obj_ids = batch['object_id'].tolist()\n",
    "            target_indices = torch.tensor(\n",
    "                [obj_id_to_idx[oid] for oid in raw_obj_ids], \n",
    "                dtype=torch.long, device=device\n",
    "            )\n",
    "\n",
    "            # Forward\n",
    "            pred_q, pred_t_res = model(points)\n",
    "\n",
    "            # Reconstruction\n",
    "            pred_t_abs = centroids + pred_t_res\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(\n",
    "                pred_q=pred_q, \n",
    "                pred_t=pred_t_abs, \n",
    "                gt_q=gt_rotations, \n",
    "                gt_t=gt_t_absolute, \n",
    "                class_indices=target_indices\n",
    "            )\n",
    "\n",
    "            rot_err = compute_rotation_error(pred_q, gt_rotations)\n",
    "            val_pbar.set_postfix({\n",
    "                'Val Loss': f\"{loss.item():.4f}\", \n",
    "                'Rot Err (deg)': f\"{rot_err:.1f}¬∞\"  # <--- ECCOLO!\n",
    "            })\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            val_pbar.set_postfix({'Val Loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    \n",
    "    print(f\"üìä Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} m | Val Loss: {avg_test_loss:.4f} m\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. CHECKPOINT SAVING\n",
    "    # ==========================================\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        \n",
    "        # Handle DataParallel state_dict if necessary\n",
    "        model_state = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model_state,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_test_loss,\n",
    "            'config': { \n",
    "                'num_points': 1024, # Useful for inference\n",
    "                'obj_map': obj_id_to_idx\n",
    "            }\n",
    "        }, checkpoint_path)\n",
    "        print(f\"‚úÖ New Record! Model saved with Loss: {best_test_loss:.4f} m\")\n",
    "    else:\n",
    "        print(f\"‚è≥ No improvement (Best: {best_test_loss:.4f} m)\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T14:19:08.939489Z",
     "iopub.status.busy": "2025-12-22T14:19:08.939131Z",
     "iopub.status.idle": "2025-12-22T14:19:10.636653Z",
     "shell.execute_reply": "2025-12-22T14:19:10.635971Z",
     "shell.execute_reply.started": "2025-12-22T14:19:08.939453Z"
    },
    "id": "d2823bc9",
    "outputId": "ef287fb9-80b6-4626-8107-2d4e958acdbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots directory\n",
    "# plots_dir = \"plots\"\n",
    "plots_dir = checkpoint_dir\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Training vs Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, len(test_losses)+1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training vs Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "loss_plot_path = os.path.join(plots_dir, \"loss_comparison.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {loss_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Only Training Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "train_loss_path = os.path.join(plots_dir, \"training_loss.png\")\n",
    "plt.savefig(train_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {train_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Only Test Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-s', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Test Loss', fontsize=12)\n",
    "plt.title('Test Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best: {best_test_loss:.4f}', linewidth=2)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "test_loss_path = os.path.join(plots_dir, \"test_loss.png\")\n",
    "plt.savefig(test_loss_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {test_loss_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ All plots saved in '{plots_dir}' directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "OEDg_DQr32yn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:54:45.492208Z",
     "iopub.status.busy": "2025-12-22T14:54:45.491505Z",
     "iopub.status.idle": "2025-12-22T14:54:45.496828Z",
     "shell.execute_reply": "2025-12-22T14:54:45.496060Z",
     "shell.execute_reply.started": "2025-12-22T14:54:45.492178Z"
    },
    "id": "OEDg_DQr32yn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save losses\n",
    "import pickle\n",
    "\n",
    "\n",
    "losses_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses\n",
    "}\n",
    "\n",
    "losses_path = os.path.join(checkpoint_dir, \"losses.pkl\")\n",
    "with open(losses_path, 'wb') as f:\n",
    "    pickle.dump(losses_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dcf9c",
   "metadata": {
    "id": "da3dcf9c"
   },
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98a4a30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:46:58.271634Z",
     "iopub.status.busy": "2025-12-22T14:46:58.270931Z",
     "iopub.status.idle": "2025-12-22T14:46:58.276065Z",
     "shell.execute_reply": "2025-12-22T14:46:58.275392Z",
     "shell.execute_reply.started": "2025-12-22T14:46:58.271604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['points', 'centroid', 'rotation', 't_residual', 'gt_translation', 'object_id', 'class_idx', 'img_id', 'cam_K'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T14:47:00.289756Z",
     "iopub.status.busy": "2025-12-22T14:47:00.289246Z",
     "iopub.status.idle": "2025-12-22T14:47:00.876427Z",
     "shell.execute_reply": "2025-12-22T14:47:00.875613Z",
     "shell.execute_reply.started": "2025-12-22T14:47:00.289727Z"
    },
    "id": "cad99042",
    "outputId": "8870604a-00eb-4a86-ef5d-8708e035b204",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from utils.projection_utils import setup_projection_utils, visualize_pose_comparison\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP E CARICAMENTO MODELLO\n",
    "# ==========================================\n",
    "\n",
    "# Setup projection utils (assumiamo dataset_root sia definito)\n",
    "setup_projection_utils(dataset_root)\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "if not os.path.exists(best_checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint non trovato: {best_checkpoint_path}\")\n",
    "\n",
    "print(f\"üìÇ Caricamento checkpoint da: {best_checkpoint_path}\")\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location=device)\n",
    "\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# Rimuovi il prefisso 'module.' se il modello era in DataParallel\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    # name = k[7:] if k.startswith('module.') else k \n",
    "    name = \"module.\" + k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# Inizializza il modello (Assumiamo PointNetPoseModel sia importata)\n",
    "# model = PointNetPoseModel(num_points=1024).to(device) # Scommenta se devi instanziare\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Modello caricato dall'epoca {checkpoint.get('epoch', '?')} con loss: {checkpoint.get('best_val_loss', '?'):.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. SELEZIONE E PREPARAZIONE SAMPLE\n",
    "# ==========================================\n",
    "\n",
    "# Seleziona un indice casuale dal test dataset\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "sample = test_dataset[random_idx]\n",
    "\n",
    "print(f\"\\nüì∑ Visualizing Sample {random_idx}:\")\n",
    "print(f\"   Object ID: {sample['object_id']}\")\n",
    "# Gestione robusta nel caso 'img_id' manchi (vecchi dataset)\n",
    "img_id_display = sample.get('img_id', 'N/A')\n",
    "print(f\"   Image ID: {img_id_display}\")\n",
    "\n",
    "# Recuperiamo l'immagine RGB originale per disegnare sopra\n",
    "# Nel dataset PointNet non carichiamo l'RGB nel __getitem__, quindi dobbiamo farlo a mano qui\n",
    "# Costruiamo il path usando le info nel sample o nel config\n",
    "if 'img_path' in sample:\n",
    "    img_path = sample['img_path']\n",
    "else:\n",
    "    # Fallback: ricostruiamo il path se non √® nel sample\n",
    "    # (Assumendo struttura LineMod standard)\n",
    "    obj_id = sample['object_id']\n",
    "    img_id = sample['img_id']\n",
    "    img_path = os.path.join(dataset_root, 'data', f\"{obj_id:02d}\", 'rgb', f\"{img_id:04d}.png\")\n",
    "\n",
    "image_bgr = cv2.imread(str(img_path))\n",
    "if image_bgr is None:\n",
    "    raise FileNotFoundError(f\"Impossibile caricare immagine da: {img_path}\")\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ==========================================\n",
    "# 3. INFERENZA POINTNET\n",
    "# ==========================================\n",
    "\n",
    "# Prepara i tensori (Aggiungi dimensione batch)\n",
    "points = sample['points'].unsqueeze(0).to(device)       # (1, 3, N)\n",
    "centroid = sample['centroid'].unsqueeze(0).to(device)   # (1, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Il modello restituisce rotazione E residuo traslazione\n",
    "    pred_q, pred_t_res = model(points)\n",
    "    \n",
    "    # Ricostruzione Traslazione Assoluta\n",
    "    # T_abs = Centroid + Residual\n",
    "    pred_trans_abs = centroid + pred_t_res\n",
    "\n",
    "# Converti in numpy per visualizzazione\n",
    "pred_rotation = pred_q[0].cpu().numpy()\n",
    "pred_translation = pred_trans_abs[0].cpu().numpy()\n",
    "\n",
    "# Ground Truth\n",
    "gt_rotation = sample['rotation'].numpy()\n",
    "gt_translation = sample['gt_translation'].numpy() # O sample['translation']\n",
    "cam_K = sample['cam_K'].numpy()\n",
    "\n",
    "print(f\"\\nüìä Ground Truth vs Prediction:\")\n",
    "print(f\"   GT Rotation:   {gt_rotation}\")\n",
    "print(f\"   Pred Rotation: {pred_rotation}\")\n",
    "print(f\"   GT Trans (m):   {gt_translation}\")\n",
    "print(f\"   Pred Trans (m): {pred_translation}\")\n",
    "\n",
    "# Calcola errore distanza (solo per curiosit√†)\n",
    "dist_error = np.linalg.norm(gt_translation - pred_translation)\n",
    "print(f\"   Translation Error: {dist_error*100:.2f} cm\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. VISUALIZZAZIONE\n",
    "# ==========================================\n",
    "\n",
    "# Visualizza confronto pose\n",
    "# Nota: La funzione visualize_pose_comparison si aspetta un'immagine RGB (numpy)\n",
    "img_vis = visualize_pose_comparison(\n",
    "    image_rgb,\n",
    "    object_id=sample['object_id'],\n",
    "    cam_K=cam_K,\n",
    "    gt_rotation=gt_rotation,\n",
    "    gt_translation=gt_translation,\n",
    "    pred_rotation=pred_rotation,\n",
    "    pred_translation=pred_translation  # <-- ORA USIAMO LA TRASLAZIONE PREDETTA!\n",
    ")\n",
    "\n",
    "# Plot con Matplotlib\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "# visualize_pose_comparison ritorna RGB se gli passi RGB, quindi ok\n",
    "ax.imshow(img_vis)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"PointNet Pose - Obj {sample['object_id']} (Err: {dist_error*100:.1f}cm)\", fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Visualizzazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "210982f0-6028-41fb-ba4e-7fd93f6bf866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:53:15.719219Z",
     "iopub.status.busy": "2025-12-22T14:53:15.718811Z",
     "iopub.status.idle": "2025-12-22T14:53:15.757822Z",
     "shell.execute_reply": "2025-12-22T14:53:15.757031Z",
     "shell.execute_reply.started": "2025-12-22T14:53:15.719188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello salvato in: /kaggle/working/6D_pose/pointnet_vanilla_best.pth\n",
      "‚ö†Ô∏è ORA SCARICALO SUBITO! Se la sessione cade, il file sparisce.\n",
      "‚úÖ Checkpoint completo salvato.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Definizione percorso\n",
    "save_path = \"pointnet_vanilla_best.pth\"\n",
    "\n",
    "# Gestione DataParallel (se stavi usando 2 GPU)\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    state_dict = model.module.state_dict()\n",
    "else:\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "# Salvataggio\n",
    "torch.save(state_dict, save_path)\n",
    "\n",
    "print(f\"‚úÖ Modello salvato in: {os.path.abspath(save_path)}\")\n",
    "print(\"‚ö†Ô∏è ORA SCARICALO SUBITO! Se la sessione cade, il file sparisce.\")\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': 30,  # O l'ultima epoca a cui sei arrivato\n",
    "    'model_state_dict': state_dict, # Usa lo state_dict pulito calcolato sopra\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': 0.0368, # La tua best loss\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"pointnet_checkpoint_full.pth\")\n",
    "print(\"‚úÖ Checkpoint completo salvato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cb5fe35-d2eb-4efc-aa76-5c0eb70a98f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:53:25.429196Z",
     "iopub.status.busy": "2025-12-22T14:53:25.428641Z",
     "iopub.status.idle": "2025-12-22T14:53:28.499887Z",
     "shell.execute_reply": "2025-12-22T14:53:28.498983Z",
     "shell.execute_reply.started": "2025-12-22T14:53:25.429168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trimesh in /usr/local/lib/python3.12/dist-packages (4.10.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c862c6a3-6c12-4c90-b228-9ea1a1a47518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:53:58.540029Z",
     "iopub.status.busy": "2025-12-22T14:53:58.539716Z",
     "iopub.status.idle": "2025-12-22T14:53:58.557256Z",
     "shell.execute_reply": "2025-12-22T14:53:58.556424Z",
     "shell.execute_reply.started": "2025-12-22T14:53:58.539981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from metrics.ADD_metric import compute_ADD_metric_quaternion, compute_ADDs_metric_quaternion\n",
    "# Ensure you import the correct PointNet model class here\n",
    "from src.pose_pointnet.model import PointNetPoseModel \n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA AND DIAMETERS\n",
    "# ==========================================\n",
    "def load_models_info(models_dir, obj_ids, num_points=1000):\n",
    "    \"\"\"\n",
    "    Loads sampled points and calculates the DIAMETER of each object.\n",
    "    (This function remains unchanged as it works on .ply files).\n",
    "    \"\"\"\n",
    "    point_cache = {}\n",
    "    diameters = {}\n",
    "    \n",
    "    unique_ids = list(set(obj_ids))\n",
    "    print(f\"‚è≥ Loading info for {len(unique_ids)} models...\")\n",
    "    \n",
    "    for oid in tqdm(unique_ids, desc=\"Mesh Analysis\"):\n",
    "        filename = f\"obj_{int(oid):02d}.ply\"\n",
    "        path = os.path.join(models_dir, filename)\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            mesh = trimesh.load(path)\n",
    "            # 1. Sample points for ADD metric calculation\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "            point_cache[oid] = points / 1000.0  # Convert mm to Meters\n",
    "            \n",
    "            # 2. Diameter Calculation (Max distance in the mesh)\n",
    "            extents = mesh.extents / 1000.0  # Meters\n",
    "            diameter = np.linalg.norm(extents)\n",
    "            diameters[oid] = diameter\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing model file: {path}\")\n",
    "            \n",
    "    return point_cache, diameters\n",
    "\n",
    "# ==========================================\n",
    "# 2. COMPREHENSIVE EVALUATION (POINTNET VERSION)\n",
    "# ==========================================\n",
    "def evaluate_comprehensive(model, dataloader, device, models_dir, output_csv=\"evaluation_results.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluates the PointNet model using ADD and ADD-S metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # --- MAPPING ID TO NAMES (LineMOD Standard) ---\n",
    "    id_to_name = {\n",
    "        1: 'ape', 2: 'benchvise', 4: 'camera', 5: 'can', 6: 'cat',\n",
    "        8: 'driller', 9: 'duck', 10: 'eggbox', 11: 'glue',\n",
    "        12: 'holepuncher', 13: 'iron', 14: 'lamp', 15: 'phone'\n",
    "    }\n",
    "\n",
    "    # Define IDs to evaluate\n",
    "    all_obj_ids = list(id_to_name.keys())\n",
    "    \n",
    "    # Load mesh data (Points and Diameters)\n",
    "    points_dict, diameters_dict = load_models_info(models_dir, all_obj_ids)\n",
    "    \n",
    "    # Data Structures for logging\n",
    "    errors_dict = defaultdict(list)\n",
    "    accuracy_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "    # Objects requiring ADD-S (Symmetric objects)\n",
    "    SYMMETRIC_OBJECTS = [10, 11]  # Eggbox, Glue\n",
    "    \n",
    "    print(\"\\nüöÄ Starting Comprehensive Benchmark (ADD Error + ADD-0.1d Accuracy)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # --- UPDATED INPUTS FOR POINTNET ---\n",
    "            # We load points and centroids, not images\n",
    "            points = batch['points'].to(device)           # (B, 3, N)\n",
    "            centroids = batch['centroid'].to(device)      # (B, 3)\n",
    "            \n",
    "            gt_quats = batch['rotation'].to(device)       # (B, 4)\n",
    "            gt_trans = batch['gt_translation'].to(device) # (B, 3) - Absolute GT\n",
    "            obj_ids = batch['object_id']\n",
    "            \n",
    "            # --- FORWARD PASS ---\n",
    "            # Predict Rotation and Residual Translation\n",
    "            pred_quats, pred_t_res = model(points)\n",
    "            \n",
    "            # --- RECONSTRUCT ABSOLUTE TRANSLATION ---\n",
    "            # Abs_Trans = Centroid + Residual\n",
    "            pred_trans_abs = centroids + pred_t_res\n",
    "            \n",
    "            batch_size = points.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                curr_id = int(obj_ids[i])\n",
    "                if curr_id not in points_dict: continue\n",
    "\n",
    "                # Select Metric: ADD-S for symmetric, ADD for others\n",
    "                metric = compute_ADDs_metric_quaternion if curr_id in SYMMETRIC_OBJECTS else compute_ADD_metric_quaternion\n",
    "                \n",
    "                # --- CALCULATE ERROR ---\n",
    "                # We pass the PREDICTED translation (pred_trans_abs), not the GT one!\n",
    "                # This evaluates the full 6D pose (Rot + Trans).\n",
    "                add_error = metric(\n",
    "                    model_points=points_dict[curr_id],\n",
    "                    gt_quat=gt_quats[i].cpu().numpy(),\n",
    "                    gt_translation=gt_trans[i].cpu().numpy(),\n",
    "                    pred_quat=pred_quats[i].cpu().numpy(),\n",
    "                    pred_translation=pred_trans_abs[i].cpu().numpy() \n",
    "                )\n",
    "                \n",
    "                # Store absolute error\n",
    "                errors_dict[curr_id].append(add_error)\n",
    "                \n",
    "                # Calculate Accuracy (Threshold = 10% of diameter)\n",
    "                threshold = diameters_dict[curr_id] * 0.1\n",
    "                accuracy_stats[curr_id][\"total\"] += 1\n",
    "                if add_error < threshold:\n",
    "                    accuracy_stats[curr_id][\"correct\"] += 1\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. PANDAS REPORT GENERATION\n",
    "    # ==========================================\n",
    "    results_data = []\n",
    "    \n",
    "    total_acc_correct = 0\n",
    "    total_acc_count = 0\n",
    "    total_errors = []\n",
    "\n",
    "    sorted_ids = sorted(errors_dict.keys())\n",
    "    \n",
    "    for oid in sorted_ids:\n",
    "        # Error stats\n",
    "        mean_err_m = np.mean(errors_dict[oid])\n",
    "        mean_err_cm = mean_err_m * 100.0\n",
    "        total_errors.extend(errors_dict[oid])\n",
    "        \n",
    "        # Accuracy stats\n",
    "        stats = accuracy_stats[oid]\n",
    "        acc_perc = (stats[\"correct\"] / stats[\"total\"]) * 100.0 if stats[\"total\"] > 0 else 0.0\n",
    "        \n",
    "        total_acc_correct += stats[\"correct\"]\n",
    "        total_acc_count += stats[\"total\"]\n",
    "        \n",
    "        diam_cm = diameters_dict[oid] * 100.0\n",
    "        \n",
    "        # Get Class Name\n",
    "        class_name = id_to_name.get(oid, \"Unknown\")\n",
    "\n",
    "        # Append to list\n",
    "        results_data.append({\n",
    "            \"Object ID\": oid,\n",
    "            \"Class Name\": class_name,\n",
    "            \"Diameter (cm)\": round(diam_cm, 2),\n",
    "            \"Mean ADD Error (cm)\": round(mean_err_cm, 2),\n",
    "            \"Accuracy (%)\": round(acc_perc, 2),\n",
    "            \"Samples\": stats['total']\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results_data)\n",
    "\n",
    "    # Calculate Global Stats\n",
    "    global_mean_error_cm = np.mean(total_errors) * 100.0 if total_errors else 0.0\n",
    "    global_accuracy = (total_acc_correct / total_acc_count * 100.0) if total_acc_count > 0 else 0.0\n",
    "\n",
    "    # Add Global Row\n",
    "    global_row = pd.DataFrame([{\n",
    "        \"Object ID\": \"GLOBAL\",\n",
    "        \"Class Name\": \"ALL\", \n",
    "        \"Diameter (cm)\": \"-\",\n",
    "        \"Mean ADD Error (cm)\": round(global_mean_error_cm, 2),\n",
    "        \"Accuracy (%)\": round(global_accuracy, 2),\n",
    "        \"Samples\": total_acc_count\n",
    "    }])\n",
    "    \n",
    "    df = pd.concat([df, global_row], ignore_index=True)\n",
    "\n",
    "    # Print and Save\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL EVALUATION REPORT (POINTNET)\")\n",
    "    print(\"=\"*80)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fcbdf81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T14:54:06.740802Z",
     "iopub.status.busy": "2025-12-22T14:54:06.740286Z",
     "iopub.status.idle": "2025-12-22T14:54:16.746626Z",
     "shell.execute_reply": "2025-12-22T14:54:16.746049Z",
     "shell.execute_reply.started": "2025-12-22T14:54:06.740771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading checkpoint from: /kaggle/working/POINTNET_20251222_133052/best_model.pth\n",
      "‚è≥ Loading info for 13 models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276ad2e93cb044b3a24db57cebf8c4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mesh Analysis:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting Comprehensive Benchmark (ADD Error + ADD-0.1d Accuracy)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5aaab6366043cb9c1c22df28faa550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION REPORT (POINTNET)\n",
      "================================================================================\n",
      "Object ID  Class Name Diameter (cm)  Mean ADD Error (cm)  Accuracy (%)  Samples\n",
      "        1         ape         14.21                 0.63         95.56      248\n",
      "        2   benchvise         33.09                 1.23         96.71      243\n",
      "        4      camera         22.19                 0.82         96.27      241\n",
      "        5         can         28.42                 1.04         96.25      240\n",
      "        6         cat         18.59                 0.60         98.31      236\n",
      "        8     driller         31.88                 1.32         96.22      238\n",
      "        9        duck         15.57                 0.71         96.02      251\n",
      "       10      eggbox          19.7                 0.51        100.00      251\n",
      "       11        glue         19.31                 0.50         99.59      244\n",
      "       12 holepuncher         17.38                 0.71         96.77      248\n",
      "       13        iron         31.72                 7.56         46.32      231\n",
      "       14        lamp         31.66                 2.89         78.86      246\n",
      "       15       phone         25.43                 1.05         94.78      249\n",
      "   GLOBAL         ALL             -                 1.48         91.85     3166\n",
      "================================================================================\n",
      "‚úÖ Results saved to /kaggle/working/POINTNET_20251222_133052/linemod_results.csv\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# --- USAGE ---\n",
    "\n",
    "# 1. Define Paths\n",
    "MODELS_ROOT = \"/kaggle/input/line-mode/Linemod_preprocessed/models\"\n",
    "# in case of the samll dataset\n",
    "# MODELS_ROOT = \"/kaggle/input/linemode-preprocessed-small/Linemod_preprocessed_small/models\"\n",
    "checkpoint_path = checkpoint_dir + \"/best_model.pth\"\n",
    "\n",
    "# 2. Load Checkpoint\n",
    "print(f\"üìÇ Loading checkpoint from: {checkpoint_path}\")\n",
    "data = torch.load(checkpoint_path, map_location=device)\n",
    "state_dict = data['model_state_dict']\n",
    "\n",
    "# 3. Clean State Dict (Remove 'module.' prefix from DataParallel)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# 4. Initialize and Load Model\n",
    "test_model = PointNetPoseModel()\n",
    "test_model.load_state_dict(new_state_dict)\n",
    "test_model.to(device)\n",
    "\n",
    "# 5. Run Evaluation\n",
    "evaluate_comprehensive(\n",
    "    test_model, \n",
    "    test_loader, \n",
    "    device, \n",
    "    MODELS_ROOT, \n",
    "    output_csv=checkpoint_dir + '/linemod_results.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10409e3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8862865,
     "sourceId": 13909860,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
