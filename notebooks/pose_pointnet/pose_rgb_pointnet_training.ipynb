{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dad8daca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad8daca",
        "outputId": "dcf70adc-d787-45d4-e23e-3fd2d5a7b29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/6D_pose\n",
            "Already on 'pose_rgb'\n",
            "Your branch is up to date with 'origin/pose_rgb'.\n",
            "HEAD is now at 5a413ca Fix: minor changes\n",
            "/content\n",
            "Updated https://github.com/fraco03/6D_pose.git\n",
            "/content/6D_pose\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone or pull part\n",
        "repo_url = \"https://github.com/fraco03/6D_pose.git\"\n",
        "repo_dir = \"/content/6D_pose\"\n",
        "branch = \"pose_rgb\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    print(f\"Cloned {repo_url}\")\n",
        "else:\n",
        "    %cd {repo_dir}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git reset --hard origin/{branch}\n",
        "    %cd ..\n",
        "    print(f\"Updated {repo_url}\")\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)\n",
        "\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SQ3b58fTYu_g",
      "metadata": {
        "collapsed": true,
        "id": "SQ3b58fTYu_g"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1zNthSyiBdPUfn7BmUKPbKoGgQdG1vGnS/view?usp=drive_link -O Linemod_preprocessed.zip\n",
        "!unzip Linemod_preprocessed.zip\n",
        "%cd 6D_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "209858ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209858ea",
        "outputId": "812acb64-dbda-4771-e90a-d4ee22cdeba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Drive mounted at /content/drive\n",
            "\n",
            "âœ… Setup complete!\n",
            "ðŸ“ Dataset path: /content/Linemod_preprocessed\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from utils.load_data import mount_drive\n",
        "\n",
        "mount_drive()\n",
        "\n",
        "# dataset_root = \"/content/drive/MyDrive/Linemod_preprocessed\"\n",
        "dataset_root = \"/content/Linemod_preprocessed\"\n",
        "print(f\"\\nâœ… Setup complete!\")\n",
        "print(f\"ðŸ“ Dataset path: {dataset_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bf7c73b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf7c73b5",
        "outputId": "1a711857-58f3-4620-a1b2-812b4a1d207a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plyfile\n",
            "  Downloading plyfile-1.1.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from plyfile) (2.0.2)\n",
            "Downloading plyfile-1.1.3-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8eae81c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eae81c8",
        "outputId": "fdcedb0e-dfa4-43a1-80f8-40c5163cba5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from src.pose_pointnet.pointcloud_dataset import LineModPointCloudDataset\n",
        "from src.pose_pointnet.pointnet_model import PointNetPose\n",
        "from src.pose_rgb.loss import AutomaticWeightedLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"ðŸ”¥ Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9722028",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9722028",
        "outputId": "2595ca1c-d9ac-4cac-fe39-bc078f9b9d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LineModConfig initialized: /content/Linemod_preprocessed\n",
            "ðŸ”„ Preloading YAML files...\n",
            "âœ… Preloaded YAML data for 13 objects\n",
            "ðŸ“Š Loaded 2373 samples for train split\n",
            "ðŸ”„ Preloading YAML files...\n",
            "âœ… Preloaded YAML data for 13 objects\n",
            "ðŸ“Š Loaded 13407 samples for test split\n",
            "Train samples: 2373\n",
            "Test samples: 13407\n"
          ]
        }
      ],
      "source": [
        "# Crea dataset con point clouds\n",
        "# Nota: Prediciamo SOLO rotazione, la traslazione viene ricavata da depth + bbox usando pinhole geometry\n",
        "\n",
        "train_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='train',\n",
        "    num_points=512,\n",
        "    use_rgb=True\n",
        ")\n",
        "\n",
        "test_dataset = LineModPointCloudDataset(\n",
        "    root_dir=dataset_root,\n",
        "    split='test',\n",
        "    num_points=512,\n",
        "    use_rgb=True\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "befa5059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "befa5059",
        "outputId": "0806b81c-ce77-4d0f-eac0-81bf3b4aef09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample keys: dict_keys(['point_cloud', 'bbox_info', 'rotation', 'object_id', 'img_id', 'cam_K', 'bbox', 'depth_z', 'gt_translation'])\n",
            "Point cloud shape: torch.Size([512, 6])\n",
            "Rotation shape: torch.Size([4])\n",
            "Depth Z: 1.0280 m\n",
            "\n",
            "Rotation (quat, tensor): tensor([ 0.3326,  0.6473,  0.6364, -0.2555])\n",
            "Bbox info (tensor): tensor([0.4180, 0.4563, 0.0672, 0.1167])\n"
          ]
        }
      ],
      "source": [
        "# Visualizza un sample\n",
        "sample = train_dataset[0]\n",
        "\n",
        "print(\"Sample keys:\", sample.keys())\n",
        "print(f\"Point cloud shape: {sample['point_cloud'].shape}\")  # (512, 6)\n",
        "print(f\"Rotation shape: {sample['rotation'].shape}\")        # (4,) - TENSOR\n",
        "print(f\"Depth Z: {sample['depth_z']:.4f} m\")\n",
        "print(f\"\\nRotation (quat, tensor): {sample['rotation']}\")\n",
        "print(f\"Bbox info (tensor): {sample['bbox_info']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c441ebe0",
      "metadata": {
        "id": "c441ebe0"
      },
      "outputs": [],
      "source": [
        "# DataLoaders - Ottimizzati per performance\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,  # Aumentato da 32 per migliore GPU utilization\n",
        "    shuffle=True,\n",
        "    num_workers=2,  # Aumentato da 2\n",
        "    pin_memory=True  # Velocizza transfer CPU->GPU\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "54dbb9a9",
      "metadata": {
        "id": "54dbb9a9"
      },
      "outputs": [],
      "source": [
        "# Import visualization utilities\n",
        "from utils.projection_utils import visualize_pose_comparison\n",
        "from utils.linemod_config import get_linemod_config\n",
        "from utils.projection_utils import setup_projection_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Config per caricare modelli 3D\n",
        "config = get_linemod_config(dataset_root)\n",
        "setup_projection_utils(dataset_root)\n",
        "\n",
        "def compute_translation_from_depth(bbox_info, depth_z, cam_K, img_shape):\n",
        "    \"\"\"\n",
        "    Compute 3D translation using pinhole geometry.\n",
        "    bbox_info: tensor or numpy array\n",
        "    depth_z: scalar (tensor or float)\n",
        "    cam_K: tensor or numpy array\n",
        "    \"\"\"\n",
        "    H, W = img_shape\n",
        "\n",
        "    # Convert to numpy if needed\n",
        "    if isinstance(bbox_info, torch.Tensor):\n",
        "        bbox_info = bbox_info.numpy()\n",
        "    if isinstance(cam_K, torch.Tensor):\n",
        "        cam_K = cam_K.numpy()\n",
        "    if isinstance(depth_z, torch.Tensor):\n",
        "        depth_z = depth_z.item()\n",
        "\n",
        "    cx_norm, cy_norm = bbox_info[0], bbox_info[1]\n",
        "\n",
        "    # Convert normalized to pixel coordinates\n",
        "    cx_pixel = cx_norm * W\n",
        "    cy_pixel = cy_norm * H\n",
        "\n",
        "    # Back-project using pinhole model\n",
        "    fx = cam_K[0, 0]\n",
        "    fy = cam_K[1, 1]\n",
        "    cx_intr = cam_K[0, 2]\n",
        "    cy_intr = cam_K[1, 2]\n",
        "\n",
        "    Z = depth_z\n",
        "    X = (cx_pixel - cx_intr) * Z / fx\n",
        "    Y = (cy_pixel - cy_intr) * Z / fy\n",
        "\n",
        "    return np.array([X, Y, Z])\n",
        "\n",
        "def visualize_training_sample(model, dataset, dataset_root, checkpoint_dir, epoch, device='cuda'):\n",
        "    \"\"\"\n",
        "    Visualizza una predizione casuale e la salva.\n",
        "    \"\"\"\n",
        "    import shutil\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Sample casuale\n",
        "    idx = np.random.randint(0, len(dataset))\n",
        "    sample = dataset[idx]\n",
        "\n",
        "    obj_id = sample['object_id']\n",
        "    img_id = sample['img_id']\n",
        "\n",
        "    # Carica immagine originale\n",
        "    img_path = Path(dataset_root) / \"data\" / f\"{obj_id:02d}\" / \"rgb\" / f\"{img_id:04d}.png\"\n",
        "    image = cv2.imread(str(img_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    H, W = image.shape[:2]\n",
        "\n",
        "    # Prepare input\n",
        "    point_cloud = sample['point_cloud'].unsqueeze(0).to(device)\n",
        "    bbox_info = sample['bbox_info'].unsqueeze(0).to(device)\n",
        "\n",
        "    # Inference - ONLY rotation\n",
        "    with torch.no_grad():\n",
        "        pred_rot = model(point_cloud, bbox_info)\n",
        "\n",
        "    # Convert to numpy\n",
        "    pred_rot = pred_rot.squeeze(0).cpu().numpy()\n",
        "    gt_rot = sample['rotation'].cpu().numpy()\n",
        "    cam_K = sample['cam_K'].numpy()\n",
        "\n",
        "    # Compute translations from depth + bbox (same for both gt and pred)\n",
        "    trans = compute_translation_from_depth(sample['bbox_info'], sample['depth_z'], cam_K, (H, W))\n",
        "\n",
        "    # Visualizza (rotation is different, translation is same)\n",
        "    img_vis = visualize_pose_comparison(\n",
        "        image, obj_id, cam_K,\n",
        "        gt_rot, trans,\n",
        "        pred_rot, trans\n",
        "    )\n",
        "\n",
        "    # Calcola errore di rotazione\n",
        "    dot_product = np.abs(np.dot(pred_rot, gt_rot))\n",
        "    dot_product = np.clip(dot_product, -1.0, 1.0)\n",
        "    angle_error = 2 * np.arccos(dot_product) * 180 / np.pi\n",
        "\n",
        "    # Salva\n",
        "    tmp_path = f\"/tmp/vis_epoch_{epoch:03d}_obj_{obj_id:02d}.png\"\n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(img_vis)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Object {obj_id} | Rotation Error: {angle_error:.2f}Â°\")\n",
        "    plt.savefig(tmp_path, bbox_inches='tight', dpi=100)\n",
        "    plt.close()\n",
        "\n",
        "    # Copia su Drive\n",
        "    vis_dir = Path(checkpoint_dir) / \"visualizations\"\n",
        "    vis_dir.mkdir(exist_ok=True)\n",
        "    drive_path = vis_dir / f\"epoch_{epoch:03d}_obj_{obj_id:02d}.png\"\n",
        "    shutil.copy(tmp_path, str(drive_path))\n",
        "\n",
        "    print(f\"âœ… Saved: epoch {epoch} | Rotation Error: {angle_error:.2f}Â°\")\n",
        "\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dcaf4309",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaf4309",
        "outputId": "018a4887-232a-44ff-d3c6-cf7220e732f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ Precaching model_points (sampling 1024 points per model)...\n",
            "âœ… Cached 15 object models (1024 points each) to cuda\n",
            "\n",
            "ðŸ”¥ STARTING POINTNET ROTATION-ONLY TRAINING on cuda...\n",
            "ðŸ“ Checkpoints: /content/drive/MyDrive/runs/pointnet_20251218_134341\n",
            "âš™ï¸  Loss: PoseMatchingLoss (quaternion geodesic + point transformation)\n",
            "âš¡ Mixed Precision: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from itertools import islice\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.amp import autocast, GradScaler\n",
        "from src.pose_pointnet.pointnet_model import PointNetPose\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# HYPERPARAMETERS\n",
        "# ==========================================\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50\n",
        "USE_MIXED_PRECISION = True\n",
        "NUM_MODEL_POINTS = 1024  # Sample fixed number from each model\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/runs/pointnet_{timestamp}'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize PointNet Model - ROTATION ONLY\n",
        "model = PointNetPose(input_channels=6, use_batch_norm=True).to(DEVICE)\n",
        "\n",
        "# Loss - SIMPLE: Only Rotation Loss\n",
        "from src.pose_pointnet.loss import PoseMatchingLoss\n",
        "criterion = PoseMatchingLoss()\n",
        "\n",
        "# ==========================================\n",
        "# PRECACHE MODEL POINTS (ONE TIME)\n",
        "# ==========================================\n",
        "print(f\"âš¡ Precaching model_points (sampling {NUM_MODEL_POINTS} points per model)...\")\n",
        "model_points_gpu = {}\n",
        "for obj_id in range(1, 16):  # Objects 01-15\n",
        "    try:\n",
        "        vertices = config.get_model_3d(obj_id)  # (N, 3) in mm\n",
        "        vertices_m = vertices / 1000.0  # Convert to meters\n",
        "\n",
        "        # Sample fixed number of points\n",
        "        if vertices_m.shape[0] > NUM_MODEL_POINTS:\n",
        "            # Downsample: random sampling without replacement\n",
        "            indices = np.random.choice(vertices_m.shape[0], NUM_MODEL_POINTS, replace=False)\n",
        "            vertices_m = vertices_m[indices]\n",
        "        elif vertices_m.shape[0] < NUM_MODEL_POINTS:\n",
        "            # Upsample: random sampling with replacement\n",
        "            indices = np.random.choice(vertices_m.shape[0], NUM_MODEL_POINTS, replace=True)\n",
        "            vertices_m = vertices_m[indices]\n",
        "\n",
        "        # To GPU\n",
        "        model_points_gpu[obj_id] = torch.from_numpy(vertices_m).float().to(DEVICE)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Could not load model points for object {obj_id}: {e}\")\n",
        "\n",
        "print(f\"âœ… Cached {len(model_points_gpu)} object models ({NUM_MODEL_POINTS} points each) to {DEVICE}\")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Mixed Precision Scaler\n",
        "scaler = GradScaler('cuda') if USE_MIXED_PRECISION else None\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"\\nðŸ”¥ STARTING POINTNET ROTATION-ONLY TRAINING on {DEVICE}...\")\n",
        "print(f\"ðŸ“ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"âš™ï¸  Loss: PoseMatchingLoss (quaternion geodesic + point transformation)\")\n",
        "print(f\"âš¡ Mixed Precision: {USE_MIXED_PRECISION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c66a224",
      "metadata": {
        "id": "6c66a224"
      },
      "source": [
        "## ðŸŽ¯ Rotation-Only Model Architecture\n",
        "\n",
        "**Key Insight**: With depth available, we only need to predict **rotation**. Translation is computed directly using pinhole geometry:\n",
        "\n",
        "$$X = \\frac{(c_x - c_x^{intr}) \\cdot Z}{f_x}, \\quad Y = \\frac{(c_y - c_y^{intr}) \\cdot Z}{f_y}, \\quad Z = \\text{depth}[c_x, c_y]$$\n",
        "\n",
        "**Advantages:**\n",
        "- Simpler model (no translation head)\n",
        "- Faster training (only rotation loss)\n",
        "- More stable (depth provides ground truth Z)\n",
        "- Cleaner optimization (one prediction target instead of two)\n",
        "\n",
        "**Dataset returns:**\n",
        "- `point_cloud`: Local point cloud (NÃ—3 or NÃ—6 with RGB)\n",
        "- `rotation`: Target quaternion\n",
        "- `depth_z`: Z coordinate from depth at bbox center (for inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "659ef393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "659ef393",
        "outputId": "18333df8-a73a-4c03-bed9-eef49dce4d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.12it/s, Loss=0.0343]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:49<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 1: Train Loss=0.0567 | Val Loss=0.0475\n",
            "ðŸ† New Best Model! (Loss: 0.0475)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.14it/s, Loss=0.0416]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 2: Train Loss=0.0558 | Val Loss=0.0469\n",
            "ðŸ† New Best Model! (Loss: 0.0469)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.14it/s, Loss=0.0305]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 3: Train Loss=0.0550 | Val Loss=0.0468\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 2 | Rotation Error: 107.17Â°\n",
            "ðŸ† New Best Model! (Loss: 0.0468)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.13it/s, Loss=0.0574]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 4: Train Loss=0.0554 | Val Loss=0.0466\n",
            "ðŸ† New Best Model! (Loss: 0.0466)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.16it/s, Loss=0.0591]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 5: Train Loss=0.0552 | Val Loss=0.0463\n",
            "ðŸ† New Best Model! (Loss: 0.0463)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.14it/s, Loss=0.0691]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 6: Train Loss=0.0552 | Val Loss=0.0464\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 5 | Rotation Error: 20.94Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.14it/s, Loss=0.0527]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 7: Train Loss=0.0544 | Val Loss=0.0462\n",
            "ðŸ† New Best Model! (Loss: 0.0462)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.15it/s, Loss=0.0656]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 8: Train Loss=0.0544 | Val Loss=0.0465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.16it/s, Loss=0.0607]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:47<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 9: Train Loss=0.0539 | Val Loss=0.0467\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 8 | Rotation Error: 42.15Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.14it/s, Loss=0.0581]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 10: Train Loss=0.0535 | Val Loss=0.0460\n",
            "ðŸ† New Best Model! (Loss: 0.0460)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.17it/s, Loss=0.0485]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:43<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 11: Train Loss=0.0530 | Val Loss=0.0466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:34<00:00,  1.11it/s, Loss=0.0589]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 12: Train Loss=0.0526 | Val Loss=0.0473\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 11 | Rotation Error: 37.27Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.16it/s, Loss=0.0660]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 13: Train Loss=0.0532 | Val Loss=0.0462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.17it/s, Loss=0.0288]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 14: Train Loss=0.0514 | Val Loss=0.0456\n",
            "ðŸ† New Best Model! (Loss: 0.0456)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:34<00:00,  1.12it/s, Loss=0.0639]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 15: Train Loss=0.0520 | Val Loss=0.0460\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 14 | Rotation Error: 40.45Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.15it/s, Loss=0.0555]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 16: Train Loss=0.0510 | Val Loss=0.0463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.15it/s, Loss=0.0576]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 17: Train Loss=0.0512 | Val Loss=0.0465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:35<00:00,  1.07it/s, Loss=0.0701]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 18: Train Loss=0.0509 | Val Loss=0.0449\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 17 | Rotation Error: 23.23Â°\n",
            "ðŸ† New Best Model! (Loss: 0.0449)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.18it/s, Loss=0.0620]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 19: Train Loss=0.0502 | Val Loss=0.0444\n",
            "ðŸ† New Best Model! (Loss: 0.0444)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.15it/s, Loss=0.0581]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 20: Train Loss=0.0499 | Val Loss=0.0451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:35<00:00,  1.07it/s, Loss=0.0620]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:47<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 21: Train Loss=0.0501 | Val Loss=0.0461\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 20 | Rotation Error: 25.07Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:34<00:00,  1.09it/s, Loss=0.0441]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:47<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 22: Train Loss=0.0494 | Val Loss=0.0440\n",
            "ðŸ† New Best Model! (Loss: 0.0440)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:34<00:00,  1.10it/s, Loss=0.0464]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 23: Train Loss=0.0484 | Val Loss=0.0453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:33<00:00,  1.13it/s, Loss=0.0549]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:45<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Epoch 24: Train Loss=0.0490 | Val Loss=0.0441\n",
            "ðŸŽ¨ Visualizing random validation sample...\n",
            "âœ… Saved: epoch 23 | Rotation Error: 86.59Â°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50 [Train]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 26/38 [00:25<00:11,  1.02it/s, Loss=0.0514]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-156251962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Move ENTIRE batch to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         batch_cuda = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# TRAINING LOOP - POSE MATCHING LOSS\n",
        "# ==========================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # --- TRAIN PHASE ---\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
        "\n",
        "    for batch in pbar:\n",
        "        # Move ENTIRE batch to device\n",
        "        batch_cuda = {\n",
        "            'point_cloud': batch['point_cloud'].to(DEVICE, non_blocking=True),\n",
        "            'bbox_info': batch['bbox_info'].to(DEVICE, non_blocking=True),\n",
        "            'rotation': batch['rotation'].to(DEVICE, non_blocking=True),\n",
        "            'object_id': batch['object_id'],\n",
        "        }\n",
        "\n",
        "        # Get model_points from precached GPU cache\n",
        "        obj_ids = batch_cuda['object_id']\n",
        "        model_points_batch = torch.stack([model_points_gpu[obj_id.item()] for obj_id in obj_ids])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        if USE_MIXED_PRECISION:\n",
        "            with autocast('cuda'):\n",
        "                pred_rot = model(batch_cuda['point_cloud'], batch_cuda['bbox_info'])\n",
        "                loss = criterion(pred_rot, batch_cuda['rotation'], model_points_batch)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            pred_rot = model(batch_cuda['point_cloud'], batch_cuda['bbox_info'])\n",
        "            loss = criterion(pred_rot, batch_cuda['rotation'], model_points_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        pbar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- VALIDATION PHASE ---\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_batches_limit = 50\n",
        "    count_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_iterator = islice(test_loader, val_batches_limit)\n",
        "        val_pbar = tqdm(val_iterator, total=val_batches_limit, desc=\"Validating\")\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            # Move ENTIRE batch to device\n",
        "            batch_cuda = {\n",
        "                'point_cloud': batch['point_cloud'].to(DEVICE, non_blocking=True),\n",
        "                'bbox_info': batch['bbox_info'].to(DEVICE, non_blocking=True),\n",
        "                'rotation': batch['rotation'].to(DEVICE, non_blocking=True),\n",
        "                'object_id': batch['object_id'],\n",
        "            }\n",
        "\n",
        "\n",
        "            # Get model_points from precached GPU cache\n",
        "            obj_ids = batch_cuda['object_id']\n",
        "            model_points_batch = torch.stack([model_points_gpu[obj_id.item()] for obj_id in obj_ids])\n",
        "\n",
        "            if USE_MIXED_PRECISION:\n",
        "                with autocast('cuda'):\n",
        "                    pred_rot = model(batch_cuda['point_cloud'], batch_cuda['bbox_info'])\n",
        "                    loss = criterion(pred_rot, batch_cuda['rotation'], model_points_batch)\n",
        "            else:\n",
        "                pred_rot = model(batch_cuda['point_cloud'], batch_cuda['bbox_info'])\n",
        "                loss = criterion(pred_rot, batch_cuda['rotation'], model_points_batch)\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "            count_batches += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / count_batches if count_batches > 0 else 0.0\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # --- REPORT & SAVE ---\n",
        "    print(f\"ðŸ“Š Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} | Val Loss={avg_val_loss:.4f}\")\n",
        "\n",
        "    # --- VISUALIZE RANDOM SAMPLE ---\n",
        "    if (epoch + 1) % 3 == 0:\n",
        "        print(f\"ðŸŽ¨ Visualizing random validation sample...\")\n",
        "        visualize_training_sample(model, test_dataset, dataset_root, CHECKPOINT_DIR, epoch, DEVICE)\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_loss': best_val_loss\n",
        "        }, os.path.join(CHECKPOINT_DIR, \"best_model.pth\"))\n",
        "\n",
        "        print(f\"ðŸ† New Best Model! (Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Save last checkpoint\n",
        "    if (epoch + 1) == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "        }, os.path.join(CHECKPOINT_DIR, f\"checkpoint_ep{epoch+1}.pth\"))\n",
        "\n",
        "print(\"\\nðŸŽ‰ TRAINING COMPLETE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbd1b1a",
      "metadata": {
        "id": "cdbd1b1a"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('PointNet Training History')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o', alpha=0.7)\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s', alpha=0.7)\n",
        "if best_epoch > 0:\n",
        "    plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.5,\n",
        "                label=f'Best Epoch ({best_epoch})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (log scale)')\n",
        "plt.yscale('log')\n",
        "plt.title('PointNet Training History (Log)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_history.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nðŸ“Š Training Statistics:\")\n",
        "print(f\"   Best epoch: {best_epoch}\")\n",
        "print(f\"   Best val loss: {best_val_loss:.6f}\")\n",
        "print(f\"   Final train loss: {train_losses[-1]:.6f}\")\n",
        "\n",
        "# Save history\n",
        "history = {\n",
        "    'train_losses': [float(x) for x in train_losses],\n",
        "    'val_losses': [float(x) for x in val_losses],\n",
        "    'best_epoch': int(best_epoch),\n",
        "    'best_val_loss': float(best_val_loss),\n",
        "    'timestamp': timestamp\n",
        "}\n",
        "\n",
        "with open(os.path.join(CHECKPOINT_DIR, 'history.json'), 'w') as f:\n",
        "    json.dump(history, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc8bf1c",
      "metadata": {
        "id": "6cc8bf1c"
      },
      "source": [
        "## Visualize Point Cloud Sample\n",
        "\n",
        "Visualizing point cloud from random point in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e081a4e7",
      "metadata": {
        "id": "e081a4e7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Choose sample\n",
        "sample = train_dataset[100]\n",
        "pc = sample['point_cloud'].numpy()  # (512, 6) [x, y, z, r, g, b]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot 3D points with RGB colors\n",
        "ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2],\n",
        "           c=pc[:, 3:6], s=2, alpha=0.6)\n",
        "\n",
        "ax.set_xlabel('X (m)')\n",
        "ax.set_ylabel('Y (m)')\n",
        "ax.set_zlabel('Z (m)')\n",
        "ax.set_title(f'Point Cloud - Object {sample[\"object_id\"]}')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Object ID: {sample['object_id']}\")\n",
        "print(f\"Rotation (quat, tensor): {sample['rotation']}\")\n",
        "print(f\"GT Translation (m, tensor): {sample['gt_translation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "xBzdBr4w9w7V",
      "metadata": {
        "id": "xBzdBr4w9w7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168df543-0243-4ad2-938e-eb5489d10433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 60.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ADD: 0.0145 m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# QUICK EVALUATION - ADD/ADD-S METRICS\n",
        "# ==========================================\n",
        "\n",
        "# Load best model\n",
        "checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "from metrics.ADD_metric import compute_ADD_metric_quaternion\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(100)):  # 100 samples\n",
        "        sample = test_dataset[i]\n",
        "        pred_rot = model(sample['point_cloud'].unsqueeze(0).to(DEVICE),\n",
        "                        sample['bbox_info'].unsqueeze(0).to(DEVICE))\n",
        "\n",
        "        model_3d = config.get_model_3d(sample['object_id'], unit='m')\n",
        "        add = compute_ADD_metric_quaternion(\n",
        "            model_3d,\n",
        "            sample['rotation'].numpy(), sample['gt_translation'].numpy(),\n",
        "            pred_rot.squeeze(0).cpu().numpy(), sample['gt_translation'].numpy()\n",
        "        )\n",
        "        results.append(add)\n",
        "\n",
        "print(f\"Mean ADD: {np.mean(results):.4f} m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJZAcpcN0prg"
      },
      "id": "XJZAcpcN0prg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlVenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}